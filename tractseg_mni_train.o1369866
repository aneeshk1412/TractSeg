Processing /work/09355/aneeshks/ls6/TractSeg
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: future in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (0.18.3)
Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (1.26.1)
Requirement already satisfied: nibabel>=2.3.0 in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (5.1.0)
Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (3.8.1)
Requirement already satisfied: scikit-learn in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (1.3.2)
Requirement already satisfied: scipy in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (1.11.3)
Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (4.66.1)
Requirement already satisfied: six in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (1.16.0)
Requirement already satisfied: psutil in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (5.9.6)
Requirement already satisfied: dipy>=1.5.0 in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (1.7.0)
Requirement already satisfied: fury in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (0.9.0)
Requirement already satisfied: joblib>=0.13.2 in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (1.3.2)
Requirement already satisfied: seaborn in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (0.13.0)
Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (2.31.0)
Requirement already satisfied: xvfbwrapper in ./.venv/lib/python3.9/site-packages (from TractSeg==2.9) (0.2.9)
Requirement already satisfied: h5py>=2.8.0 in ./.venv/lib/python3.9/site-packages (from dipy>=1.5.0->TractSeg==2.9) (3.10.0)
Requirement already satisfied: packaging>=17 in ./.venv/lib/python3.9/site-packages (from nibabel>=2.3.0->TractSeg==2.9) (23.2)
Requirement already satisfied: aiohttp>=3.8.4 in ./.venv/lib/python3.9/site-packages (from fury->TractSeg==2.9) (3.8.6)
Requirement already satisfied: pillow>=5.4.1 in ./.venv/lib/python3.9/site-packages (from fury->TractSeg==2.9) (10.0.1)
Requirement already satisfied: pygltflib>=1.15.3 in ./.venv/lib/python3.9/site-packages (from fury->TractSeg==2.9) (1.16.1)
Requirement already satisfied: vtk>=9.1.0 in ./.venv/lib/python3.9/site-packages (from fury->TractSeg==2.9) (9.2.6)
Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->TractSeg==2.9) (1.2.0)
Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib->TractSeg==2.9) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->TractSeg==2.9) (4.44.0)
Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->TractSeg==2.9) (1.4.5)
Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->TractSeg==2.9) (3.1.1)
Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib->TractSeg==2.9) (2.8.2)
Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->TractSeg==2.9) (6.1.0)
Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests->TractSeg==2.9) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests->TractSeg==2.9) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests->TractSeg==2.9) (2.0.7)
Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests->TractSeg==2.9) (2023.7.22)
Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn->TractSeg==2.9) (3.2.0)
Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.9/site-packages (from seaborn->TractSeg==2.9) (2.1.2)
Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp>=3.8.4->fury->TractSeg==2.9) (23.1.0)
Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.9/site-packages (from aiohttp>=3.8.4->fury->TractSeg==2.9) (6.0.4)
Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.venv/lib/python3.9/site-packages (from aiohttp>=3.8.4->fury->TractSeg==2.9) (4.0.3)
Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.9/site-packages (from aiohttp>=3.8.4->fury->TractSeg==2.9) (1.9.2)
Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.9/site-packages (from aiohttp>=3.8.4->fury->TractSeg==2.9) (1.4.0)
Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.9/site-packages (from aiohttp>=3.8.4->fury->TractSeg==2.9) (1.3.1)
Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->TractSeg==2.9) (3.17.0)
Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas>=1.2->seaborn->TractSeg==2.9) (2023.3.post1)
Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.9/site-packages (from pandas>=1.2->seaborn->TractSeg==2.9) (2023.3)
Requirement already satisfied: dataclasses-json>=0.0.25 in ./.venv/lib/python3.9/site-packages (from pygltflib>=1.15.3->fury->TractSeg==2.9) (0.6.1)
Requirement already satisfied: deprecated in ./.venv/lib/python3.9/site-packages (from pygltflib>=1.15.3->fury->TractSeg==2.9) (1.2.14)
Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.9/site-packages (from dataclasses-json>=0.0.25->pygltflib>=1.15.3->fury->TractSeg==2.9) (3.20.1)
Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.9/site-packages (from dataclasses-json>=0.0.25->pygltflib>=1.15.3->fury->TractSeg==2.9) (0.9.0)
Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.9/site-packages (from deprecated->pygltflib>=1.15.3->fury->TractSeg==2.9) (1.15.0)
Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib>=1.15.3->fury->TractSeg==2.9) (1.0.0)
Requirement already satisfied: typing-extensions>=3.7.4 in ./.venv/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib>=1.15.3->fury->TractSeg==2.9) (4.8.0)
Building wheels for collected packages: TractSeg
  Building wheel for TractSeg (pyproject.toml): started
  Building wheel for TractSeg (pyproject.toml): finished with status 'done'
  Created wheel for TractSeg: filename=TractSeg-2.9-py3-none-any.whl size=4749020 sha256=bc781b3c466460c89abbce0beca9de56fc3712ab8eda8181436ef76a2afe27c9
  Stored in directory: /tmp/pip-ephem-wheel-cache-psi44os1/wheels/c2/f0/54/b83bc170689d8cb524ab13cb144bd7c615e9dbb8708f2c72d0
Successfully built TractSeg
Installing collected packages: TractSeg
  Attempting uninstall: TractSeg
    Found existing installation: TractSeg 2.9
    Uninstalling TractSeg-2.9:
      Successfully uninstalled TractSeg-2.9
Successfully installed TractSeg-2.9
INFO: LABELS_FILENAME manually set
Hyperparameters:
{'BATCH_NORM': False,
 'BATCH_SIZE': 8,
 'BEST_EPOCH': 0,
 'BEST_EPOCH_SELECTION': 'f1',
 'CALC_F1': True,
 'CLASSES': 'camcan_all_classes',
 'CSD_RESOLUTION': 'LOW',
 'CV_FOLD': 0,
 'DATASET': 'camcan',
 'DATASET_FOLDER': '/scratch/09355/aneeshks/SegTracts/TrainingData/camcan/',
 'DATA_AUGMENTATION': True,
 'DAUG_ALPHA': (90.0, 120.0),
 'DAUG_BLUR_SIGMA': (0, 1),
 'DAUG_ELASTIC_DEFORM': True,
 'DAUG_FLIP_PEAKS': False,
 'DAUG_GAUSSIAN_BLUR': True,
 'DAUG_INFO': '-',
 'DAUG_MIRROR': False,
 'DAUG_NOISE': True,
 'DAUG_NOISE_VARIANCE': (0, 0.05),
 'DAUG_RESAMPLE': False,
 'DAUG_RESAMPLE_LEGACY': False,
 'DAUG_ROTATE': False,
 'DAUG_ROTATE_ANGLE': (-0.2, 0.2),
 'DAUG_SCALE': True,
 'DAUG_SIGMA': (9.0, 11.0),
 'DIM': '2D',
 'DROPOUT_SAMPLING': False,
 'EPOCH_MULTIPLIER': 1,
 'EXPERIMENT_TYPE': 'tract_segmentation',
 'EXP_MULTI_NAME': '',
 'EXP_NAME': 'my_custom_experiment',
 'EXP_PATH': '/scratch/09355/aneeshks/hcp_exp/my_custom_experiment_x2',
 'FEATURES_FILENAME': 'peaks/peaks',
 'FLIP_OUTPUT_PEAKS': False,
 'FP16': True,
 'GET_PROBS': False,
 'INFO': '-',
 'INPUT_DIM': (144, 144),
 'INPUT_RESCALING': False,
 'KEEP_INTERMEDIATE_FILES': False,
 'LABELS_FILENAME': 'tractmasks/masks/mask',
 'LABELS_FOLDER': 'bundle_masks',
 'LABELS_TYPE': 'int',
 'LEARNING_RATE': 0.001,
 'LOAD_WEIGHTS': False,
 'LOSS_FUNCTION': 'soft_sample_dice',
 'LOSS_WEIGHT': None,
 'LOSS_WEIGHT_LEN': -1,
 'LR_SCHEDULE': True,
 'LR_SCHEDULE_MODE': 'min',
 'LR_SCHEDULE_PATIENCE': 20,
 'METRIC_TYPES': ['loss', 'f1_macro'],
 'MODEL': 'UNet_Pytorch_DeepSup',
 'MULTI_PARENT_PATH': '/scratch/09355/aneeshks/hcp_exp/',
 'NORMALIZE_DATA': True,
 'NORMALIZE_PER_CHANNEL': False,
 'NR_CPUS': -1,
 'NR_OF_CLASSES': 61,
 'NR_OF_GRADIENTS': 9,
 'NR_SLICES': 1,
 'NUM_EPOCHS': 150,
 'ONLY_VAL': False,
 'OPTIMIZER': 'Adamax',
 'OUTPUT_MULTIPLE_FILES': False,
 'PAD_TO_SQUARE': True,
 'PEAK_DICE_LEN_THR': 0.05,
 'PEAK_DICE_THR': [0.95],
 'PREDICT_IMG': False,
 'PREDICT_IMG_OUTPUT': None,
 'PRINT_FREQ': 20,
 'P_SAMP': 1.0,
 'RESET_LAST_LAYER': False,
 'RESOLUTION': '1.25mm',
 'SAVE_WEIGHTS': True,
 'SEGMENT': False,
 'SEG_INPUT': 'Peaks',
 'SLICE_DIRECTION': 'y',
 'SPATIAL_TRANSFORM': 'SpatialTransformPeaks',
 'TEST': False,
 'TEST_TIME_DAUG': False,
 'THRESHOLD': 0.5,
 'TRACTSEG_DIR': 'tractseg_output',
 'TRAIN': True,
 'TRAINING_SLICE_DIRECTION': 'xyz',
 'TYPE': 'single_direction',
 'UNET_NR_FILT': 64,
 'UPSAMPLE_TYPE': 'bilinear',
 'USE_DROPOUT': False,
 'USE_VISLOGGER': False,
 'VERBOSE': True,
 'WEIGHTS_PATH': '',
 'WEIGHT_DECAY': 0}
cuda
INFO: Did not find APEX, defaulting to fp32 training
Training...
torch.cuda.is_available() = True
torch.cuda.device_count() = 3
torch.cuda.current_device() = 0
c308-001.ls6.tacc.utexas.edu
Start looping batches...
using pin_memory on device 0
train Ep 0, Sp 160, loss 0.962239, t print 62.033s, t batch 3.102s
train Ep 0, Sp 320, loss 0.932126, t print 9.008s, t batch 0.45s
train Ep 0, Sp 480, loss 0.921081, t print 11.828s, t batch 0.591s
train Ep 0, Sp 640, loss 0.912913, t print 11.613s, t batch 0.581s
train Ep 0, Sp 800, loss 0.903953, t print 18.352s, t batch 0.918s
train Ep 0, Sp 960, loss 0.901594, t print 13.614s, t batch 0.681s
train Ep 0, Sp 1120, loss 0.89277, t print 11.609s, t batch 0.58s
train Ep 0, Sp 1280, loss 0.87609, t print 15.161s, t batch 0.758s
train Ep 0, Sp 1440, loss 0.857086, t print 16.745s, t batch 0.837s
train Ep 0, Sp 1600, loss 0.84514, t print 11.666s, t batch 0.583s
train Ep 0, Sp 1760, loss 0.856367, t print 11.815s, t batch 0.591s
train Ep 0, Sp 1920, loss 0.846759, t print 19.812s, t batch 0.991s
train Ep 0, Sp 2080, loss 0.85158, t print 11.649s, t batch 0.582s
train Ep 0, Sp 2240, loss 0.84947, t print 11.154s, t batch 0.558s
train Ep 0, Sp 2400, loss 0.846227, t print 19.397s, t batch 0.97s
train Ep 0, Sp 2560, loss 0.834525, t print 12.338s, t batch 0.617s
train Ep 0, Sp 2720, loss 0.82206, t print 11.117s, t batch 0.556s
train Ep 0, Sp 2880, loss 0.838991, t print 17.438s, t batch 0.872s
train Ep 0, Sp 3040, loss 0.833362, t print 14.032s, t batch 0.702s
train Ep 0, Sp 3200, loss 0.816411, t print 11.013s, t batch 0.551s
train Ep 0, Sp 3360, loss 0.834753, t print 15.653s, t batch 0.783s
train Ep 0, Sp 3520, loss 0.839867, t print 15.662s, t batch 0.783s
train Ep 0, Sp 3680, loss 0.801755, t print 10.999s, t batch 0.55s
train Ep 0, Sp 3840, loss 0.835242, t print 14.138s, t batch 0.707s
train Ep 0, Sp 4000, loss 0.845684, t print 17.202s, t batch 0.86s
train Ep 0, Sp 4160, loss 0.836118, t print 10.988s, t batch 0.549s
train Ep 0, Sp 4320, loss 0.823346, t print 12.598s, t batch 0.63s
train Ep 0, Sp 4480, loss 0.83561, t print 19.036s, t batch 0.952s
train Ep 0, Sp 4640, loss 0.828694, t print 11.047s, t batch 0.552s
train Ep 0, Sp 4800, loss 0.802683, t print 11.187s, t batch 0.559s
train Ep 0, Sp 4960, loss 0.802358, t print 20.556s, t batch 1.028s
train Ep 0, Sp 5120, loss 0.819043, t print 11.016s, t batch 0.551s
train Ep 0, Sp 5280, loss 0.778044, t print 11.169s, t batch 0.558s
train Ep 0, Sp 5440, loss 0.787801, t print 20.688s, t batch 1.034s
train Ep 0, Sp 5600, loss 0.788217, t print 11.145s, t batch 0.557s
train Ep 0, Sp 5760, loss 0.766168, t print 11.126s, t batch 0.556s
train Ep 0, Sp 5920, loss 0.77541, t print 22.116s, t batch 1.106s
train Ep 0, Sp 6080, loss 0.75348, t print 11.142s, t batch 0.557s
train Ep 0, Sp 6240, loss 0.763816, t print 11.195s, t batch 0.56s
train Ep 0, Sp 6400, loss 0.792255, t print 20.614s, t batch 1.031s
train Ep 0, Sp 6560, loss 0.80238, t print 11.202s, t batch 0.56s
train Ep 0, Sp 6720, loss 0.776563, t print 11.393s, t batch 0.57s
train Ep 0, Sp 6880, loss 0.763943, t print 20.856s, t batch 1.043s
train Ep 0, Sp 7040, loss 0.755826, t print 11.256s, t batch 0.563s
train Ep 0, Sp 7200, loss 0.762544, t print 11.224s, t batch 0.561s
train Ep 0, Sp 7360, loss 0.781547, t print 20.921s, t batch 1.046s
train Ep 0, Sp 7520, loss 0.777544, t print 11.217s, t batch 0.561s
train Ep 0, Sp 7680, loss 0.755917, t print 11.1s, t batch 0.555s
train Ep 0, Sp 7840, loss 0.756467, t print 20.521s, t batch 1.026s
train Ep 0, Sp 8000, loss 0.762178, t print 11.085s, t batch 0.554s
train Ep 0, Sp 8160, loss 0.769367, t print 11.108s, t batch 0.555s
train Ep 0, Sp 8320, loss 0.773767, t print 20.373s, t batch 1.019s
train Ep 0, Sp 8480, loss 0.754821, t print 11.515s, t batch 0.576s
train Ep 0, Sp 8640, loss 0.725248, t print 11.213s, t batch 0.561s
train Ep 0, Sp 8800, loss 0.727111, t print 18.743s, t batch 0.937s
train Ep 0, Sp 8960, loss 0.775241, t print 14.43s, t batch 0.722s
train Ep 0, Sp 9120, loss 0.734409, t print 10.943s, t batch 0.547s
train Ep 0, Sp 9280, loss 0.741291, t print 16.438s, t batch 0.822s
train Ep 0, Sp 9440, loss 0.723369, t print 14.726s, t batch 0.736s
train Ep 0, Sp 9600, loss 0.744353, t print 11.038s, t batch 0.552s
train Ep 0, Sp 9760, loss 0.756179, t print 16.069s, t batch 0.803s
train Ep 0, Sp 9920, loss 0.7295, t print 15.021s, t batch 0.751s
train Ep 0, Sp 10080, loss 0.71888, t print 10.978s, t batch 0.549s
train Ep 0, Sp 10240, loss 0.71381, t print 16.517s, t batch 0.826s
Start looping batches...
using pin_memory on device 0
validate Ep 0, Sp 160, loss 0.729062, t print 27.142s, t batch 1.357s
validate Ep 0, Sp 320, loss 0.732034, t print 10.596s, t batch 0.53s
validate Ep 0, Sp 480, loss 0.720033, t print 10.374s, t batch 0.519s
validate Ep 0, Sp 640, loss 0.725255, t print 19.39s, t batch 0.97s
validate Ep 0, Sp 800, loss 0.755686, t print 10.791s, t batch 0.54s
validate Ep 0, Sp 960, loss 0.754694, t print 10.294s, t batch 0.515s
validate Ep 0, Sp 1120, loss 0.782259, t print 19.403s, t batch 0.97s
validate Ep 0, Sp 1280, loss 0.764295, t print 10.566s, t batch 0.528s
validate Ep 0, Sp 1440, loss 0.745466, t print 10.457s, t batch 0.523s
validate Ep 0, Sp 1600, loss 0.7296, t print 20.132s, t batch 1.007s
validate Ep 0, Sp 1760, loss 0.740556, t print 10.492s, t batch 0.525s
validate Ep 0, Sp 1920, loss 0.71589, t print 10.725s, t batch 0.536s
validate Ep 0, Sp 2080, loss 0.747575, t print 19.929s, t batch 0.996s
validate Ep 0, Sp 2240, loss 0.723676, t print 10.571s, t batch 0.529s
validate Ep 0, Sp 2400, loss 0.747033, t print 10.601s, t batch 0.53s
  Epoch 0, Average Epoch loss = 0.8050771525796548
  Epoch 0, nr_of_updates 1296
current learning rate: 0.001
  Saving weights...
  Epoch 0, time total 1183.9483633041382s
  Epoch 0, time UNet: 170.91916632652283s
  Epoch 0, time metrics: 0.1121525764465332s
  Epoch 0, time saving files: 0.633049726486206s
2023-11-30 09:04:35.933828
Start looping batches...
train Ep 1, Sp 160, loss 0.701271, t print 1.653s, t batch 0.083s
train Ep 1, Sp 320, loss 0.753491, t print 11.34s, t batch 0.567s
train Ep 1, Sp 480, loss 0.728676, t print 11.768s, t batch 0.588s
train Ep 1, Sp 640, loss 0.728664, t print 11.709s, t batch 0.585s
train Ep 1, Sp 800, loss 0.727092, t print 21.009s, t batch 1.05s
train Ep 1, Sp 960, loss 0.728603, t print 11.635s, t batch 0.582s
train Ep 1, Sp 1120, loss 0.74404, t print 11.342s, t batch 0.567s
train Ep 1, Sp 1280, loss 0.697548, t print 20.724s, t batch 1.036s
train Ep 1, Sp 1440, loss 0.695379, t print 11.967s, t batch 0.598s
train Ep 1, Sp 1600, loss 0.742345, t print 11.313s, t batch 0.566s
train Ep 1, Sp 1760, loss 0.723174, t print 19.378s, t batch 0.969s
train Ep 1, Sp 1920, loss 0.768995, t print 12.917s, t batch 0.646s
train Ep 1, Sp 2080, loss 0.718772, t print 11.37s, t batch 0.568s
train Ep 1, Sp 2240, loss 0.727873, t print 16.634s, t batch 0.832s
train Ep 1, Sp 2400, loss 0.714242, t print 15.613s, t batch 0.781s
train Ep 1, Sp 2560, loss 0.703292, t print 11.188s, t batch 0.559s
train Ep 1, Sp 2720, loss 0.762506, t print 14.53s, t batch 0.727s
train Ep 1, Sp 2880, loss 0.736424, t print 17.466s, t batch 0.873s
train Ep 1, Sp 3040, loss 0.720096, t print 11.184s, t batch 0.559s
train Ep 1, Sp 3200, loss 0.71038, t print 12.302s, t batch 0.615s
train Ep 1, Sp 3360, loss 0.723132, t print 18.85s, t batch 0.942s
train Ep 1, Sp 3520, loss 0.770097, t print 10.896s, t batch 0.545s
train Ep 1, Sp 3680, loss 0.721748, t print 11.085s, t batch 0.554s
train Ep 1, Sp 3840, loss 0.716617, t print 20.562s, t batch 1.028s
train Ep 1, Sp 4000, loss 0.700841, t print 11.033s, t batch 0.552s
train Ep 1, Sp 4160, loss 0.708026, t print 11.012s, t batch 0.551s
train Ep 1, Sp 4320, loss 0.737271, t print 20.268s, t batch 1.013s
train Ep 1, Sp 4480, loss 0.758909, t print 11.03s, t batch 0.552s
train Ep 1, Sp 4640, loss 0.724459, t print 11.039s, t batch 0.552s
train Ep 1, Sp 4800, loss 0.706707, t print 20.292s, t batch 1.015s
train Ep 1, Sp 4960, loss 0.735683, t print 11.01s, t batch 0.55s
train Ep 1, Sp 5120, loss 0.711662, t print 10.993s, t batch 0.55s
train Ep 1, Sp 5280, loss 0.722446, t print 20.68s, t batch 1.034s
train Ep 1, Sp 5440, loss 0.7237, t print 11.057s, t batch 0.553s
train Ep 1, Sp 5600, loss 0.738018, t print 11.106s, t batch 0.555s
train Ep 1, Sp 5760, loss 0.718128, t print 20.744s, t batch 1.037s
train Ep 1, Sp 5920, loss 0.698567, t print 11.094s, t batch 0.555s
train Ep 1, Sp 6080, loss 0.741579, t print 11.071s, t batch 0.554s
train Ep 1, Sp 6240, loss 0.720668, t print 20.887s, t batch 1.044s
train Ep 1, Sp 6400, loss 0.729902, t print 11.108s, t batch 0.555s
train Ep 1, Sp 6560, loss 0.712931, t print 11.202s, t batch 0.56s
train Ep 1, Sp 6720, loss 0.746003, t print 20.817s, t batch 1.041s
train Ep 1, Sp 6880, loss 0.731882, t print 11.022s, t batch 0.551s
train Ep 1, Sp 7040, loss 0.734419, t print 11.137s, t batch 0.557s
train Ep 1, Sp 7200, loss 0.739619, t print 20.141s, t batch 1.007s
train Ep 1, Sp 7360, loss 0.72675, t print 10.876s, t batch 0.544s
train Ep 1, Sp 7520, loss 0.725749, t print 12.109s, t batch 0.605s
train Ep 1, Sp 7680, loss 0.702474, t print 18.169s, t batch 0.908s
train Ep 1, Sp 7840, loss 0.715179, t print 10.631s, t batch 0.532s
train Ep 1, Sp 8000, loss 0.72135, t print 14.05s, t batch 0.703s
train Ep 1, Sp 8160, loss 0.732707, t print 16.101s, t batch 0.805s
train Ep 1, Sp 8320, loss 0.716803, t print 10.673s, t batch 0.534s
train Ep 1, Sp 8480, loss 0.719683, t print 16.084s, t batch 0.804s
train Ep 1, Sp 8640, loss 0.727002, t print 14.129s, t batch 0.706s
train Ep 1, Sp 8800, loss 0.732321, t print 10.495s, t batch 0.525s
train Ep 1, Sp 8960, loss 0.729947, t print 17.998s, t batch 0.9s
train Ep 1, Sp 9120, loss 0.715185, t print 12.511s, t batch 0.626s
train Ep 1, Sp 9280, loss 0.706359, t print 10.985s, t batch 0.549s
train Ep 1, Sp 9440, loss 0.699647, t print 18.973s, t batch 0.949s
train Ep 1, Sp 9600, loss 0.73029, t print 12.712s, t batch 0.636s
train Ep 1, Sp 9760, loss 0.718378, t print 11.114s, t batch 0.556s
train Ep 1, Sp 9920, loss 0.724701, t print 17.244s, t batch 0.862s
train Ep 1, Sp 10080, loss 0.744412, t print 14.472s, t batch 0.724s
train Ep 1, Sp 10240, loss 0.727446, t print 10.996s, t batch 0.55s
Start looping batches...
validate Ep 1, Sp 160, loss 0.681191, t print 0.982s, t batch 0.049s
validate Ep 1, Sp 320, loss 0.715858, t print 636.346s, t batch 31.817s
validate Ep 1, Sp 480, loss 0.726421, t print 12.429s, t batch 0.621s
validate Ep 1, Sp 640, loss 0.719004, t print 11.742s, t batch 0.587s
validate Ep 1, Sp 800, loss 0.695113, t print 19.787s, t batch 0.989s
validate Ep 1, Sp 960, loss 0.700571, t print 10.645s, t batch 0.532s
validate Ep 1, Sp 1120, loss 0.717423, t print 10.984s, t batch 0.549s
validate Ep 1, Sp 1280, loss 0.749027, t print 19.821s, t batch 0.991s
validate Ep 1, Sp 1440, loss 0.668362, t print 11.391s, t batch 0.57s
validate Ep 1, Sp 1600, loss 0.733254, t print 10.776s, t batch 0.539s
validate Ep 1, Sp 1760, loss 0.730351, t print 19.245s, t batch 0.962s
validate Ep 1, Sp 1920, loss 0.732353, t print 12.357s, t batch 0.618s
validate Ep 1, Sp 2080, loss 0.725265, t print 10.938s, t batch 0.547s
validate Ep 1, Sp 2240, loss 0.697399, t print 18.02s, t batch 0.901s
validate Ep 1, Sp 2400, loss 0.701352, t print 12.581s, t batch 0.629s
  Epoch 1, Average Epoch loss = 0.7247626115510493
  Epoch 1, nr_of_updates 2592
current learning rate: 0.001
  Saving weights...
  Epoch 1, time total 1718.0236418247223s
  Epoch 1, time UNet: 123.87545657157898s
  Epoch 1, time metrics: 0.1112833023071289s
  Epoch 1, time saving files: 0.35461974143981934s
2023-11-30 09:33:13.965548
Start looping batches...
train Ep 2, Sp 160, loss 0.692662, t print 1.747s, t batch 0.087s
train Ep 2, Sp 320, loss 0.700136, t print 10.921s, t batch 0.546s
train Ep 2, Sp 480, loss 0.71154, t print 13.361s, t batch 0.668s
train Ep 2, Sp 640, loss 0.710818, t print 11.563s, t batch 0.578s
train Ep 2, Sp 800, loss 0.730993, t print 19.942s, t batch 0.997s
train Ep 2, Sp 960, loss 0.723995, t print 13.312s, t batch 0.666s
train Ep 2, Sp 1120, loss 0.709106, t print 11.473s, t batch 0.574s
train Ep 2, Sp 1280, loss 0.708355, t print 18.144s, t batch 0.907s
train Ep 2, Sp 1440, loss 0.69801, t print 14.829s, t batch 0.741s
train Ep 2, Sp 1600, loss 0.703734, t print 11.181s, t batch 0.559s
train Ep 2, Sp 1760, loss 0.677779, t print 15.775s, t batch 0.789s
train Ep 2, Sp 1920, loss 0.740535, t print 16.16s, t batch 0.808s
train Ep 2, Sp 2080, loss 0.71139, t print 11.925s, t batch 0.596s
train Ep 2, Sp 2240, loss 0.706057, t print 13.441s, t batch 0.672s
train Ep 2, Sp 2400, loss 0.723539, t print 17.496s, t batch 0.875s
train Ep 2, Sp 2560, loss 0.732355, t print 11.336s, t batch 0.567s
train Ep 2, Sp 2720, loss 0.686577, t print 13.209s, t batch 0.66s
train Ep 2, Sp 2880, loss 0.725601, t print 18.536s, t batch 0.927s
train Ep 2, Sp 3040, loss 0.716431, t print 11.281s, t batch 0.564s
train Ep 2, Sp 3200, loss 0.713872, t print 12.046s, t batch 0.602s
train Ep 2, Sp 3360, loss 0.724873, t print 19.557s, t batch 0.978s
train Ep 2, Sp 3520, loss 0.741249, t print 10.99s, t batch 0.549s
train Ep 2, Sp 3680, loss 0.723459, t print 11.229s, t batch 0.561s
train Ep 2, Sp 3840, loss 0.719713, t print 20.718s, t batch 1.036s
train Ep 2, Sp 4000, loss 0.703663, t print 11.095s, t batch 0.555s
train Ep 2, Sp 4160, loss 0.717232, t print 11.203s, t batch 0.56s
train Ep 2, Sp 4320, loss 0.718692, t print 20.712s, t batch 1.036s
train Ep 2, Sp 4480, loss 0.710559, t print 11.12s, t batch 0.556s
train Ep 2, Sp 4640, loss 0.707642, t print 10.989s, t batch 0.549s
train Ep 2, Sp 4800, loss 0.688655, t print 20.546s, t batch 1.027s
train Ep 2, Sp 4960, loss 0.722392, t print 11.118s, t batch 0.556s
train Ep 2, Sp 5120, loss 0.689634, t print 11.372s, t batch 0.569s
train Ep 2, Sp 5280, loss 0.701808, t print 20.526s, t batch 1.026s
train Ep 2, Sp 5440, loss 0.717855, t print 11.757s, t batch 0.588s
train Ep 2, Sp 5600, loss 0.710094, t print 11.125s, t batch 0.556s
train Ep 2, Sp 5760, loss 0.708053, t print 20.568s, t batch 1.028s
train Ep 2, Sp 5920, loss 0.697083, t print 11.416s, t batch 0.571s
train Ep 2, Sp 6080, loss 0.740266, t print 11.297s, t batch 0.565s
train Ep 2, Sp 6240, loss 0.708649, t print 21.156s, t batch 1.058s
train Ep 2, Sp 6400, loss 0.719706, t print 11.374s, t batch 0.569s
train Ep 2, Sp 6560, loss 0.741681, t print 11.424s, t batch 0.571s
train Ep 2, Sp 6720, loss 0.694997, t print 21.144s, t batch 1.057s
train Ep 2, Sp 6880, loss 0.722484, t print 11.309s, t batch 0.565s
train Ep 2, Sp 7040, loss 0.722662, t print 11.282s, t batch 0.564s
train Ep 2, Sp 7200, loss 0.71058, t print 21.111s, t batch 1.056s
train Ep 2, Sp 7360, loss 0.716077, t print 11.231s, t batch 0.562s
train Ep 2, Sp 7520, loss 0.711791, t print 11.324s, t batch 0.566s
train Ep 2, Sp 7680, loss 0.693259, t print 20.84s, t batch 1.042s
train Ep 2, Sp 7840, loss 0.725708, t print 11.182s, t batch 0.559s
train Ep 2, Sp 8000, loss 0.728024, t print 11.327s, t batch 0.566s
train Ep 2, Sp 8160, loss 0.698167, t print 21.222s, t batch 1.061s
train Ep 2, Sp 8320, loss 0.657616, t print 11.622s, t batch 0.581s
train Ep 2, Sp 8480, loss 0.713079, t print 11.421s, t batch 0.571s
train Ep 2, Sp 8640, loss 0.699834, t print 21.286s, t batch 1.064s
train Ep 2, Sp 8800, loss 0.711981, t print 11.281s, t batch 0.564s
train Ep 2, Sp 8960, loss 0.724287, t print 11.302s, t batch 0.565s
train Ep 2, Sp 9120, loss 0.725999, t print 21.421s, t batch 1.071s
train Ep 2, Sp 9280, loss 0.69361, t print 11.378s, t batch 0.569s
train Ep 2, Sp 9440, loss 0.687356, t print 11.234s, t batch 0.562s
train Ep 2, Sp 9600, loss 0.711937, t print 20.194s, t batch 1.01s
train Ep 2, Sp 9760, loss 0.7246, t print 10.83s, t batch 0.542s
train Ep 2, Sp 9920, loss 0.710064, t print 10.981s, t batch 0.549s
train Ep 2, Sp 10080, loss 0.68597, t print 20.294s, t batch 1.015s
train Ep 2, Sp 10240, loss 0.720443, t print 11.02s, t batch 0.551s
Start looping batches...
validate Ep 2, Sp 160, loss 0.754893, t print 1.04s, t batch 0.052s
validate Ep 2, Sp 320, loss 0.675489, t print 12.888s, t batch 0.644s
validate Ep 2, Sp 480, loss 0.706461, t print 12.145s, t batch 0.607s
validate Ep 2, Sp 640, loss 0.658615, t print 10.83s, t batch 0.541s
validate Ep 2, Sp 800, loss 0.734787, t print 20.362s, t batch 1.018s
validate Ep 2, Sp 960, loss 0.727953, t print 10.91s, t batch 0.545s
validate Ep 2, Sp 1120, loss 0.716339, t print 10.943s, t batch 0.547s
validate Ep 2, Sp 1280, loss 0.70516, t print 20.726s, t batch 1.036s
validate Ep 2, Sp 1440, loss 0.681228, t print 10.656s, t batch 0.533s
validate Ep 2, Sp 1600, loss 0.693444, t print 10.616s, t batch 0.531s
validate Ep 2, Sp 1760, loss 0.690663, t print 19.971s, t batch 0.999s
validate Ep 2, Sp 1920, loss 0.706937, t print 10.561s, t batch 0.528s
validate Ep 2, Sp 2080, loss 0.713624, t print 10.837s, t batch 0.542s
validate Ep 2, Sp 2240, loss 0.660619, t print 20.722s, t batch 1.036s
validate Ep 2, Sp 2400, loss 0.741619, t print 10.78s, t batch 0.539s
  Epoch 2, Average Epoch loss = 0.7113390761301105
  Epoch 2, nr_of_updates 3888
current learning rate: 0.001
  Saving weights...
  Epoch 2, time total 1111.057736158371s
  Epoch 2, time UNet: 122.47499442100525s
  Epoch 2, time metrics: 0.11654448509216309s
  Epoch 2, time saving files: 0.4115152359008789s
2023-11-30 09:51:45.031536
Start looping batches...
train Ep 3, Sp 160, loss 0.697079, t print 1.605s, t batch 0.08s
train Ep 3, Sp 320, loss 0.730187, t print 10.989s, t batch 0.549s
train Ep 3, Sp 480, loss 0.698088, t print 13.432s, t batch 0.672s
train Ep 3, Sp 640, loss 0.694808, t print 11.332s, t batch 0.567s
train Ep 3, Sp 800, loss 0.700696, t print 19.762s, t batch 0.988s
train Ep 3, Sp 960, loss 0.721085, t print 12.248s, t batch 0.612s
train Ep 3, Sp 1120, loss 0.701574, t print 12.003s, t batch 0.6s
train Ep 3, Sp 1280, loss 0.697278, t print 17.626s, t batch 0.881s
train Ep 3, Sp 1440, loss 0.678561, t print 13.096s, t batch 0.655s
train Ep 3, Sp 1600, loss 0.727446, t print 13.239s, t batch 0.662s
train Ep 3, Sp 1760, loss 0.710718, t print 14.721s, t batch 0.736s
train Ep 3, Sp 1920, loss 0.691922, t print 14.553s, t batch 0.728s
train Ep 3, Sp 2080, loss 0.694118, t print 14.281s, t batch 0.714s
train Ep 3, Sp 2240, loss 0.694357, t print 13.132s, t batch 0.657s
train Ep 3, Sp 2400, loss 0.72496, t print 14.964s, t batch 0.748s
train Ep 3, Sp 2560, loss 0.720527, t print 15.47s, t batch 0.773s
train Ep 3, Sp 2720, loss 0.733946, t print 11.722s, t batch 0.586s
train Ep 3, Sp 2880, loss 0.714222, t print 15.303s, t batch 0.765s
train Ep 3, Sp 3040, loss 0.726366, t print 16.617s, t batch 0.831s
train Ep 3, Sp 3200, loss 0.705358, t print 11.455s, t batch 0.573s
train Ep 3, Sp 3360, loss 0.714643, t print 14.119s, t batch 0.706s
train Ep 3, Sp 3520, loss 0.697164, t print 18.514s, t batch 0.926s
train Ep 3, Sp 3680, loss 0.72507, t print 11.389s, t batch 0.569s
train Ep 3, Sp 3840, loss 0.719199, t print 12.347s, t batch 0.617s
train Ep 3, Sp 4000, loss 0.697959, t print 19.847s, t batch 0.992s
train Ep 3, Sp 4160, loss 0.687842, t print 11.477s, t batch 0.574s
train Ep 3, Sp 4320, loss 0.718483, t print 11.339s, t batch 0.567s
train Ep 3, Sp 4480, loss 0.701945, t print 21.181s, t batch 1.059s
train Ep 3, Sp 4640, loss 0.670066, t print 11.374s, t batch 0.569s
train Ep 3, Sp 4800, loss 0.692638, t print 11.341s, t batch 0.567s
train Ep 3, Sp 4960, loss 0.69835, t print 21.016s, t batch 1.051s
train Ep 3, Sp 5120, loss 0.712489, t print 11.271s, t batch 0.564s
train Ep 3, Sp 5280, loss 0.689417, t print 11.381s, t batch 0.569s
train Ep 3, Sp 5440, loss 0.677333, t print 20.89s, t batch 1.045s
train Ep 3, Sp 5600, loss 0.702324, t print 11.437s, t batch 0.572s
train Ep 3, Sp 5760, loss 0.75148, t print 11.472s, t batch 0.574s
train Ep 3, Sp 5920, loss 0.715779, t print 20.867s, t batch 1.043s
train Ep 3, Sp 6080, loss 0.721499, t print 11.102s, t batch 0.555s
train Ep 3, Sp 6240, loss 0.716081, t print 11.063s, t batch 0.553s
train Ep 3, Sp 6400, loss 0.719056, t print 20.625s, t batch 1.031s
train Ep 3, Sp 6560, loss 0.762405, t print 11.24s, t batch 0.562s
train Ep 3, Sp 6720, loss 0.721901, t print 11.051s, t batch 0.553s
train Ep 3, Sp 6880, loss 0.664845, t print 20.544s, t batch 1.027s
train Ep 3, Sp 7040, loss 0.707401, t print 11.363s, t batch 0.568s
train Ep 3, Sp 7200, loss 0.697481, t print 11.165s, t batch 0.558s
train Ep 3, Sp 7360, loss 0.704742, t print 20.133s, t batch 1.007s
train Ep 3, Sp 7520, loss 0.710111, t print 11.65s, t batch 0.583s
train Ep 3, Sp 7680, loss 0.701983, t print 11.287s, t batch 0.564s
train Ep 3, Sp 7840, loss 0.685449, t print 19.499s, t batch 0.975s
train Ep 3, Sp 8000, loss 0.720571, t print 12.332s, t batch 0.617s
train Ep 3, Sp 8160, loss 0.733644, t print 11.208s, t batch 0.56s
train Ep 3, Sp 8320, loss 0.712301, t print 18.269s, t batch 0.913s
train Ep 3, Sp 8480, loss 0.730306, t print 13.488s, t batch 0.674s
train Ep 3, Sp 8640, loss 0.692876, t print 11.166s, t batch 0.558s
train Ep 3, Sp 8800, loss 0.744285, t print 17.016s, t batch 0.851s
train Ep 3, Sp 8960, loss 0.661555, t print 15.146s, t batch 0.757s
train Ep 3, Sp 9120, loss 0.701245, t print 11.148s, t batch 0.557s
train Ep 3, Sp 9280, loss 0.701697, t print 15.708s, t batch 0.785s
train Ep 3, Sp 9440, loss 0.693468, t print 16.453s, t batch 0.823s
train Ep 3, Sp 9600, loss 0.704146, t print 11.228s, t batch 0.561s
train Ep 3, Sp 9760, loss 0.68493, t print 13.927s, t batch 0.696s
train Ep 3, Sp 9920, loss 0.681537, t print 18.254s, t batch 0.913s
train Ep 3, Sp 10080, loss 0.72989, t print 11.3s, t batch 0.565s
train Ep 3, Sp 10240, loss 0.693383, t print 12.06s, t batch 0.603s
Start looping batches...
validate Ep 3, Sp 160, loss 0.693075, t print 1.005s, t batch 0.05s
validate Ep 3, Sp 320, loss 0.698801, t print 2558.197s, t batch 127.91s
validate Ep 3, Sp 480, loss 0.672007, t print 11.294s, t batch 0.565s
validate Ep 3, Sp 640, loss 0.701843, t print 11.248s, t batch 0.562s
validate Ep 3, Sp 800, loss 0.702841, t print 21.112s, t batch 1.056s
validate Ep 3, Sp 960, loss 0.719286, t print 11.513s, t batch 0.576s
validate Ep 3, Sp 1120, loss 0.719192, t print 10.983s, t batch 0.549s
validate Ep 3, Sp 1280, loss 0.697207, t print 20.136s, t batch 1.007s
validate Ep 3, Sp 1440, loss 0.736816, t print 11.526s, t batch 0.576s
validate Ep 3, Sp 1600, loss 0.727207, t print 10.745s, t batch 0.537s
validate Ep 3, Sp 1760, loss 0.660714, t print 18.801s, t batch 0.94s
validate Ep 3, Sp 1920, loss 0.70592, t print 12.087s, t batch 0.604s
validate Ep 3, Sp 2080, loss 0.674917, t print 10.557s, t batch 0.528s
validate Ep 3, Sp 2240, loss 0.663566, t print 18.604s, t batch 0.93s
validate Ep 3, Sp 2400, loss 0.745071, t print 12.089s, t batch 0.604s
  Epoch 3, Average Epoch loss = 0.7067565060232157
  Epoch 3, nr_of_updates 5184
current learning rate: 0.001
  Saving weights...
  Epoch 3, time total 3659.1768486499786s
  Epoch 3, time UNet: 124.52929306030273s
  Epoch 3, time metrics: 0.1132040023803711s
  Epoch 3, time saving files: 0.3991682529449463s
2023-11-30 10:52:44.216186
Start looping batches...
train Ep 4, Sp 160, loss 0.692344, t print 2.031s, t batch 0.102s
train Ep 4, Sp 320, loss 0.7235, t print 11.164s, t batch 0.558s
train Ep 4, Sp 480, loss 0.724189, t print 13.208s, t batch 0.66s
train Ep 4, Sp 640, loss 0.700862, t print 11.559s, t batch 0.578s
train Ep 4, Sp 800, loss 0.63995, t print 20.344s, t batch 1.017s
train Ep 4, Sp 960, loss 0.711723, t print 12.592s, t batch 0.63s
train Ep 4, Sp 1120, loss 0.702026, t print 11.94s, t batch 0.597s
train Ep 4, Sp 1280, loss 0.681804, t print 17.04s, t batch 0.852s
train Ep 4, Sp 1440, loss 0.675651, t print 15.165s, t batch 0.758s
train Ep 4, Sp 1600, loss 0.734692, t print 11.232s, t batch 0.562s
train Ep 4, Sp 1760, loss 0.693075, t print 15.073s, t batch 0.754s
train Ep 4, Sp 1920, loss 0.720362, t print 17.754s, t batch 0.888s
train Ep 4, Sp 2080, loss 0.669094, t print 11.345s, t batch 0.567s
train Ep 4, Sp 2240, loss 0.714561, t print 12.219s, t batch 0.611s
train Ep 4, Sp 2400, loss 0.704508, t print 20.471s, t batch 1.024s
train Ep 4, Sp 2560, loss 0.722061, t print 11.438s, t batch 0.572s
train Ep 4, Sp 2720, loss 0.688974, t print 11.355s, t batch 0.568s
train Ep 4, Sp 2880, loss 0.693769, t print 21.18s, t batch 1.059s
train Ep 4, Sp 3040, loss 0.712919, t print 11.513s, t batch 0.576s
train Ep 4, Sp 3200, loss 0.745832, t print 11.367s, t batch 0.568s
train Ep 4, Sp 3360, loss 0.669019, t print 20.871s, t batch 1.044s
train Ep 4, Sp 3520, loss 0.718429, t print 11.297s, t batch 0.565s
train Ep 4, Sp 3680, loss 0.684942, t print 11.333s, t batch 0.567s
train Ep 4, Sp 3840, loss 0.70496, t print 21.122s, t batch 1.056s
train Ep 4, Sp 4000, loss 0.689315, t print 11.442s, t batch 0.572s
train Ep 4, Sp 4160, loss 0.716572, t print 11.384s, t batch 0.569s
train Ep 4, Sp 4320, loss 0.688753, t print 21.15s, t batch 1.057s
train Ep 4, Sp 4480, loss 0.701466, t print 11.473s, t batch 0.574s
train Ep 4, Sp 4640, loss 0.708999, t print 11.4s, t batch 0.57s
train Ep 4, Sp 4800, loss 0.714443, t print 21.186s, t batch 1.059s
train Ep 4, Sp 4960, loss 0.689277, t print 11.318s, t batch 0.566s
train Ep 4, Sp 5120, loss 0.734061, t print 11.309s, t batch 0.565s
train Ep 4, Sp 5280, loss 0.666232, t print 20.936s, t batch 1.047s
train Ep 4, Sp 5440, loss 0.672933, t print 11.344s, t batch 0.567s
train Ep 4, Sp 5600, loss 0.730534, t print 11.272s, t batch 0.564s
train Ep 4, Sp 5760, loss 0.664032, t print 20.873s, t batch 1.044s
train Ep 4, Sp 5920, loss 0.689123, t print 11.275s, t batch 0.564s
train Ep 4, Sp 6080, loss 0.733166, t print 11.075s, t batch 0.554s
train Ep 4, Sp 6240, loss 0.716082, t print 20.773s, t batch 1.039s
train Ep 4, Sp 6400, loss 0.729462, t print 11.135s, t batch 0.557s
train Ep 4, Sp 6560, loss 0.697906, t print 11.197s, t batch 0.56s
train Ep 4, Sp 6720, loss 0.710295, t print 20.689s, t batch 1.034s
train Ep 4, Sp 6880, loss 0.703615, t print 11.354s, t batch 0.568s
train Ep 4, Sp 7040, loss 0.699129, t print 11.155s, t batch 0.558s
train Ep 4, Sp 7200, loss 0.676488, t print 20.811s, t batch 1.041s
train Ep 4, Sp 7360, loss 0.709742, t print 11.247s, t batch 0.562s
train Ep 4, Sp 7520, loss 0.718923, t print 11.08s, t batch 0.554s
train Ep 4, Sp 7680, loss 0.682158, t print 20.973s, t batch 1.049s
train Ep 4, Sp 7840, loss 0.70612, t print 11.263s, t batch 0.563s
train Ep 4, Sp 8000, loss 0.711289, t print 11.305s, t batch 0.565s
train Ep 4, Sp 8160, loss 0.699204, t print 21.088s, t batch 1.054s
train Ep 4, Sp 8320, loss 0.734894, t print 11.452s, t batch 0.573s
train Ep 4, Sp 8480, loss 0.697955, t print 11.475s, t batch 0.574s
train Ep 4, Sp 8640, loss 0.676133, t print 21.218s, t batch 1.061s
train Ep 4, Sp 8800, loss 0.714294, t print 11.307s, t batch 0.565s
train Ep 4, Sp 8960, loss 0.684681, t print 11.452s, t batch 0.573s
train Ep 4, Sp 9120, loss 0.688309, t print 21.28s, t batch 1.064s
train Ep 4, Sp 9280, loss 0.66886, t print 11.552s, t batch 0.578s
train Ep 4, Sp 9440, loss 0.711476, t print 11.452s, t batch 0.573s
train Ep 4, Sp 9600, loss 0.661576, t print 21.471s, t batch 1.074s
train Ep 4, Sp 9760, loss 0.717174, t print 11.609s, t batch 0.58s
train Ep 4, Sp 9920, loss 0.727441, t print 11.468s, t batch 0.573s
train Ep 4, Sp 10080, loss 0.692195, t print 21.439s, t batch 1.072s
train Ep 4, Sp 10240, loss 0.687301, t print 11.54s, t batch 0.577s
Start looping batches...
validate Ep 4, Sp 160, loss 0.69072, t print 1.028s, t batch 0.051s
validate Ep 4, Sp 320, loss 0.715511, t print 1760.547s, t batch 88.027s
validate Ep 4, Sp 480, loss 0.686474, t print 7.342s, t batch 0.367s
validate Ep 4, Sp 640, loss 0.688683, t print 10.916s, t batch 0.546s
validate Ep 4, Sp 800, loss 0.641219, t print 20.963s, t batch 1.048s
validate Ep 4, Sp 960, loss 0.732314, t print 10.733s, t batch 0.537s
validate Ep 4, Sp 1120, loss 0.693568, t print 10.675s, t batch 0.534s
validate Ep 4, Sp 1280, loss 0.711892, t print 20.473s, t batch 1.024s
validate Ep 4, Sp 1440, loss 0.678203, t print 10.697s, t batch 0.535s
validate Ep 4, Sp 1600, loss 0.694044, t print 10.712s, t batch 0.536s
validate Ep 4, Sp 1760, loss 0.667608, t print 20.393s, t batch 1.02s
validate Ep 4, Sp 1920, loss 0.687871, t print 10.964s, t batch 0.548s
validate Ep 4, Sp 2080, loss 0.678334, t print 10.744s, t batch 0.537s
validate Ep 4, Sp 2240, loss 0.718545, t print 20.284s, t batch 1.014s
validate Ep 4, Sp 2400, loss 0.706161, t print 10.741s, t batch 0.537s
  Epoch 4, Average Epoch loss = 0.7013746727211976
  Epoch 4, nr_of_updates 6480
current learning rate: 0.001
  Saving weights...
  Epoch 4, time total 2865.420699596405s
  Epoch 4, time UNet: 126.96483588218689s
  Epoch 4, time metrics: 0.11760902404785156s
  Epoch 4, time saving files: 0.9056806564331055s
2023-11-30 11:40:29.644714
Start looping batches...
train Ep 5, Sp 160, loss 0.690269, t print 5.158s, t batch 0.258s
train Ep 5, Sp 320, loss 0.710006, t print 10.928s, t batch 0.546s
train Ep 5, Sp 480, loss 0.707578, t print 12.872s, t batch 0.644s
train Ep 5, Sp 640, loss 0.672683, t print 11.921s, t batch 0.596s
train Ep 5, Sp 800, loss 0.73975, t print 18.262s, t batch 0.913s
train Ep 5, Sp 960, loss 0.716651, t print 14.108s, t batch 0.705s
train Ep 5, Sp 1120, loss 0.667216, t print 11.272s, t batch 0.564s
train Ep 5, Sp 1280, loss 0.668941, t print 15.27s, t batch 0.764s
train Ep 5, Sp 1440, loss 0.680089, t print 16.71s, t batch 0.835s
train Ep 5, Sp 1600, loss 0.65371, t print 11.496s, t batch 0.575s
train Ep 5, Sp 1760, loss 0.690128, t print 12.406s, t batch 0.62s
train Ep 5, Sp 1920, loss 0.690169, t print 20.542s, t batch 1.027s
train Ep 5, Sp 2080, loss 0.667016, t print 11.328s, t batch 0.566s
train Ep 5, Sp 2240, loss 0.693447, t print 11.344s, t batch 0.567s
train Ep 5, Sp 2400, loss 0.705363, t print 20.877s, t batch 1.044s
train Ep 5, Sp 2560, loss 0.706341, t print 11.621s, t batch 0.581s
train Ep 5, Sp 2720, loss 0.691751, t print 11.379s, t batch 0.569s
train Ep 5, Sp 2880, loss 0.699866, t print 19.997s, t batch 1.0s
train Ep 5, Sp 3040, loss 0.701396, t print 12.347s, t batch 0.617s
train Ep 5, Sp 3200, loss 0.709353, t print 11.313s, t batch 0.566s
train Ep 5, Sp 3360, loss 0.679188, t print 17.706s, t batch 0.885s
train Ep 5, Sp 3520, loss 0.693081, t print 14.236s, t batch 0.712s
train Ep 5, Sp 3680, loss 0.694173, t print 11.292s, t batch 0.565s
train Ep 5, Sp 3840, loss 0.708668, t print 16.549s, t batch 0.827s
train Ep 5, Sp 4000, loss 0.698123, t print 15.486s, t batch 0.774s
train Ep 5, Sp 4160, loss 0.693804, t print 11.289s, t batch 0.564s
train Ep 5, Sp 4320, loss 0.673637, t print 15.291s, t batch 0.765s
train Ep 5, Sp 4480, loss 0.643503, t print 16.455s, t batch 0.823s
train Ep 5, Sp 4640, loss 0.71416, t print 10.931s, t batch 0.547s
train Ep 5, Sp 4800, loss 0.688986, t print 14.844s, t batch 0.742s
train Ep 5, Sp 4960, loss 0.677217, t print 16.504s, t batch 0.825s
train Ep 5, Sp 5120, loss 0.68419, t print 11.228s, t batch 0.561s
train Ep 5, Sp 5280, loss 0.658163, t print 14.593s, t batch 0.73s
train Ep 5, Sp 5440, loss 0.736443, t print 16.505s, t batch 0.825s
train Ep 5, Sp 5600, loss 0.655682, t print 11.308s, t batch 0.565s
train Ep 5, Sp 5760, loss 0.671816, t print 14.098s, t batch 0.705s
train Ep 5, Sp 5920, loss 0.664451, t print 16.963s, t batch 0.848s
train Ep 5, Sp 6080, loss 0.684436, t print 11.201s, t batch 0.56s
train Ep 5, Sp 6240, loss 0.713601, t print 13.755s, t batch 0.688s
train Ep 5, Sp 6400, loss 0.702173, t print 17.294s, t batch 0.865s
train Ep 5, Sp 6560, loss 0.707978, t print 11.463s, t batch 0.573s
train Ep 5, Sp 6720, loss 0.651865, t print 13.001s, t batch 0.65s
train Ep 5, Sp 6880, loss 0.702758, t print 18.261s, t batch 0.913s
train Ep 5, Sp 7040, loss 0.656473, t print 11.502s, t batch 0.575s
train Ep 5, Sp 7200, loss 0.699875, t print 12.254s, t batch 0.613s
train Ep 5, Sp 7360, loss 0.70951, t print 18.887s, t batch 0.944s
train Ep 5, Sp 7520, loss 0.714576, t print 12.145s, t batch 0.607s
train Ep 5, Sp 7680, loss 0.682181, t print 11.431s, t batch 0.572s
train Ep 5, Sp 7840, loss 0.674964, t print 18.399s, t batch 0.92s
train Ep 5, Sp 8000, loss 0.665652, t print 13.404s, t batch 0.67s
train Ep 5, Sp 8160, loss 0.663469, t print 11.16s, t batch 0.558s
train Ep 5, Sp 8320, loss 0.709852, t print 17.507s, t batch 0.875s
train Ep 5, Sp 8480, loss 0.729724, t print 14.862s, t batch 0.743s
train Ep 5, Sp 8640, loss 0.662455, t print 11.154s, t batch 0.558s
train Ep 5, Sp 8800, loss 0.679216, t print 16.3s, t batch 0.815s
train Ep 5, Sp 8960, loss 0.646713, t print 15.706s, t batch 0.785s
train Ep 5, Sp 9120, loss 0.702457, t print 11.064s, t batch 0.553s
train Ep 5, Sp 9280, loss 0.693955, t print 15.075s, t batch 0.754s
train Ep 5, Sp 9440, loss 0.683928, t print 16.39s, t batch 0.82s
train Ep 5, Sp 9600, loss 0.662778, t print 11.107s, t batch 0.555s
train Ep 5, Sp 9760, loss 0.6749, t print 14.228s, t batch 0.711s
train Ep 5, Sp 9920, loss 0.734299, t print 17.504s, t batch 0.875s
train Ep 5, Sp 10080, loss 0.729145, t print 11.124s, t batch 0.556s
train Ep 5, Sp 10240, loss 0.671168, t print 13.278s, t batch 0.664s
Start looping batches...
validate Ep 5, Sp 160, loss 0.693926, t print 0.983s, t batch 0.049s
validate Ep 5, Sp 320, loss 0.689247, t print 11.696s, t batch 0.585s
validate Ep 5, Sp 480, loss 0.678109, t print 12.064s, t batch 0.603s
validate Ep 5, Sp 640, loss 0.710526, t print 11.404s, t batch 0.57s
validate Ep 5, Sp 800, loss 0.693995, t print 20.204s, t batch 1.01s
validate Ep 5, Sp 960, loss 0.694143, t print 11.042s, t batch 0.552s
validate Ep 5, Sp 1120, loss 0.721495, t print 10.956s, t batch 0.548s
validate Ep 5, Sp 1280, loss 0.699154, t print 20.007s, t batch 1.0s
validate Ep 5, Sp 1440, loss 0.697909, t print 10.804s, t batch 0.54s
validate Ep 5, Sp 1600, loss 0.678, t print 11.068s, t batch 0.553s
validate Ep 5, Sp 1760, loss 0.72374, t print 19.805s, t batch 0.99s
validate Ep 5, Sp 1920, loss 0.685007, t print 10.709s, t batch 0.535s
validate Ep 5, Sp 2080, loss 0.725533, t print 10.806s, t batch 0.54s
validate Ep 5, Sp 2240, loss 0.701448, t print 19.554s, t batch 0.978s
validate Ep 5, Sp 2400, loss 0.722789, t print 11.026s, t batch 0.551s
  Epoch 5, Average Epoch loss = 0.6897592514201447
  Epoch 5, nr_of_updates 7776
current learning rate: 0.001
  Epoch 5, time total 1099.9129092693329s
  Epoch 5, time UNet: 129.0620744228363s
  Epoch 5, time metrics: 0.1261582374572754s
  Epoch 5, time saving files: 0.00020933151245117188s
2023-11-30 11:58:49.566233
Start looping batches...
train Ep 6, Sp 160, loss 0.713023, t print 1.632s, t batch 0.082s
train Ep 6, Sp 320, loss 0.686912, t print 11.32s, t batch 0.566s
train Ep 6, Sp 480, loss 0.646744, t print 12.627s, t batch 0.631s
train Ep 6, Sp 640, loss 0.664844, t print 12.153s, t batch 0.608s
train Ep 6, Sp 800, loss 0.678848, t print 20.047s, t batch 1.002s
train Ep 6, Sp 960, loss 0.699122, t print 14.093s, t batch 0.705s
train Ep 6, Sp 1120, loss 0.668871, t print 11.893s, t batch 0.595s
train Ep 6, Sp 1280, loss 0.698892, t print 17.363s, t batch 0.868s
train Ep 6, Sp 1440, loss 0.707778, t print 16.408s, t batch 0.82s
train Ep 6, Sp 1600, loss 0.685567, t print 11.928s, t batch 0.596s
train Ep 6, Sp 1760, loss 0.691961, t print 14.454s, t batch 0.723s
train Ep 6, Sp 1920, loss 0.705479, t print 19.102s, t batch 0.955s
train Ep 6, Sp 2080, loss 0.673754, t print 11.688s, t batch 0.584s
train Ep 6, Sp 2240, loss 0.69788, t print 12.036s, t batch 0.602s
train Ep 6, Sp 2400, loss 0.677652, t print 21.555s, t batch 1.078s
train Ep 6, Sp 2560, loss 0.71197, t print 11.584s, t batch 0.579s
train Ep 6, Sp 2720, loss 0.684042, t print 11.464s, t batch 0.573s
train Ep 6, Sp 2880, loss 0.688796, t print 21.33s, t batch 1.066s
train Ep 6, Sp 3040, loss 0.732324, t print 11.504s, t batch 0.575s
train Ep 6, Sp 3200, loss 0.690834, t print 11.448s, t batch 0.572s
train Ep 6, Sp 3360, loss 0.670668, t print 21.475s, t batch 1.074s
train Ep 6, Sp 3520, loss 0.684925, t print 11.59s, t batch 0.58s
train Ep 6, Sp 3680, loss 0.728687, t print 11.151s, t batch 0.558s
train Ep 6, Sp 3840, loss 0.687503, t print 21.032s, t batch 1.052s
train Ep 6, Sp 4000, loss 0.688236, t print 11.508s, t batch 0.575s
train Ep 6, Sp 4160, loss 0.711532, t print 11.504s, t batch 0.575s
train Ep 6, Sp 4320, loss 0.692249, t print 21.103s, t batch 1.055s
train Ep 6, Sp 4480, loss 0.685207, t print 11.603s, t batch 0.58s
train Ep 6, Sp 4640, loss 0.682987, t print 11.625s, t batch 0.581s
train Ep 6, Sp 4800, loss 0.741963, t print 19.545s, t batch 0.977s
train Ep 6, Sp 4960, loss 0.669148, t print 12.828s, t batch 0.641s
train Ep 6, Sp 5120, loss 0.693927, t print 11.053s, t batch 0.553s
train Ep 6, Sp 5280, loss 0.695111, t print 18.657s, t batch 0.933s
train Ep 6, Sp 5440, loss 0.672683, t print 13.592s, t batch 0.68s
train Ep 6, Sp 5600, loss 0.698742, t print 11.384s, t batch 0.569s
train Ep 6, Sp 5760, loss 0.721488, t print 16.867s, t batch 0.843s
train Ep 6, Sp 5920, loss 0.675472, t print 15.373s, t batch 0.769s
train Ep 6, Sp 6080, loss 0.700544, t print 10.853s, t batch 0.543s
train Ep 6, Sp 6240, loss 0.675344, t print 16.323s, t batch 0.816s
train Ep 6, Sp 6400, loss 0.698026, t print 15.429s, t batch 0.771s
train Ep 6, Sp 6560, loss 0.678271, t print 11.349s, t batch 0.567s
train Ep 6, Sp 6720, loss 0.687078, t print 15.085s, t batch 0.754s
train Ep 6, Sp 6880, loss 0.710196, t print 16.569s, t batch 0.828s
train Ep 6, Sp 7040, loss 0.678666, t print 11.318s, t batch 0.566s
train Ep 6, Sp 7200, loss 0.685277, t print 14.311s, t batch 0.716s
train Ep 6, Sp 7360, loss 0.670148, t print 17.763s, t batch 0.888s
train Ep 6, Sp 7520, loss 0.713608, t print 11.344s, t batch 0.567s
train Ep 6, Sp 7680, loss 0.699816, t print 13.173s, t batch 0.659s
train Ep 6, Sp 7840, loss 0.702931, t print 19.026s, t batch 0.951s
train Ep 6, Sp 8000, loss 0.719518, t print 10.868s, t batch 0.543s
train Ep 6, Sp 8160, loss 0.667361, t print 12.343s, t batch 0.617s
train Ep 6, Sp 8320, loss 0.699252, t print 20.189s, t batch 1.009s
train Ep 6, Sp 8480, loss 0.729887, t print 10.938s, t batch 0.547s
train Ep 6, Sp 8640, loss 0.674676, t print 11.564s, t batch 0.578s
train Ep 6, Sp 8800, loss 0.70911, t print 20.914s, t batch 1.046s
train Ep 6, Sp 8960, loss 0.703147, t print 11.528s, t batch 0.576s
train Ep 6, Sp 9120, loss 0.706315, t print 10.924s, t batch 0.546s
train Ep 6, Sp 9280, loss 0.713894, t print 20.565s, t batch 1.028s
train Ep 6, Sp 9440, loss 0.676997, t print 10.937s, t batch 0.547s
train Ep 6, Sp 9600, loss 0.663618, t print 11.08s, t batch 0.554s
train Ep 6, Sp 9760, loss 0.730044, t print 20.614s, t batch 1.031s
train Ep 6, Sp 9920, loss 0.706515, t print 11.212s, t batch 0.561s
train Ep 6, Sp 10080, loss 0.680286, t print 11.32s, t batch 0.566s
train Ep 6, Sp 10240, loss 0.685615, t print 20.278s, t batch 1.014s
Start looping batches...
validate Ep 6, Sp 160, loss 0.741484, t print 1.034s, t batch 0.052s
validate Ep 6, Sp 320, loss 0.703521, t print 12.161s, t batch 0.608s
validate Ep 6, Sp 480, loss 0.711528, t print 11.481s, t batch 0.574s
validate Ep 6, Sp 640, loss 0.691517, t print 11.277s, t batch 0.564s
validate Ep 6, Sp 800, loss 0.7426, t print 20.818s, t batch 1.041s
validate Ep 6, Sp 960, loss 0.695885, t print 10.921s, t batch 0.546s
validate Ep 6, Sp 1120, loss 0.677486, t print 10.824s, t batch 0.541s
validate Ep 6, Sp 1280, loss 0.706224, t print 20.514s, t batch 1.026s
validate Ep 6, Sp 1440, loss 0.698891, t print 10.514s, t batch 0.526s
validate Ep 6, Sp 1600, loss 0.739673, t print 10.653s, t batch 0.533s
validate Ep 6, Sp 1760, loss 0.718897, t print 20.63s, t batch 1.031s
validate Ep 6, Sp 1920, loss 0.655728, t print 10.912s, t batch 0.546s
validate Ep 6, Sp 2080, loss 0.648889, t print 10.993s, t batch 0.55s
validate Ep 6, Sp 2240, loss 0.670717, t print 19.638s, t batch 0.982s
validate Ep 6, Sp 2400, loss 0.70896, t print 10.392s, t batch 0.52s
  Epoch 6, Average Epoch loss = 0.6936519031447393
  Epoch 6, nr_of_updates 9072
current learning rate: 0.001
  Saving weights...
  Epoch 6, time total 1119.9099702835083s
  Epoch 6, time UNet: 124.08459234237671s
  Epoch 6, time metrics: 0.13162660598754883s
  Epoch 6, time saving files: 0.2816891670227051s
2023-11-30 12:17:29.484395
Start looping batches...
train Ep 7, Sp 160, loss 0.722145, t print 1.639s, t batch 0.082s
train Ep 7, Sp 320, loss 0.677827, t print 11.201s, t batch 0.56s
train Ep 7, Sp 480, loss 0.703693, t print 12.233s, t batch 0.612s
train Ep 7, Sp 640, loss 0.681382, t print 11.886s, t batch 0.594s
train Ep 7, Sp 800, loss 0.706847, t print 20.885s, t batch 1.044s
train Ep 7, Sp 960, loss 0.679569, t print 12.811s, t batch 0.641s
train Ep 7, Sp 1120, loss 0.695262, t print 11.787s, t batch 0.589s
train Ep 7, Sp 1280, loss 0.702762, t print 18.109s, t batch 0.905s
train Ep 7, Sp 1440, loss 0.669282, t print 15.599s, t batch 0.78s
train Ep 7, Sp 1600, loss 0.658921, t print 11.648s, t batch 0.582s
train Ep 7, Sp 1760, loss 0.711703, t print 15.055s, t batch 0.753s
train Ep 7, Sp 1920, loss 0.710082, t print 17.832s, t batch 0.892s
train Ep 7, Sp 2080, loss 0.717673, t print 11.022s, t batch 0.551s
train Ep 7, Sp 2240, loss 0.703513, t print 12.827s, t batch 0.641s
train Ep 7, Sp 2400, loss 0.687703, t print 19.945s, t batch 0.997s
train Ep 7, Sp 2560, loss 0.710916, t print 11.72s, t batch 0.586s
train Ep 7, Sp 2720, loss 0.701943, t print 11.478s, t batch 0.574s
train Ep 7, Sp 2880, loss 0.657898, t print 21.79s, t batch 1.089s
train Ep 7, Sp 3040, loss 0.658577, t print 11.436s, t batch 0.572s
train Ep 7, Sp 3200, loss 0.709627, t print 11.52s, t batch 0.576s
train Ep 7, Sp 3360, loss 0.708823, t print 21.118s, t batch 1.056s
train Ep 7, Sp 3520, loss 0.70175, t print 11.356s, t batch 0.568s
train Ep 7, Sp 3680, loss 0.671238, t print 11.353s, t batch 0.568s
train Ep 7, Sp 3840, loss 0.736909, t print 21.448s, t batch 1.072s
train Ep 7, Sp 4000, loss 0.696092, t print 11.582s, t batch 0.579s
train Ep 7, Sp 4160, loss 0.715887, t print 11.593s, t batch 0.58s
train Ep 7, Sp 4320, loss 0.67623, t print 21.57s, t batch 1.079s
train Ep 7, Sp 4480, loss 0.680877, t print 11.502s, t batch 0.575s
train Ep 7, Sp 4640, loss 0.66935, t print 11.757s, t batch 0.588s
train Ep 7, Sp 4800, loss 0.638423, t print 21.634s, t batch 1.082s
train Ep 7, Sp 4960, loss 0.691678, t print 11.532s, t batch 0.577s
train Ep 7, Sp 5120, loss 0.676372, t print 11.558s, t batch 0.578s
train Ep 7, Sp 5280, loss 0.683837, t print 21.307s, t batch 1.065s
train Ep 7, Sp 5440, loss 0.674549, t print 11.233s, t batch 0.562s
train Ep 7, Sp 5600, loss 0.704078, t print 11.411s, t batch 0.571s
train Ep 7, Sp 5760, loss 0.680316, t print 21.54s, t batch 1.077s
train Ep 7, Sp 5920, loss 0.677371, t print 11.305s, t batch 0.565s
train Ep 7, Sp 6080, loss 0.696722, t print 11.439s, t batch 0.572s
train Ep 7, Sp 6240, loss 0.694046, t print 21.604s, t batch 1.08s
train Ep 7, Sp 6400, loss 0.687819, t print 11.436s, t batch 0.572s
train Ep 7, Sp 6560, loss 0.727574, t print 11.441s, t batch 0.572s
train Ep 7, Sp 6720, loss 0.675706, t print 21.399s, t batch 1.07s
train Ep 7, Sp 6880, loss 0.725308, t print 11.51s, t batch 0.576s
train Ep 7, Sp 7040, loss 0.715726, t print 11.51s, t batch 0.575s
train Ep 7, Sp 7200, loss 0.691937, t print 21.262s, t batch 1.063s
train Ep 7, Sp 7360, loss 0.676742, t print 11.389s, t batch 0.569s
train Ep 7, Sp 7520, loss 0.678358, t print 11.49s, t batch 0.574s
train Ep 7, Sp 7680, loss 0.712005, t print 21.472s, t batch 1.074s
train Ep 7, Sp 7840, loss 0.701831, t print 11.472s, t batch 0.574s
train Ep 7, Sp 8000, loss 0.667185, t print 11.557s, t batch 0.578s
train Ep 7, Sp 8160, loss 0.717078, t print 21.454s, t batch 1.073s
train Ep 7, Sp 8320, loss 0.683105, t print 11.3s, t batch 0.565s
train Ep 7, Sp 8480, loss 0.71911, t print 11.214s, t batch 0.561s
train Ep 7, Sp 8640, loss 0.716172, t print 20.264s, t batch 1.013s
train Ep 7, Sp 8800, loss 0.701726, t print 10.768s, t batch 0.538s
train Ep 7, Sp 8960, loss 0.680649, t print 10.871s, t batch 0.544s
train Ep 7, Sp 9120, loss 0.719678, t print 20.042s, t batch 1.002s
train Ep 7, Sp 9280, loss 0.710621, t print 10.921s, t batch 0.546s
train Ep 7, Sp 9440, loss 0.687861, t print 10.948s, t batch 0.547s
train Ep 7, Sp 9600, loss 0.695762, t print 20.114s, t batch 1.006s
train Ep 7, Sp 9760, loss 0.67223, t print 10.808s, t batch 0.54s
train Ep 7, Sp 9920, loss 0.701257, t print 10.902s, t batch 0.545s
train Ep 7, Sp 10080, loss 0.650753, t print 20.305s, t batch 1.015s
train Ep 7, Sp 10240, loss 0.678721, t print 10.954s, t batch 0.548s
Start looping batches...
validate Ep 7, Sp 160, loss 0.682513, t print 1.09s, t batch 0.054s
validate Ep 7, Sp 320, loss 0.656491, t print 11.521s, t batch 0.576s
validate Ep 7, Sp 480, loss 0.716929, t print 12.18s, t batch 0.609s
validate Ep 7, Sp 640, loss 0.683111, t print 11.606s, t batch 0.58s
validate Ep 7, Sp 800, loss 0.691029, t print 19.692s, t batch 0.985s
validate Ep 7, Sp 960, loss 0.72078, t print 11.093s, t batch 0.555s
validate Ep 7, Sp 1120, loss 0.690776, t print 10.805s, t batch 0.54s
validate Ep 7, Sp 1280, loss 0.7291, t print 20.911s, t batch 1.046s
validate Ep 7, Sp 1440, loss 0.689811, t print 10.973s, t batch 0.549s
validate Ep 7, Sp 1600, loss 0.716859, t print 10.888s, t batch 0.544s
validate Ep 7, Sp 1760, loss 0.691762, t print 20.707s, t batch 1.035s
validate Ep 7, Sp 1920, loss 0.670232, t print 10.83s, t batch 0.541s
validate Ep 7, Sp 2080, loss 0.675897, t print 10.915s, t batch 0.546s
validate Ep 7, Sp 2240, loss 0.719046, t print 20.177s, t batch 1.009s
validate Ep 7, Sp 2400, loss 0.695212, t print 10.789s, t batch 0.539s
  Epoch 7, Average Epoch loss = 0.6926386486049052
  Epoch 7, nr_of_updates 10368
current learning rate: 0.001
  Saving weights...
  Epoch 7, time total 1123.0854625701904s
  Epoch 7, time UNet: 122.28412699699402s
  Epoch 7, time metrics: 0.13132786750793457s
  Epoch 7, time saving files: 0.48490285873413086s
2023-11-30 12:36:12.576631
Start looping batches...
train Ep 8, Sp 160, loss 0.696294, t print 1.653s, t batch 0.083s
train Ep 8, Sp 320, loss 0.657929, t print 11.102s, t batch 0.555s
train Ep 8, Sp 480, loss 0.677611, t print 12.636s, t batch 0.632s
train Ep 8, Sp 640, loss 0.700334, t print 11.537s, t batch 0.577s
train Ep 8, Sp 800, loss 0.653797, t print 20.752s, t batch 1.038s
train Ep 8, Sp 960, loss 0.713903, t print 11.259s, t batch 0.563s
train Ep 8, Sp 1120, loss 0.717867, t print 11.4s, t batch 0.57s
train Ep 8, Sp 1280, loss 0.674882, t print 20.837s, t batch 1.042s
train Ep 8, Sp 1440, loss 0.702515, t print 11.212s, t batch 0.561s
train Ep 8, Sp 1600, loss 0.707438, t print 11.621s, t batch 0.581s
train Ep 8, Sp 1760, loss 0.709909, t print 20.357s, t batch 1.018s
train Ep 8, Sp 1920, loss 0.734507, t print 11.196s, t batch 0.56s
train Ep 8, Sp 2080, loss 0.714424, t print 11.588s, t batch 0.579s
train Ep 8, Sp 2240, loss 0.680058, t print 20.195s, t batch 1.01s
train Ep 8, Sp 2400, loss 0.714126, t print 11.071s, t batch 0.554s
train Ep 8, Sp 2560, loss 0.702983, t print 12.328s, t batch 0.616s
train Ep 8, Sp 2720, loss 0.686141, t print 19.042s, t batch 0.952s
train Ep 8, Sp 2880, loss 0.727774, t print 10.736s, t batch 0.537s
train Ep 8, Sp 3040, loss 0.709198, t print 12.824s, t batch 0.641s
train Ep 8, Sp 3200, loss 0.69812, t print 17.978s, t batch 0.899s
train Ep 8, Sp 3360, loss 0.719201, t print 10.738s, t batch 0.537s
train Ep 8, Sp 3520, loss 0.711474, t print 13.83s, t batch 0.691s
train Ep 8, Sp 3680, loss 0.696411, t print 16.975s, t batch 0.849s
train Ep 8, Sp 3840, loss 0.715107, t print 11.25s, t batch 0.563s
train Ep 8, Sp 4000, loss 0.683562, t print 14.574s, t batch 0.729s
train Ep 8, Sp 4160, loss 0.676597, t print 16.006s, t batch 0.8s
train Ep 8, Sp 4320, loss 0.704002, t print 11.89s, t batch 0.594s
train Ep 8, Sp 4480, loss 0.634855, t print 14.895s, t batch 0.745s
train Ep 8, Sp 4640, loss 0.694435, t print 14.615s, t batch 0.731s
train Ep 8, Sp 4800, loss 0.70887, t print 12.596s, t batch 0.63s
train Ep 8, Sp 4960, loss 0.67006, t print 15.212s, t batch 0.761s
train Ep 8, Sp 5120, loss 0.660113, t print 13.949s, t batch 0.697s
train Ep 8, Sp 5280, loss 0.722373, t print 12.861s, t batch 0.643s
train Ep 8, Sp 5440, loss 0.704254, t print 16.354s, t batch 0.818s
train Ep 8, Sp 5600, loss 0.690708, t print 12.661s, t batch 0.633s
train Ep 8, Sp 5760, loss 0.683674, t print 13.097s, t batch 0.655s
train Ep 8, Sp 5920, loss 0.690329, t print 17.697s, t batch 0.885s
train Ep 8, Sp 6080, loss 0.715367, t print 11.992s, t batch 0.6s
train Ep 8, Sp 6240, loss 0.701413, t print 12.846s, t batch 0.642s
train Ep 8, Sp 6400, loss 0.692086, t print 18.887s, t batch 0.944s
train Ep 8, Sp 6560, loss 0.71179, t print 11.918s, t batch 0.596s
train Ep 8, Sp 6720, loss 0.697407, t print 11.749s, t batch 0.587s
train Ep 8, Sp 6880, loss 0.732654, t print 20.546s, t batch 1.027s
train Ep 8, Sp 7040, loss 0.708157, t print 11.631s, t batch 0.582s
train Ep 8, Sp 7200, loss 0.714295, t print 11.619s, t batch 0.581s
train Ep 8, Sp 7360, loss 0.691992, t print 21.706s, t batch 1.085s
train Ep 8, Sp 7520, loss 0.697162, t print 11.777s, t batch 0.589s
train Ep 8, Sp 7680, loss 0.707788, t print 11.66s, t batch 0.583s
train Ep 8, Sp 7840, loss 0.691596, t print 21.734s, t batch 1.087s
train Ep 8, Sp 8000, loss 0.711948, t print 11.688s, t batch 0.584s
train Ep 8, Sp 8160, loss 0.723774, t print 11.594s, t batch 0.58s
train Ep 8, Sp 8320, loss 0.71735, t print 21.338s, t batch 1.067s
train Ep 8, Sp 8480, loss 0.693951, t print 11.52s, t batch 0.576s
train Ep 8, Sp 8640, loss 0.726178, t print 11.285s, t batch 0.564s
train Ep 8, Sp 8800, loss 0.714882, t print 21.005s, t batch 1.05s
train Ep 8, Sp 8960, loss 0.669418, t print 11.416s, t batch 0.571s
train Ep 8, Sp 9120, loss 0.697288, t print 11.217s, t batch 0.561s
train Ep 8, Sp 9280, loss 0.691375, t print 20.657s, t batch 1.033s
train Ep 8, Sp 9440, loss 0.678775, t print 11.286s, t batch 0.564s
train Ep 8, Sp 9600, loss 0.657273, t print 11.398s, t batch 0.57s
train Ep 8, Sp 9760, loss 0.708102, t print 21.143s, t batch 1.057s
train Ep 8, Sp 9920, loss 0.712849, t print 11.261s, t batch 0.563s
train Ep 8, Sp 10080, loss 0.683617, t print 11.123s, t batch 0.556s
train Ep 8, Sp 10240, loss 0.686944, t print 21.082s, t batch 1.054s
Start looping batches...
validate Ep 8, Sp 160, loss 0.677325, t print 0.971s, t batch 0.049s
validate Ep 8, Sp 320, loss 0.685311, t print 1689.368s, t batch 84.468s
validate Ep 8, Sp 480, loss 0.702395, t print 11.495s, t batch 0.575s
validate Ep 8, Sp 640, loss 0.65929, t print 10.661s, t batch 0.533s
validate Ep 8, Sp 800, loss 0.714473, t print 20.102s, t batch 1.005s
validate Ep 8, Sp 960, loss 0.695019, t print 11.076s, t batch 0.554s
validate Ep 8, Sp 1120, loss 0.672306, t print 11.094s, t batch 0.555s
validate Ep 8, Sp 1280, loss 0.711676, t print 20.466s, t batch 1.023s
validate Ep 8, Sp 1440, loss 0.685936, t print 11.137s, t batch 0.557s
validate Ep 8, Sp 1600, loss 0.677534, t print 10.919s, t batch 0.546s
validate Ep 8, Sp 1760, loss 0.713541, t print 20.132s, t batch 1.007s
validate Ep 8, Sp 1920, loss 0.66587, t print 10.86s, t batch 0.543s
validate Ep 8, Sp 2080, loss 0.691722, t print 10.825s, t batch 0.541s
validate Ep 8, Sp 2240, loss 0.717511, t print 20.352s, t batch 1.018s
validate Ep 8, Sp 2400, loss 0.714148, t print 11.112s, t batch 0.556s
  Epoch 8, Average Epoch loss = 0.6981816805991126
  Epoch 8, nr_of_updates 11664
current learning rate: 0.001
  Saving weights...
  Epoch 8, time total 2792.936201572418s
  Epoch 8, time UNet: 124.00984168052673s
  Epoch 8, time metrics: 0.12798190116882324s
  Epoch 8, time saving files: 0.6220669746398926s
2023-11-30 13:22:45.521341
Start looping batches...
train Ep 9, Sp 160, loss 0.702363, t print 2.574s, t batch 0.129s
train Ep 9, Sp 320, loss 0.643315, t print 10.568s, t batch 0.528s
train Ep 9, Sp 480, loss 0.709231, t print 13.231s, t batch 0.662s
train Ep 9, Sp 640, loss 0.685119, t print 11.66s, t batch 0.583s
train Ep 9, Sp 800, loss 0.741833, t print 18.009s, t batch 0.9s
train Ep 9, Sp 960, loss 0.717116, t print 14.078s, t batch 0.704s
train Ep 9, Sp 1120, loss 0.67086, t print 11.437s, t batch 0.572s
train Ep 9, Sp 1280, loss 0.686992, t print 15.486s, t batch 0.774s
train Ep 9, Sp 1440, loss 0.696864, t print 17.122s, t batch 0.856s
train Ep 9, Sp 1600, loss 0.693358, t print 11.29s, t batch 0.565s
train Ep 9, Sp 1760, loss 0.732364, t print 12.594s, t batch 0.63s
train Ep 9, Sp 1920, loss 0.662777, t print 19.702s, t batch 0.985s
train Ep 9, Sp 2080, loss 0.692505, t print 11.156s, t batch 0.558s
train Ep 9, Sp 2240, loss 0.727779, t print 11.123s, t batch 0.556s
train Ep 9, Sp 2400, loss 0.733258, t print 20.631s, t batch 1.032s
train Ep 9, Sp 2560, loss 0.751079, t print 11.303s, t batch 0.565s
train Ep 9, Sp 2720, loss 0.728928, t print 11.268s, t batch 0.563s
train Ep 9, Sp 2880, loss 0.716833, t print 20.886s, t batch 1.044s
train Ep 9, Sp 3040, loss 0.683405, t print 11.401s, t batch 0.57s
train Ep 9, Sp 3200, loss 0.724386, t print 11.083s, t batch 0.554s
train Ep 9, Sp 3360, loss 0.679448, t print 21.119s, t batch 1.056s
train Ep 9, Sp 3520, loss 0.660363, t print 11.38s, t batch 0.569s
train Ep 9, Sp 3680, loss 0.681459, t print 11.347s, t batch 0.567s
train Ep 9, Sp 3840, loss 0.685539, t print 21.003s, t batch 1.05s
train Ep 9, Sp 4000, loss 0.674191, t print 11.423s, t batch 0.571s
train Ep 9, Sp 4160, loss 0.700307, t print 11.285s, t batch 0.564s
train Ep 9, Sp 4320, loss 0.70853, t print 20.871s, t batch 1.044s
train Ep 9, Sp 4480, loss 0.731832, t print 11.262s, t batch 0.563s
train Ep 9, Sp 4640, loss 0.661775, t print 11.226s, t batch 0.561s
train Ep 9, Sp 4800, loss 0.699209, t print 20.973s, t batch 1.049s
train Ep 9, Sp 4960, loss 0.708489, t print 11.114s, t batch 0.556s
train Ep 9, Sp 5120, loss 0.705859, t print 11.323s, t batch 0.566s
train Ep 9, Sp 5280, loss 0.662284, t print 20.623s, t batch 1.031s
train Ep 9, Sp 5440, loss 0.679738, t print 10.987s, t batch 0.549s
train Ep 9, Sp 5600, loss 0.670963, t print 11.065s, t batch 0.553s
train Ep 9, Sp 5760, loss 0.659587, t print 20.84s, t batch 1.042s
train Ep 9, Sp 5920, loss 0.709066, t print 10.998s, t batch 0.55s
train Ep 9, Sp 6080, loss 0.683848, t print 11.024s, t batch 0.551s
train Ep 9, Sp 6240, loss 0.666745, t print 20.59s, t batch 1.03s
train Ep 9, Sp 6400, loss 0.6884, t print 11.159s, t batch 0.558s
train Ep 9, Sp 6560, loss 0.707519, t print 11.211s, t batch 0.561s
train Ep 9, Sp 6720, loss 0.722676, t print 20.686s, t batch 1.034s
train Ep 9, Sp 6880, loss 0.681487, t print 11.132s, t batch 0.557s
train Ep 9, Sp 7040, loss 0.693264, t print 11.224s, t batch 0.561s
train Ep 9, Sp 7200, loss 0.71616, t print 20.535s, t batch 1.027s
train Ep 9, Sp 7360, loss 0.676896, t print 11.228s, t batch 0.561s
train Ep 9, Sp 7520, loss 0.670989, t print 11.625s, t batch 0.581s
train Ep 9, Sp 7680, loss 0.701766, t print 20.971s, t batch 1.049s
train Ep 9, Sp 7840, loss 0.69861, t print 11.257s, t batch 0.563s
train Ep 9, Sp 8000, loss 0.648503, t print 11.165s, t batch 0.558s
train Ep 9, Sp 8160, loss 0.653684, t print 20.821s, t batch 1.041s
train Ep 9, Sp 8320, loss 0.682773, t print 11.424s, t batch 0.571s
train Ep 9, Sp 8480, loss 0.675768, t print 11.394s, t batch 0.57s
train Ep 9, Sp 8640, loss 0.703987, t print 21.232s, t batch 1.062s
train Ep 9, Sp 8800, loss 0.684174, t print 11.464s, t batch 0.573s
train Ep 9, Sp 8960, loss 0.698994, t print 11.534s, t batch 0.577s
train Ep 9, Sp 9120, loss 0.687494, t print 21.292s, t batch 1.065s
train Ep 9, Sp 9280, loss 0.708792, t print 11.232s, t batch 0.562s
train Ep 9, Sp 9440, loss 0.704318, t print 11.511s, t batch 0.576s
train Ep 9, Sp 9600, loss 0.723898, t print 20.847s, t batch 1.042s
train Ep 9, Sp 9760, loss 0.711935, t print 11.096s, t batch 0.555s
train Ep 9, Sp 9920, loss 0.660017, t print 10.912s, t batch 0.546s
train Ep 9, Sp 10080, loss 0.670153, t print 19.894s, t batch 0.995s
train Ep 9, Sp 10240, loss 0.732839, t print 10.8s, t batch 0.54s
Start looping batches...
validate Ep 9, Sp 160, loss 0.704977, t print 1.159s, t batch 0.058s
validate Ep 9, Sp 320, loss 0.718498, t print 11.875s, t batch 0.594s
validate Ep 9, Sp 480, loss 0.703763, t print 11.941s, t batch 0.597s
validate Ep 9, Sp 640, loss 0.716465, t print 10.937s, t batch 0.547s
validate Ep 9, Sp 800, loss 0.674971, t print 20.871s, t batch 1.044s
validate Ep 9, Sp 960, loss 0.702259, t print 10.916s, t batch 0.546s
validate Ep 9, Sp 1120, loss 0.684103, t print 10.938s, t batch 0.547s
validate Ep 9, Sp 1280, loss 0.684317, t print 21.017s, t batch 1.051s
validate Ep 9, Sp 1440, loss 0.672403, t print 11.058s, t batch 0.553s
validate Ep 9, Sp 1600, loss 0.717317, t print 10.919s, t batch 0.546s
validate Ep 9, Sp 1760, loss 0.675206, t print 20.966s, t batch 1.048s
validate Ep 9, Sp 1920, loss 0.660034, t print 10.915s, t batch 0.546s
validate Ep 9, Sp 2080, loss 0.689192, t print 10.833s, t batch 0.542s
validate Ep 9, Sp 2240, loss 0.675125, t print 19.643s, t batch 0.982s
validate Ep 9, Sp 2400, loss 0.688788, t print 10.739s, t batch 0.537s
  Epoch 9, Average Epoch loss = 0.6939348238577814
  Epoch 9, nr_of_updates 12960
current learning rate: 0.001
  Epoch 9, time total 1110.7093074321747s
  Epoch 9, time UNet: 124.2191150188446s
  Epoch 9, time metrics: 0.12866663932800293s
  Epoch 9, time saving files: 0.00013113021850585938s
2023-11-30 13:41:16.237534
Start looping batches...
train Ep 10, Sp 160, loss 0.680807, t print 1.632s, t batch 0.082s
train Ep 10, Sp 320, loss 0.681446, t print 11.903s, t batch 0.595s
train Ep 10, Sp 480, loss 0.68604, t print 13.063s, t batch 0.653s
train Ep 10, Sp 640, loss 0.704042, t print 11.646s, t batch 0.582s
train Ep 10, Sp 800, loss 0.712374, t print 21.751s, t batch 1.088s
train Ep 10, Sp 960, loss 0.716852, t print 11.722s, t batch 0.586s
train Ep 10, Sp 1120, loss 0.716948, t print 11.619s, t batch 0.581s
train Ep 10, Sp 1280, loss 0.693963, t print 21.729s, t batch 1.086s
train Ep 10, Sp 1440, loss 0.676391, t print 11.718s, t batch 0.586s
train Ep 10, Sp 1600, loss 0.697679, t print 11.637s, t batch 0.582s
train Ep 10, Sp 1760, loss 0.682872, t print 21.676s, t batch 1.084s
train Ep 10, Sp 1920, loss 0.688943, t print 11.585s, t batch 0.579s
train Ep 10, Sp 2080, loss 0.668591, t print 11.492s, t batch 0.575s
train Ep 10, Sp 2240, loss 0.674487, t print 21.241s, t batch 1.062s
train Ep 10, Sp 2400, loss 0.656769, t print 11.578s, t batch 0.579s
train Ep 10, Sp 2560, loss 0.699573, t print 11.474s, t batch 0.574s
train Ep 10, Sp 2720, loss 0.697722, t print 20.425s, t batch 1.021s
train Ep 10, Sp 2880, loss 0.697493, t print 11.289s, t batch 0.564s
train Ep 10, Sp 3040, loss 0.69474, t print 11.182s, t batch 0.559s
train Ep 10, Sp 3200, loss 0.700195, t print 20.528s, t batch 1.026s
train Ep 10, Sp 3360, loss 0.691312, t print 11.744s, t batch 0.587s
train Ep 10, Sp 3520, loss 0.689962, t print 11.033s, t batch 0.552s
train Ep 10, Sp 3680, loss 0.65607, t print 20.358s, t batch 1.018s
train Ep 10, Sp 3840, loss 0.690235, t print 11.807s, t batch 0.59s
train Ep 10, Sp 4000, loss 0.663026, t print 11.448s, t batch 0.572s
train Ep 10, Sp 4160, loss 0.709094, t print 19.69s, t batch 0.985s
train Ep 10, Sp 4320, loss 0.662327, t print 12.061s, t batch 0.603s
train Ep 10, Sp 4480, loss 0.688488, t print 11.23s, t batch 0.561s
train Ep 10, Sp 4640, loss 0.718418, t print 19.779s, t batch 0.989s
train Ep 10, Sp 4800, loss 0.679841, t print 11.828s, t batch 0.591s
train Ep 10, Sp 4960, loss 0.668943, t print 11.181s, t batch 0.559s
train Ep 10, Sp 5120, loss 0.687206, t print 19.796s, t batch 0.99s
train Ep 10, Sp 5280, loss 0.727012, t print 11.919s, t batch 0.596s
train Ep 10, Sp 5440, loss 0.724997, t print 11.147s, t batch 0.557s
train Ep 10, Sp 5600, loss 0.704939, t print 19.053s, t batch 0.953s
train Ep 10, Sp 5760, loss 0.730366, t print 12.832s, t batch 0.642s
train Ep 10, Sp 5920, loss 0.711938, t print 11.132s, t batch 0.557s
train Ep 10, Sp 6080, loss 0.683503, t print 17.211s, t batch 0.861s
train Ep 10, Sp 6240, loss 0.703824, t print 14.496s, t batch 0.725s
train Ep 10, Sp 6400, loss 0.693035, t print 11.057s, t batch 0.553s
train Ep 10, Sp 6560, loss 0.708835, t print 15.866s, t batch 0.793s
train Ep 10, Sp 6720, loss 0.696243, t print 15.894s, t batch 0.795s
train Ep 10, Sp 6880, loss 0.695998, t print 11.041s, t batch 0.552s
train Ep 10, Sp 7040, loss 0.687286, t print 14.388s, t batch 0.719s
train Ep 10, Sp 7200, loss 0.686482, t print 17.226s, t batch 0.861s
train Ep 10, Sp 7360, loss 0.687314, t print 11.046s, t batch 0.552s
train Ep 10, Sp 7520, loss 0.672807, t print 13.65s, t batch 0.682s
train Ep 10, Sp 7680, loss 0.700327, t print 17.554s, t batch 0.878s
train Ep 10, Sp 7840, loss 0.674624, t print 11.027s, t batch 0.551s
train Ep 10, Sp 8000, loss 0.676532, t print 13.683s, t batch 0.684s
train Ep 10, Sp 8160, loss 0.687932, t print 18.055s, t batch 0.903s
train Ep 10, Sp 8320, loss 0.666278, t print 11.137s, t batch 0.557s
train Ep 10, Sp 8480, loss 0.699158, t print 12.374s, t batch 0.619s
train Ep 10, Sp 8640, loss 0.676118, t print 19.417s, t batch 0.971s
train Ep 10, Sp 8800, loss 0.701951, t print 11.063s, t batch 0.553s
train Ep 10, Sp 8960, loss 0.710038, t print 11.673s, t batch 0.584s
train Ep 10, Sp 9120, loss 0.688898, t print 19.816s, t batch 0.991s
train Ep 10, Sp 9280, loss 0.695905, t print 11.685s, t batch 0.584s
train Ep 10, Sp 9440, loss 0.712529, t print 11.704s, t batch 0.585s
train Ep 10, Sp 9600, loss 0.706035, t print 18.335s, t batch 0.917s
train Ep 10, Sp 9760, loss 0.721921, t print 13.346s, t batch 0.667s
train Ep 10, Sp 9920, loss 0.696314, t print 11.946s, t batch 0.597s
train Ep 10, Sp 10080, loss 0.685888, t print 16.569s, t batch 0.828s
train Ep 10, Sp 10240, loss 0.701505, t print 14.574s, t batch 0.729s
Start looping batches...
validate Ep 10, Sp 160, loss 0.699217, t print 1.004s, t batch 0.05s
validate Ep 10, Sp 320, loss 0.724273, t print 2351.387s, t batch 117.569s
validate Ep 10, Sp 480, loss 0.690351, t print 6.536s, t batch 0.327s
validate Ep 10, Sp 640, loss 0.685372, t print 11.074s, t batch 0.554s
validate Ep 10, Sp 800, loss 0.713343, t print 20.636s, t batch 1.032s
validate Ep 10, Sp 960, loss 0.726072, t print 10.856s, t batch 0.543s
validate Ep 10, Sp 1120, loss 0.708677, t print 10.913s, t batch 0.546s
validate Ep 10, Sp 1280, loss 0.702117, t print 20.125s, t batch 1.006s
validate Ep 10, Sp 1440, loss 0.687946, t print 10.526s, t batch 0.526s
validate Ep 10, Sp 1600, loss 0.690749, t print 10.902s, t batch 0.545s
validate Ep 10, Sp 1760, loss 0.711793, t print 20.537s, t batch 1.027s
validate Ep 10, Sp 1920, loss 0.682458, t print 10.685s, t batch 0.534s
validate Ep 10, Sp 2080, loss 0.693068, t print 10.751s, t batch 0.538s
validate Ep 10, Sp 2240, loss 0.717825, t print 20.346s, t batch 1.017s
validate Ep 10, Sp 2400, loss 0.693163, t print 10.66s, t batch 0.533s
  Epoch 10, Average Epoch loss = 0.6930776273854721
  Epoch 10, nr_of_updates 14256
current learning rate: 0.001
  Epoch 10, time total 3443.8112938404083s
  Epoch 10, time UNet: 130.63963222503662s
  Epoch 10, time metrics: 0.13626384735107422s
  Epoch 10, time saving files: 0.02031731605529785s
2023-11-30 14:38:40.055512
Start looping batches...
train Ep 11, Sp 160, loss 0.652653, t print 4.305s, t batch 0.215s
train Ep 11, Sp 320, loss 0.671115, t print 11.271s, t batch 0.564s
train Ep 11, Sp 480, loss 0.676813, t print 12.832s, t batch 0.642s
train Ep 11, Sp 640, loss 0.711017, t print 11.858s, t batch 0.593s
train Ep 11, Sp 800, loss 0.697305, t print 20.324s, t batch 1.016s
train Ep 11, Sp 960, loss 0.670929, t print 12.441s, t batch 0.622s
train Ep 11, Sp 1120, loss 0.687422, t print 11.579s, t batch 0.579s
train Ep 11, Sp 1280, loss 0.706169, t print 19.322s, t batch 0.966s
train Ep 11, Sp 1440, loss 0.676535, t print 13.298s, t batch 0.665s
train Ep 11, Sp 1600, loss 0.641071, t print 11.786s, t batch 0.589s
train Ep 11, Sp 1760, loss 0.706665, t print 16.796s, t batch 0.84s
train Ep 11, Sp 1920, loss 0.662655, t print 16.672s, t batch 0.834s
train Ep 11, Sp 2080, loss 0.695708, t print 11.711s, t batch 0.586s
train Ep 11, Sp 2240, loss 0.745348, t print 13.543s, t batch 0.677s
train Ep 11, Sp 2400, loss 0.669176, t print 20.045s, t batch 1.002s
train Ep 11, Sp 2560, loss 0.687505, t print 11.705s, t batch 0.585s
train Ep 11, Sp 2720, loss 0.674454, t print 11.762s, t batch 0.588s
train Ep 11, Sp 2880, loss 0.693192, t print 22.1s, t batch 1.105s
train Ep 11, Sp 3040, loss 0.712259, t print 11.695s, t batch 0.585s
train Ep 11, Sp 3200, loss 0.703773, t print 11.603s, t batch 0.58s
train Ep 11, Sp 3360, loss 0.665665, t print 21.062s, t batch 1.053s
train Ep 11, Sp 3520, loss 0.693165, t print 11.297s, t batch 0.565s
train Ep 11, Sp 3680, loss 0.660168, t print 11.241s, t batch 0.562s
train Ep 11, Sp 3840, loss 0.701672, t print 20.888s, t batch 1.044s
train Ep 11, Sp 4000, loss 0.711021, t print 11.43s, t batch 0.572s
train Ep 11, Sp 4160, loss 0.68966, t print 11.405s, t batch 0.57s
train Ep 11, Sp 4320, loss 0.669007, t print 20.975s, t batch 1.049s
train Ep 11, Sp 4480, loss 0.653417, t print 11.451s, t batch 0.573s
train Ep 11, Sp 4640, loss 0.67398, t print 11.563s, t batch 0.578s
train Ep 11, Sp 4800, loss 0.700866, t print 20.545s, t batch 1.027s
train Ep 11, Sp 4960, loss 0.699585, t print 12.124s, t batch 0.606s
train Ep 11, Sp 5120, loss 0.696625, t print 11.103s, t batch 0.555s
train Ep 11, Sp 5280, loss 0.657776, t print 20.086s, t batch 1.004s
train Ep 11, Sp 5440, loss 0.691865, t print 12.104s, t batch 0.605s
train Ep 11, Sp 5600, loss 0.689948, t print 11.189s, t batch 0.559s
train Ep 11, Sp 5760, loss 0.665759, t print 19.263s, t batch 0.963s
train Ep 11, Sp 5920, loss 0.684102, t print 13.303s, t batch 0.665s
train Ep 11, Sp 6080, loss 0.705706, t print 11.311s, t batch 0.566s
train Ep 11, Sp 6240, loss 0.662484, t print 18.256s, t batch 0.913s
train Ep 11, Sp 6400, loss 0.649221, t print 13.487s, t batch 0.674s
train Ep 11, Sp 6560, loss 0.732258, t print 11.788s, t batch 0.589s
train Ep 11, Sp 6720, loss 0.725601, t print 16.892s, t batch 0.845s
train Ep 11, Sp 6880, loss 0.688429, t print 16.045s, t batch 0.802s
train Ep 11, Sp 7040, loss 0.667053, t print 11.337s, t batch 0.567s
train Ep 11, Sp 7200, loss 0.703131, t print 14.44s, t batch 0.722s
train Ep 11, Sp 7360, loss 0.678862, t print 17.873s, t batch 0.894s
train Ep 11, Sp 7520, loss 0.671386, t print 11.084s, t batch 0.554s
train Ep 11, Sp 7680, loss 0.703337, t print 12.326s, t batch 0.616s
train Ep 11, Sp 7840, loss 0.723274, t print 20.516s, t batch 1.026s
train Ep 11, Sp 8000, loss 0.650356, t print 11.563s, t batch 0.578s
train Ep 11, Sp 8160, loss 0.700715, t print 11.317s, t batch 0.566s
train Ep 11, Sp 8320, loss 0.731366, t print 21.42s, t batch 1.071s
train Ep 11, Sp 8480, loss 0.678199, t print 11.597s, t batch 0.58s
train Ep 11, Sp 8640, loss 0.694455, t print 11.43s, t batch 0.572s
train Ep 11, Sp 8800, loss 0.682814, t print 21.109s, t batch 1.055s
train Ep 11, Sp 8960, loss 0.682869, t print 11.428s, t batch 0.571s
train Ep 11, Sp 9120, loss 0.690606, t print 11.266s, t batch 0.563s
train Ep 11, Sp 9280, loss 0.691437, t print 21.002s, t batch 1.05s
train Ep 11, Sp 9440, loss 0.711877, t print 11.13s, t batch 0.557s
train Ep 11, Sp 9600, loss 0.682261, t print 10.958s, t batch 0.548s
train Ep 11, Sp 9760, loss 0.687625, t print 20.253s, t batch 1.013s
train Ep 11, Sp 9920, loss 0.684356, t print 11.864s, t batch 0.593s
train Ep 11, Sp 10080, loss 0.735341, t print 10.773s, t batch 0.539s
train Ep 11, Sp 10240, loss 0.705501, t print 20.627s, t batch 1.031s
Start looping batches...
validate Ep 11, Sp 160, loss 0.713117, t print 0.986s, t batch 0.049s
validate Ep 11, Sp 320, loss 0.699882, t print 12.278s, t batch 0.614s
validate Ep 11, Sp 480, loss 0.689129, t print 11.535s, t batch 0.577s
validate Ep 11, Sp 640, loss 0.658396, t print 11.183s, t batch 0.559s
validate Ep 11, Sp 800, loss 0.680878, t print 20.523s, t batch 1.026s
validate Ep 11, Sp 960, loss 0.70129, t print 11.615s, t batch 0.581s
validate Ep 11, Sp 1120, loss 0.712092, t print 11.414s, t batch 0.571s
validate Ep 11, Sp 1280, loss 0.684358, t print 20.598s, t batch 1.03s
validate Ep 11, Sp 1440, loss 0.689929, t print 12.46s, t batch 0.623s
validate Ep 11, Sp 1600, loss 0.681874, t print 11.211s, t batch 0.561s
validate Ep 11, Sp 1760, loss 0.694935, t print 18.458s, t batch 0.923s
validate Ep 11, Sp 1920, loss 0.698932, t print 13.065s, t batch 0.653s
validate Ep 11, Sp 2080, loss 0.692311, t print 11.494s, t batch 0.575s
validate Ep 11, Sp 2240, loss 0.691642, t print 16.014s, t batch 0.801s
validate Ep 11, Sp 2400, loss 0.679748, t print 13.823s, t batch 0.691s
  Epoch 11, Average Epoch loss = 0.6881103956221063
  Epoch 11, nr_of_updates 15552
current learning rate: 0.001
  Saving weights...
  Epoch 11, time total 1131.0688378810883s
  Epoch 11, time UNet: 126.08120465278625s
  Epoch 11, time metrics: 0.14067840576171875s
  Epoch 11, time saving files: 0.6458139419555664s
2023-11-30 14:57:31.131208
Start looping batches...
train Ep 12, Sp 160, loss 0.727419, t print 1.668s, t batch 0.083s
train Ep 12, Sp 320, loss 0.706068, t print 11.511s, t batch 0.576s
train Ep 12, Sp 480, loss 0.680207, t print 12.722s, t batch 0.636s
train Ep 12, Sp 640, loss 0.704773, t print 11.589s, t batch 0.579s
train Ep 12, Sp 800, loss 0.691377, t print 20.525s, t batch 1.026s
train Ep 12, Sp 960, loss 0.712197, t print 12.069s, t batch 0.603s
train Ep 12, Sp 1120, loss 0.715002, t print 11.236s, t batch 0.562s
train Ep 12, Sp 1280, loss 0.655971, t print 21.365s, t batch 1.068s
train Ep 12, Sp 1440, loss 0.696846, t print 11.979s, t batch 0.599s
train Ep 12, Sp 1600, loss 0.704241, t print 11.643s, t batch 0.582s
train Ep 12, Sp 1760, loss 0.683466, t print 20.013s, t batch 1.001s
train Ep 12, Sp 1920, loss 0.699227, t print 12.42s, t batch 0.621s
train Ep 12, Sp 2080, loss 0.69306, t print 11.526s, t batch 0.576s
train Ep 12, Sp 2240, loss 0.726781, t print 20.168s, t batch 1.008s
train Ep 12, Sp 2400, loss 0.673421, t print 12.709s, t batch 0.635s
train Ep 12, Sp 2560, loss 0.656299, t print 11.563s, t batch 0.578s
train Ep 12, Sp 2720, loss 0.693304, t print 19.405s, t batch 0.97s
train Ep 12, Sp 2880, loss 0.66814, t print 13.037s, t batch 0.652s
train Ep 12, Sp 3040, loss 0.687616, t print 11.381s, t batch 0.569s
train Ep 12, Sp 3200, loss 0.696271, t print 17.843s, t batch 0.892s
train Ep 12, Sp 3360, loss 0.694974, t print 14.973s, t batch 0.749s
train Ep 12, Sp 3520, loss 0.707795, t print 11.634s, t batch 0.582s
train Ep 12, Sp 3680, loss 0.690747, t print 16.158s, t batch 0.808s
train Ep 12, Sp 3840, loss 0.716457, t print 16.469s, t batch 0.823s
train Ep 12, Sp 4000, loss 0.708213, t print 11.101s, t batch 0.555s
train Ep 12, Sp 4160, loss 0.660426, t print 14.104s, t batch 0.705s
train Ep 12, Sp 4320, loss 0.665126, t print 18.213s, t batch 0.911s
train Ep 12, Sp 4480, loss 0.701489, t print 11.299s, t batch 0.565s
train Ep 12, Sp 4640, loss 0.711874, t print 12.856s, t batch 0.643s
train Ep 12, Sp 4800, loss 0.678573, t print 19.63s, t batch 0.982s
train Ep 12, Sp 4960, loss 0.696808, t print 11.213s, t batch 0.561s
train Ep 12, Sp 5120, loss 0.69813, t print 12.175s, t batch 0.609s
train Ep 12, Sp 5280, loss 0.678278, t print 20.509s, t batch 1.025s
train Ep 12, Sp 5440, loss 0.706881, t print 11.408s, t batch 0.57s
train Ep 12, Sp 5600, loss 0.709587, t print 11.466s, t batch 0.573s
train Ep 12, Sp 5760, loss 0.670904, t print 21.519s, t batch 1.076s
train Ep 12, Sp 5920, loss 0.653237, t print 11.516s, t batch 0.576s
train Ep 12, Sp 6080, loss 0.679679, t print 11.453s, t batch 0.573s
train Ep 12, Sp 6240, loss 0.664934, t print 21.114s, t batch 1.056s
train Ep 12, Sp 6400, loss 0.6873, t print 11.306s, t batch 0.565s
train Ep 12, Sp 6560, loss 0.708121, t print 11.41s, t batch 0.57s
train Ep 12, Sp 6720, loss 0.705533, t print 21.305s, t batch 1.065s
train Ep 12, Sp 6880, loss 0.737769, t print 11.447s, t batch 0.572s
train Ep 12, Sp 7040, loss 0.721368, t print 11.429s, t batch 0.571s
train Ep 12, Sp 7200, loss 0.731867, t print 21.116s, t batch 1.056s
train Ep 12, Sp 7360, loss 0.687325, t print 11.295s, t batch 0.565s
train Ep 12, Sp 7520, loss 0.640724, t print 11.479s, t batch 0.574s
train Ep 12, Sp 7680, loss 0.673463, t print 21.183s, t batch 1.059s
train Ep 12, Sp 7840, loss 0.702321, t print 11.379s, t batch 0.569s
train Ep 12, Sp 8000, loss 0.692075, t print 11.469s, t batch 0.573s
train Ep 12, Sp 8160, loss 0.713581, t print 21.122s, t batch 1.056s
train Ep 12, Sp 8320, loss 0.652862, t print 11.542s, t batch 0.577s
train Ep 12, Sp 8480, loss 0.656908, t print 11.496s, t batch 0.575s
train Ep 12, Sp 8640, loss 0.709304, t print 21.094s, t batch 1.055s
train Ep 12, Sp 8800, loss 0.693139, t print 11.462s, t batch 0.573s
train Ep 12, Sp 8960, loss 0.682246, t print 11.286s, t batch 0.564s
train Ep 12, Sp 9120, loss 0.645487, t print 21.105s, t batch 1.055s
train Ep 12, Sp 9280, loss 0.680974, t print 11.361s, t batch 0.568s
train Ep 12, Sp 9440, loss 0.679015, t print 11.426s, t batch 0.571s
train Ep 12, Sp 9600, loss 0.68573, t print 21.308s, t batch 1.065s
train Ep 12, Sp 9760, loss 0.721331, t print 11.731s, t batch 0.587s
train Ep 12, Sp 9920, loss 0.692805, t print 11.466s, t batch 0.573s
train Ep 12, Sp 10080, loss 0.680464, t print 21.616s, t batch 1.081s
train Ep 12, Sp 10240, loss 0.717278, t print 11.423s, t batch 0.571s
Start looping batches...
validate Ep 12, Sp 160, loss 0.678113, t print 1.093s, t batch 0.055s
validate Ep 12, Sp 320, loss 0.681897, t print 2140.593s, t batch 107.03s
validate Ep 12, Sp 480, loss 0.674978, t print 11.241s, t batch 0.562s
validate Ep 12, Sp 640, loss 0.681991, t print 10.822s, t batch 0.541s
validate Ep 12, Sp 800, loss 0.713457, t print 20.639s, t batch 1.032s
validate Ep 12, Sp 960, loss 0.722146, t print 11.061s, t batch 0.553s
validate Ep 12, Sp 1120, loss 0.660664, t print 10.787s, t batch 0.539s
validate Ep 12, Sp 1280, loss 0.693706, t print 21.31s, t batch 1.066s
validate Ep 12, Sp 1440, loss 0.660191, t print 11.358s, t batch 0.568s
validate Ep 12, Sp 1600, loss 0.706856, t print 11.204s, t batch 0.56s
validate Ep 12, Sp 1760, loss 0.674404, t print 21.197s, t batch 1.06s
validate Ep 12, Sp 1920, loss 0.70683, t print 11.1s, t batch 0.555s
validate Ep 12, Sp 2080, loss 0.693455, t print 11.088s, t batch 0.554s
validate Ep 12, Sp 2240, loss 0.699348, t print 20.868s, t batch 1.043s
validate Ep 12, Sp 2400, loss 0.701312, t print 10.958s, t batch 0.548s
  Epoch 12, Average Epoch loss = 0.6912203908518508
  Epoch 12, nr_of_updates 16848
current learning rate: 0.001
  Saving weights...
  Epoch 12, time total 3257.6193885803223s
  Epoch 12, time UNet: 124.14416360855103s
  Epoch 12, time metrics: 0.13526034355163574s
  Epoch 12, time saving files: 0.4002678394317627s
2023-11-30 15:51:48.758502
Start looping batches...
train Ep 13, Sp 160, loss 0.68127, t print 2.35s, t batch 0.117s
train Ep 13, Sp 320, loss 0.705048, t print 11.822s, t batch 0.591s
train Ep 13, Sp 480, loss 0.698171, t print 12.413s, t batch 0.621s
train Ep 13, Sp 640, loss 0.675257, t print 11.747s, t batch 0.587s
train Ep 13, Sp 800, loss 0.71631, t print 21.212s, t batch 1.061s
train Ep 13, Sp 960, loss 0.68364, t print 11.462s, t batch 0.573s
train Ep 13, Sp 1120, loss 0.689413, t print 11.484s, t batch 0.574s
train Ep 13, Sp 1280, loss 0.679459, t print 21.175s, t batch 1.059s
train Ep 13, Sp 1440, loss 0.692886, t print 11.293s, t batch 0.565s
train Ep 13, Sp 1600, loss 0.666459, t print 11.295s, t batch 0.565s
train Ep 13, Sp 1760, loss 0.686913, t print 20.613s, t batch 1.031s
train Ep 13, Sp 1920, loss 0.697964, t print 11.644s, t batch 0.582s
train Ep 13, Sp 2080, loss 0.703959, t print 11.426s, t batch 0.571s
train Ep 13, Sp 2240, loss 0.696598, t print 21.03s, t batch 1.051s
train Ep 13, Sp 2400, loss 0.694733, t print 11.506s, t batch 0.575s
train Ep 13, Sp 2560, loss 0.691465, t print 11.391s, t batch 0.57s
train Ep 13, Sp 2720, loss 0.68099, t print 21.222s, t batch 1.061s
train Ep 13, Sp 2880, loss 0.684791, t print 11.341s, t batch 0.567s
train Ep 13, Sp 3040, loss 0.690177, t print 11.333s, t batch 0.567s
train Ep 13, Sp 3200, loss 0.703658, t print 21.089s, t batch 1.054s
train Ep 13, Sp 3360, loss 0.729054, t print 11.316s, t batch 0.566s
train Ep 13, Sp 3520, loss 0.726697, t print 11.344s, t batch 0.567s
train Ep 13, Sp 3680, loss 0.721485, t print 20.826s, t batch 1.041s
train Ep 13, Sp 3840, loss 0.694301, t print 11.173s, t batch 0.559s
train Ep 13, Sp 4000, loss 0.702093, t print 11.071s, t batch 0.554s
train Ep 13, Sp 4160, loss 0.663397, t print 20.327s, t batch 1.016s
train Ep 13, Sp 4320, loss 0.689074, t print 12.217s, t batch 0.611s
train Ep 13, Sp 4480, loss 0.710854, t print 10.914s, t batch 0.546s
train Ep 13, Sp 4640, loss 0.677946, t print 19.009s, t batch 0.95s
train Ep 13, Sp 4800, loss 0.653991, t print 13.849s, t batch 0.692s
train Ep 13, Sp 4960, loss 0.719566, t print 11.392s, t batch 0.57s
train Ep 13, Sp 5120, loss 0.68437, t print 15.671s, t batch 0.784s
train Ep 13, Sp 5280, loss 0.686737, t print 17.218s, t batch 0.861s
train Ep 13, Sp 5440, loss 0.681786, t print 11.478s, t batch 0.574s
train Ep 13, Sp 5600, loss 0.655841, t print 12.221s, t batch 0.611s
train Ep 13, Sp 5760, loss 0.68973, t print 20.597s, t batch 1.03s
train Ep 13, Sp 5920, loss 0.683175, t print 11.337s, t batch 0.567s
train Ep 13, Sp 6080, loss 0.713153, t print 11.248s, t batch 0.562s
train Ep 13, Sp 6240, loss 0.70307, t print 21.17s, t batch 1.059s
train Ep 13, Sp 6400, loss 0.70315, t print 11.268s, t batch 0.563s
train Ep 13, Sp 6560, loss 0.669069, t print 11.357s, t batch 0.568s
train Ep 13, Sp 6720, loss 0.672054, t print 21.317s, t batch 1.066s
train Ep 13, Sp 6880, loss 0.69978, t print 11.314s, t batch 0.566s
train Ep 13, Sp 7040, loss 0.650283, t print 11.306s, t batch 0.565s
train Ep 13, Sp 7200, loss 0.670119, t print 21.267s, t batch 1.063s
train Ep 13, Sp 7360, loss 0.709047, t print 11.224s, t batch 0.561s
train Ep 13, Sp 7520, loss 0.674928, t print 11.32s, t batch 0.566s
train Ep 13, Sp 7680, loss 0.720744, t print 21.017s, t batch 1.051s
train Ep 13, Sp 7840, loss 0.685211, t print 11.272s, t batch 0.564s
train Ep 13, Sp 8000, loss 0.729423, t print 11.349s, t batch 0.567s
train Ep 13, Sp 8160, loss 0.678998, t print 20.878s, t batch 1.044s
train Ep 13, Sp 8320, loss 0.672533, t print 11.276s, t batch 0.564s
train Ep 13, Sp 8480, loss 0.701187, t print 11.324s, t batch 0.566s
train Ep 13, Sp 8640, loss 0.685942, t print 21.148s, t batch 1.057s
train Ep 13, Sp 8800, loss 0.705832, t print 11.243s, t batch 0.562s
train Ep 13, Sp 8960, loss 0.671231, t print 11.229s, t batch 0.561s
train Ep 13, Sp 9120, loss 0.718246, t print 21.052s, t batch 1.053s
train Ep 13, Sp 9280, loss 0.677087, t print 11.21s, t batch 0.561s
train Ep 13, Sp 9440, loss 0.668468, t print 11.208s, t batch 0.56s
train Ep 13, Sp 9600, loss 0.704701, t print 20.68s, t batch 1.034s
train Ep 13, Sp 9760, loss 0.690869, t print 11.076s, t batch 0.554s
train Ep 13, Sp 9920, loss 0.67742, t print 11.051s, t batch 0.553s
train Ep 13, Sp 10080, loss 0.6969, t print 20.468s, t batch 1.023s
train Ep 13, Sp 10240, loss 0.668438, t print 11.0s, t batch 0.55s
Start looping batches...
validate Ep 13, Sp 160, loss 0.693828, t print 1.018s, t batch 0.051s
validate Ep 13, Sp 320, loss 0.702828, t print 608.947s, t batch 30.447s
validate Ep 13, Sp 480, loss 0.662254, t print 11.581s, t batch 0.579s
validate Ep 13, Sp 640, loss 0.691638, t print 11.075s, t batch 0.554s
validate Ep 13, Sp 800, loss 0.683859, t print 20.632s, t batch 1.032s
validate Ep 13, Sp 960, loss 0.72777, t print 11.044s, t batch 0.552s
validate Ep 13, Sp 1120, loss 0.7241, t print 10.95s, t batch 0.548s
validate Ep 13, Sp 1280, loss 0.72292, t print 20.009s, t batch 1.0s
validate Ep 13, Sp 1440, loss 0.674547, t print 10.996s, t batch 0.55s
validate Ep 13, Sp 1600, loss 0.673284, t print 11.243s, t batch 0.562s
validate Ep 13, Sp 1760, loss 0.714468, t print 21.125s, t batch 1.056s
validate Ep 13, Sp 1920, loss 0.703837, t print 11.127s, t batch 0.556s
validate Ep 13, Sp 2080, loss 0.71329, t print 10.682s, t batch 0.534s
validate Ep 13, Sp 2240, loss 0.705313, t print 20.31s, t batch 1.015s
validate Ep 13, Sp 2400, loss 0.694096, t print 11.039s, t batch 0.552s
  Epoch 13, Average Epoch loss = 0.6905721441647152
  Epoch 13, nr_of_updates 18144
current learning rate: 0.001
  Epoch 13, time total 1715.3711833953857s
  Epoch 13, time UNet: 123.1062970161438s
  Epoch 13, time metrics: 0.136857271194458s
  Epoch 13, time saving files: 0.00021910667419433594s
2023-11-30 16:20:24.138206
Start looping batches...
train Ep 14, Sp 160, loss 0.664234, t print 1.862s, t batch 0.093s
train Ep 14, Sp 320, loss 0.671507, t print 11.095s, t batch 0.555s
train Ep 14, Sp 480, loss 0.693311, t print 13.738s, t batch 0.687s
train Ep 14, Sp 640, loss 0.67316, t print 11.796s, t batch 0.59s
train Ep 14, Sp 800, loss 0.677851, t print 19.265s, t batch 0.963s
train Ep 14, Sp 960, loss 0.674982, t print 13.83s, t batch 0.691s
train Ep 14, Sp 1120, loss 0.71826, t print 11.723s, t batch 0.586s
train Ep 14, Sp 1280, loss 0.668145, t print 17.065s, t batch 0.853s
train Ep 14, Sp 1440, loss 0.678942, t print 15.994s, t batch 0.8s
train Ep 14, Sp 1600, loss 0.677793, t print 11.47s, t batch 0.574s
train Ep 14, Sp 1760, loss 0.658224, t print 15.405s, t batch 0.77s
train Ep 14, Sp 1920, loss 0.705833, t print 17.429s, t batch 0.871s
train Ep 14, Sp 2080, loss 0.704115, t print 11.374s, t batch 0.569s
train Ep 14, Sp 2240, loss 0.684954, t print 13.944s, t batch 0.697s
train Ep 14, Sp 2400, loss 0.691586, t print 18.262s, t batch 0.913s
train Ep 14, Sp 2560, loss 0.646265, t print 11.747s, t batch 0.587s
train Ep 14, Sp 2720, loss 0.652472, t print 12.46s, t batch 0.623s
train Ep 14, Sp 2880, loss 0.675809, t print 19.661s, t batch 0.983s
train Ep 14, Sp 3040, loss 0.65993, t print 11.764s, t batch 0.588s
train Ep 14, Sp 3200, loss 0.663977, t print 11.492s, t batch 0.575s
train Ep 14, Sp 3360, loss 0.718852, t print 21.054s, t batch 1.053s
train Ep 14, Sp 3520, loss 0.676077, t print 11.611s, t batch 0.581s
train Ep 14, Sp 3680, loss 0.689453, t print 11.544s, t batch 0.577s
train Ep 14, Sp 3840, loss 0.683272, t print 21.399s, t batch 1.07s
train Ep 14, Sp 4000, loss 0.685112, t print 11.606s, t batch 0.58s
train Ep 14, Sp 4160, loss 0.677588, t print 11.186s, t batch 0.559s
train Ep 14, Sp 4320, loss 0.684392, t print 21.398s, t batch 1.07s
train Ep 14, Sp 4480, loss 0.725912, t print 11.752s, t batch 0.588s
train Ep 14, Sp 4640, loss 0.667837, t print 11.624s, t batch 0.581s
train Ep 14, Sp 4800, loss 0.67308, t print 21.128s, t batch 1.056s
train Ep 14, Sp 4960, loss 0.683832, t print 11.417s, t batch 0.571s
train Ep 14, Sp 5120, loss 0.704221, t print 11.487s, t batch 0.574s
train Ep 14, Sp 5280, loss 0.699944, t print 21.117s, t batch 1.056s
train Ep 14, Sp 5440, loss 0.683261, t print 11.38s, t batch 0.569s
train Ep 14, Sp 5600, loss 0.656714, t print 11.373s, t batch 0.569s
train Ep 14, Sp 5760, loss 0.693385, t print 21.146s, t batch 1.057s
train Ep 14, Sp 5920, loss 0.701729, t print 11.413s, t batch 0.571s
train Ep 14, Sp 6080, loss 0.700859, t print 11.196s, t batch 0.56s
train Ep 14, Sp 6240, loss 0.659933, t print 21.032s, t batch 1.052s
train Ep 14, Sp 6400, loss 0.715534, t print 11.451s, t batch 0.573s
train Ep 14, Sp 6560, loss 0.659464, t print 11.253s, t batch 0.563s
train Ep 14, Sp 6720, loss 0.665467, t print 20.885s, t batch 1.044s
train Ep 14, Sp 6880, loss 0.664559, t print 11.712s, t batch 0.586s
train Ep 14, Sp 7040, loss 0.687361, t print 11.362s, t batch 0.568s
train Ep 14, Sp 7200, loss 0.7101, t print 20.37s, t batch 1.019s
train Ep 14, Sp 7360, loss 0.723054, t print 11.761s, t batch 0.588s
train Ep 14, Sp 7520, loss 0.677195, t print 11.224s, t batch 0.561s
train Ep 14, Sp 7680, loss 0.725298, t print 19.577s, t batch 0.979s
train Ep 14, Sp 7840, loss 0.685469, t print 12.519s, t batch 0.626s
train Ep 14, Sp 8000, loss 0.670875, t print 11.207s, t batch 0.56s
train Ep 14, Sp 8160, loss 0.701319, t print 18.408s, t batch 0.92s
train Ep 14, Sp 8320, loss 0.702298, t print 13.428s, t batch 0.671s
train Ep 14, Sp 8480, loss 0.694026, t print 11.137s, t batch 0.557s
train Ep 14, Sp 8640, loss 0.66333, t print 17.006s, t batch 0.85s
train Ep 14, Sp 8800, loss 0.669737, t print 14.987s, t batch 0.749s
train Ep 14, Sp 8960, loss 0.667134, t print 11.121s, t batch 0.556s
train Ep 14, Sp 9120, loss 0.681629, t print 15.423s, t batch 0.771s
train Ep 14, Sp 9280, loss 0.698939, t print 16.285s, t batch 0.814s
train Ep 14, Sp 9440, loss 0.691934, t print 10.888s, t batch 0.544s
train Ep 14, Sp 9600, loss 0.694105, t print 14.267s, t batch 0.713s
train Ep 14, Sp 9760, loss 0.682409, t print 16.825s, t batch 0.841s
train Ep 14, Sp 9920, loss 0.73756, t print 10.824s, t batch 0.541s
train Ep 14, Sp 10080, loss 0.653478, t print 14.237s, t batch 0.712s
train Ep 14, Sp 10240, loss 0.67771, t print 16.386s, t batch 0.819s
Start looping batches...
validate Ep 14, Sp 160, loss 0.672935, t print 1.111s, t batch 0.056s
validate Ep 14, Sp 320, loss 0.678503, t print 11.26s, t batch 0.563s
validate Ep 14, Sp 480, loss 0.683063, t print 11.873s, t batch 0.594s
validate Ep 14, Sp 640, loss 0.687432, t print 10.786s, t batch 0.539s
validate Ep 14, Sp 800, loss 0.703526, t print 20.016s, t batch 1.001s
validate Ep 14, Sp 960, loss 0.693831, t print 11.955s, t batch 0.598s
validate Ep 14, Sp 1120, loss 0.685224, t print 10.8s, t batch 0.54s
validate Ep 14, Sp 1280, loss 0.65353, t print 18.793s, t batch 0.94s
validate Ep 14, Sp 1440, loss 0.712386, t print 12.787s, t batch 0.639s
validate Ep 14, Sp 1600, loss 0.707256, t print 10.935s, t batch 0.547s
validate Ep 14, Sp 1760, loss 0.69237, t print 17.523s, t batch 0.876s
validate Ep 14, Sp 1920, loss 0.704749, t print 13.86s, t batch 0.693s
validate Ep 14, Sp 2080, loss 0.685428, t print 11.137s, t batch 0.557s
validate Ep 14, Sp 2240, loss 0.681452, t print 15.907s, t batch 0.795s
validate Ep 14, Sp 2400, loss 0.687132, t print 14.698s, t batch 0.735s
  Epoch 14, Average Epoch loss = 0.6844927025613962
  Epoch 14, nr_of_updates 19440
current learning rate: 0.001
  Epoch 14, time total 1119.0065188407898s
  Epoch 14, time UNet: 125.29405927658081s
  Epoch 14, time metrics: 0.13677501678466797s
  Epoch 14, time saving files: 9.107589721679688e-05s
2023-11-30 16:39:03.152085
Start looping batches...
train Ep 15, Sp 160, loss 0.67355, t print 1.72s, t batch 0.086s
train Ep 15, Sp 320, loss 0.667513, t print 10.809s, t batch 0.54s
train Ep 15, Sp 480, loss 0.693383, t print 13.676s, t batch 0.684s
train Ep 15, Sp 640, loss 0.684319, t print 11.47s, t batch 0.573s
train Ep 15, Sp 800, loss 0.697593, t print 19.156s, t batch 0.958s
train Ep 15, Sp 960, loss 0.709779, t print 12.973s, t batch 0.649s
train Ep 15, Sp 1120, loss 0.661983, t print 11.089s, t batch 0.554s
train Ep 15, Sp 1280, loss 0.655876, t print 19.535s, t batch 0.977s
train Ep 15, Sp 1440, loss 0.692511, t print 12.358s, t batch 0.618s
train Ep 15, Sp 1600, loss 0.675736, t print 11.35s, t batch 0.568s
train Ep 15, Sp 1760, loss 0.685694, t print 19.098s, t batch 0.955s
train Ep 15, Sp 1920, loss 0.698462, t print 12.932s, t batch 0.647s
train Ep 15, Sp 2080, loss 0.675285, t print 11.244s, t batch 0.562s
train Ep 15, Sp 2240, loss 0.712199, t print 17.998s, t batch 0.9s
train Ep 15, Sp 2400, loss 0.69217, t print 14.34s, t batch 0.717s
train Ep 15, Sp 2560, loss 0.685379, t print 11.108s, t batch 0.555s
train Ep 15, Sp 2720, loss 0.686833, t print 16.701s, t batch 0.835s
train Ep 15, Sp 2880, loss 0.690473, t print 15.467s, t batch 0.773s
train Ep 15, Sp 3040, loss 0.71662, t print 11.067s, t batch 0.553s
train Ep 15, Sp 3200, loss 0.719604, t print 15.699s, t batch 0.785s
train Ep 15, Sp 3360, loss 0.674119, t print 16.379s, t batch 0.819s
train Ep 15, Sp 3520, loss 0.717173, t print 11.132s, t batch 0.557s
train Ep 15, Sp 3680, loss 0.718858, t print 14.872s, t batch 0.744s
train Ep 15, Sp 3840, loss 0.680564, t print 16.935s, t batch 0.847s
train Ep 15, Sp 4000, loss 0.688858, t print 11.068s, t batch 0.553s
train Ep 15, Sp 4160, loss 0.703596, t print 14.289s, t batch 0.714s
train Ep 15, Sp 4320, loss 0.667649, t print 17.681s, t batch 0.884s
train Ep 15, Sp 4480, loss 0.689164, t print 11.031s, t batch 0.552s
train Ep 15, Sp 4640, loss 0.709881, t print 13.471s, t batch 0.674s
train Ep 15, Sp 4800, loss 0.694489, t print 18.373s, t batch 0.919s
train Ep 15, Sp 4960, loss 0.691966, t print 11.021s, t batch 0.551s
train Ep 15, Sp 5120, loss 0.676351, t print 12.557s, t batch 0.628s
train Ep 15, Sp 5280, loss 0.705405, t print 18.87s, t batch 0.943s
train Ep 15, Sp 5440, loss 0.695924, t print 11.257s, t batch 0.563s
train Ep 15, Sp 5600, loss 0.727903, t print 11.908s, t batch 0.595s
train Ep 15, Sp 5760, loss 0.679599, t print 19.435s, t batch 0.972s
train Ep 15, Sp 5920, loss 0.692871, t print 11.752s, t batch 0.588s
train Ep 15, Sp 6080, loss 0.663223, t print 11.085s, t batch 0.554s
train Ep 15, Sp 6240, loss 0.681714, t print 18.862s, t batch 0.943s
train Ep 15, Sp 6400, loss 0.701399, t print 12.891s, t batch 0.645s
train Ep 15, Sp 6560, loss 0.701988, t print 11.176s, t batch 0.559s
train Ep 15, Sp 6720, loss 0.748406, t print 17.438s, t batch 0.872s
train Ep 15, Sp 6880, loss 0.691719, t print 14.244s, t batch 0.712s
train Ep 15, Sp 7040, loss 0.696165, t print 11.175s, t batch 0.559s
train Ep 15, Sp 7200, loss 0.714575, t print 15.985s, t batch 0.799s
train Ep 15, Sp 7360, loss 0.690103, t print 15.378s, t batch 0.769s
train Ep 15, Sp 7520, loss 0.680376, t print 11.242s, t batch 0.562s
train Ep 15, Sp 7680, loss 0.67892, t print 14.706s, t batch 0.735s
train Ep 15, Sp 7840, loss 0.713689, t print 17.217s, t batch 0.861s
train Ep 15, Sp 8000, loss 0.653203, t print 11.565s, t batch 0.578s
train Ep 15, Sp 8160, loss 0.709961, t print 12.333s, t batch 0.617s
train Ep 15, Sp 8320, loss 0.720094, t print 18.933s, t batch 0.947s
train Ep 15, Sp 8480, loss 0.65802, t print 11.795s, t batch 0.59s
train Ep 15, Sp 8640, loss 0.677404, t print 11.673s, t batch 0.584s
train Ep 15, Sp 8800, loss 0.645018, t print 18.875s, t batch 0.944s
train Ep 15, Sp 8960, loss 0.68686, t print 12.136s, t batch 0.607s
train Ep 15, Sp 9120, loss 0.712791, t print 11.469s, t batch 0.573s
train Ep 15, Sp 9280, loss 0.718575, t print 17.418s, t batch 0.871s
train Ep 15, Sp 9440, loss 0.675968, t print 14.07s, t batch 0.703s
train Ep 15, Sp 9600, loss 0.689749, t print 11.464s, t batch 0.573s
train Ep 15, Sp 9760, loss 0.705283, t print 15.856s, t batch 0.793s
train Ep 15, Sp 9920, loss 0.672141, t print 15.561s, t batch 0.778s
train Ep 15, Sp 10080, loss 0.689325, t print 11.831s, t batch 0.592s
train Ep 15, Sp 10240, loss 0.69414, t print 13.624s, t batch 0.681s
Start looping batches...
validate Ep 15, Sp 160, loss 0.694167, t print 0.981s, t batch 0.049s
validate Ep 15, Sp 320, loss 0.681392, t print 12.227s, t batch 0.611s
validate Ep 15, Sp 480, loss 0.69803, t print 11.678s, t batch 0.584s
validate Ep 15, Sp 640, loss 0.721081, t print 11.055s, t batch 0.553s
validate Ep 15, Sp 800, loss 0.688139, t print 20.288s, t batch 1.014s
validate Ep 15, Sp 960, loss 0.706667, t print 11.056s, t batch 0.553s
validate Ep 15, Sp 1120, loss 0.730526, t print 10.968s, t batch 0.548s
validate Ep 15, Sp 1280, loss 0.700762, t print 20.733s, t batch 1.037s
validate Ep 15, Sp 1440, loss 0.652107, t print 10.803s, t batch 0.54s
validate Ep 15, Sp 1600, loss 0.686148, t print 10.592s, t batch 0.53s
validate Ep 15, Sp 1760, loss 0.642871, t print 20.84s, t batch 1.042s
validate Ep 15, Sp 1920, loss 0.688011, t print 10.871s, t batch 0.544s
validate Ep 15, Sp 2080, loss 0.652577, t print 10.543s, t batch 0.527s
validate Ep 15, Sp 2240, loss 0.689889, t print 20.438s, t batch 1.022s
validate Ep 15, Sp 2400, loss 0.679609, t print 11.002s, t batch 0.55s
  Epoch 15, Average Epoch loss = 0.6917111892023204
  Epoch 15, nr_of_updates 20736
current learning rate: 0.001
  Epoch 15, time total 1097.1004438400269s
  Epoch 15, time UNet: 125.11185050010681s
  Epoch 15, time metrics: 0.1323719024658203s
  Epoch 15, time saving files: 0.00022840499877929688s
2023-11-30 16:57:20.259340
Start looping batches...
train Ep 16, Sp 160, loss 0.714303, t print 1.755s, t batch 0.088s
train Ep 16, Sp 320, loss 0.707654, t print 10.991s, t batch 0.55s
train Ep 16, Sp 480, loss 0.739393, t print 13.601s, t batch 0.68s
train Ep 16, Sp 640, loss 0.682761, t print 12.354s, t batch 0.618s
train Ep 16, Sp 800, loss 0.727541, t print 18.885s, t batch 0.944s
train Ep 16, Sp 960, loss 0.691728, t print 14.006s, t batch 0.7s
train Ep 16, Sp 1120, loss 0.711985, t print 11.454s, t batch 0.573s
train Ep 16, Sp 1280, loss 0.690549, t print 17.181s, t batch 0.859s
train Ep 16, Sp 1440, loss 0.687898, t print 15.811s, t batch 0.791s
train Ep 16, Sp 1600, loss 0.682359, t print 11.566s, t batch 0.578s
train Ep 16, Sp 1760, loss 0.620645, t print 15.122s, t batch 0.756s
train Ep 16, Sp 1920, loss 0.704463, t print 17.916s, t batch 0.896s
train Ep 16, Sp 2080, loss 0.714807, t print 11.663s, t batch 0.583s
train Ep 16, Sp 2240, loss 0.671027, t print 12.358s, t batch 0.618s
train Ep 16, Sp 2400, loss 0.699523, t print 20.839s, t batch 1.042s
train Ep 16, Sp 2560, loss 0.718337, t print 11.427s, t batch 0.571s
train Ep 16, Sp 2720, loss 0.675587, t print 11.386s, t batch 0.569s
train Ep 16, Sp 2880, loss 0.677532, t print 21.408s, t batch 1.07s
train Ep 16, Sp 3040, loss 0.710349, t print 11.302s, t batch 0.565s
train Ep 16, Sp 3200, loss 0.727529, t print 11.328s, t batch 0.566s
train Ep 16, Sp 3360, loss 0.683429, t print 21.018s, t batch 1.051s
train Ep 16, Sp 3520, loss 0.674797, t print 11.519s, t batch 0.576s
train Ep 16, Sp 3680, loss 0.67146, t print 11.322s, t batch 0.566s
train Ep 16, Sp 3840, loss 0.67495, t print 20.543s, t batch 1.027s
train Ep 16, Sp 4000, loss 0.656403, t print 11.614s, t batch 0.581s
train Ep 16, Sp 4160, loss 0.69614, t print 11.109s, t batch 0.555s
train Ep 16, Sp 4320, loss 0.667848, t print 19.561s, t batch 0.978s
train Ep 16, Sp 4480, loss 0.699337, t print 12.78s, t batch 0.639s
train Ep 16, Sp 4640, loss 0.695365, t print 11.023s, t batch 0.551s
train Ep 16, Sp 4800, loss 0.694844, t print 17.761s, t batch 0.888s
train Ep 16, Sp 4960, loss 0.673991, t print 14.372s, t batch 0.719s
train Ep 16, Sp 5120, loss 0.688508, t print 11.31s, t batch 0.565s
train Ep 16, Sp 5280, loss 0.72327, t print 15.949s, t batch 0.797s
train Ep 16, Sp 5440, loss 0.693321, t print 15.891s, t batch 0.795s
train Ep 16, Sp 5600, loss 0.697335, t print 11.141s, t batch 0.557s
train Ep 16, Sp 5760, loss 0.689179, t print 14.537s, t batch 0.727s
train Ep 16, Sp 5920, loss 0.697958, t print 17.501s, t batch 0.875s
train Ep 16, Sp 6080, loss 0.682722, t print 11.108s, t batch 0.555s
train Ep 16, Sp 6240, loss 0.634058, t print 12.974s, t batch 0.649s
train Ep 16, Sp 6400, loss 0.676245, t print 19.014s, t batch 0.951s
train Ep 16, Sp 6560, loss 0.70065, t print 11.136s, t batch 0.557s
train Ep 16, Sp 6720, loss 0.670091, t print 11.942s, t batch 0.597s
train Ep 16, Sp 6880, loss 0.66977, t print 19.591s, t batch 0.98s
train Ep 16, Sp 7040, loss 0.675476, t print 11.147s, t batch 0.557s
train Ep 16, Sp 7200, loss 0.678483, t print 11.285s, t batch 0.564s
train Ep 16, Sp 7360, loss 0.700886, t print 20.391s, t batch 1.02s
train Ep 16, Sp 7520, loss 0.660141, t print 11.337s, t batch 0.567s
train Ep 16, Sp 7680, loss 0.689, t print 11.143s, t batch 0.557s
train Ep 16, Sp 7840, loss 0.713547, t print 20.902s, t batch 1.045s
train Ep 16, Sp 8000, loss 0.682267, t print 11.445s, t batch 0.572s
train Ep 16, Sp 8160, loss 0.714095, t print 11.224s, t batch 0.561s
train Ep 16, Sp 8320, loss 0.687911, t print 21.138s, t batch 1.057s
train Ep 16, Sp 8480, loss 0.699144, t print 11.443s, t batch 0.572s
train Ep 16, Sp 8640, loss 0.700107, t print 11.272s, t batch 0.564s
train Ep 16, Sp 8800, loss 0.656055, t print 21.219s, t batch 1.061s
train Ep 16, Sp 8960, loss 0.682104, t print 11.396s, t batch 0.57s
train Ep 16, Sp 9120, loss 0.646642, t print 11.32s, t batch 0.566s
train Ep 16, Sp 9280, loss 0.70757, t print 21.05s, t batch 1.052s
train Ep 16, Sp 9440, loss 0.689869, t print 11.385s, t batch 0.569s
train Ep 16, Sp 9600, loss 0.687472, t print 11.261s, t batch 0.563s
train Ep 16, Sp 9760, loss 0.702986, t print 20.644s, t batch 1.032s
train Ep 16, Sp 9920, loss 0.678965, t print 11.03s, t batch 0.552s
train Ep 16, Sp 10080, loss 0.666099, t print 10.979s, t batch 0.549s
train Ep 16, Sp 10240, loss 0.705995, t print 20.573s, t batch 1.029s
Start looping batches...
validate Ep 16, Sp 160, loss 0.697055, t print 0.981s, t batch 0.049s
validate Ep 16, Sp 320, loss 0.673539, t print 157.196s, t batch 7.86s
validate Ep 16, Sp 480, loss 0.667485, t print 11.255s, t batch 0.563s
validate Ep 16, Sp 640, loss 0.661464, t print 10.956s, t batch 0.548s
validate Ep 16, Sp 800, loss 0.685759, t print 20.658s, t batch 1.033s
validate Ep 16, Sp 960, loss 0.653405, t print 11.194s, t batch 0.56s
validate Ep 16, Sp 1120, loss 0.707034, t print 10.796s, t batch 0.54s
validate Ep 16, Sp 1280, loss 0.687916, t print 19.563s, t batch 0.978s
validate Ep 16, Sp 1440, loss 0.683207, t print 11.666s, t batch 0.583s
validate Ep 16, Sp 1600, loss 0.673, t print 10.707s, t batch 0.535s
validate Ep 16, Sp 1760, loss 0.687889, t print 17.712s, t batch 0.886s
validate Ep 16, Sp 1920, loss 0.742252, t print 13.116s, t batch 0.656s
validate Ep 16, Sp 2080, loss 0.689459, t print 10.61s, t batch 0.53s
validate Ep 16, Sp 2240, loss 0.679398, t print 15.366s, t batch 0.768s
validate Ep 16, Sp 2400, loss 0.693878, t print 15.395s, t batch 0.77s
  Epoch 16, Average Epoch loss = 0.6894344715056596
  Epoch 16, nr_of_updates 22032
current learning rate: 0.001
  Epoch 16, time total 1259.8010034561157s
  Epoch 16, time UNet: 123.48714113235474s
  Epoch 16, time metrics: 0.13279390335083008s
  Epoch 16, time saving files: 0.0001595020294189453s
2023-11-30 17:18:20.069913
Start looping batches...
train Ep 17, Sp 160, loss 0.698099, t print 1.704s, t batch 0.085s
train Ep 17, Sp 320, loss 0.66419, t print 11.158s, t batch 0.558s
train Ep 17, Sp 480, loss 0.721287, t print 13.417s, t batch 0.671s
train Ep 17, Sp 640, loss 0.704656, t print 11.89s, t batch 0.594s
train Ep 17, Sp 800, loss 0.690996, t print 18.264s, t batch 0.913s
train Ep 17, Sp 960, loss 0.718465, t print 14.266s, t batch 0.713s
train Ep 17, Sp 1120, loss 0.685855, t print 11.319s, t batch 0.566s
train Ep 17, Sp 1280, loss 0.670699, t print 15.64s, t batch 0.782s
train Ep 17, Sp 1440, loss 0.684763, t print 16.38s, t batch 0.819s
train Ep 17, Sp 1600, loss 0.677076, t print 11.246s, t batch 0.562s
train Ep 17, Sp 1760, loss 0.680514, t print 13.351s, t batch 0.668s
train Ep 17, Sp 1920, loss 0.679547, t print 18.629s, t batch 0.931s
train Ep 17, Sp 2080, loss 0.676377, t print 11.273s, t batch 0.564s
train Ep 17, Sp 2240, loss 0.671606, t print 11.765s, t batch 0.588s
train Ep 17, Sp 2400, loss 0.692306, t print 20.829s, t batch 1.041s
train Ep 17, Sp 2560, loss 0.663761, t print 11.55s, t batch 0.578s
train Ep 17, Sp 2720, loss 0.687609, t print 11.331s, t batch 0.567s
train Ep 17, Sp 2880, loss 0.675367, t print 21.231s, t batch 1.062s
train Ep 17, Sp 3040, loss 0.695984, t print 11.416s, t batch 0.571s
train Ep 17, Sp 3200, loss 0.714908, t print 11.452s, t batch 0.573s
train Ep 17, Sp 3360, loss 0.667381, t print 21.157s, t batch 1.058s
train Ep 17, Sp 3520, loss 0.667309, t print 11.047s, t batch 0.552s
train Ep 17, Sp 3680, loss 0.688707, t print 11.461s, t batch 0.573s
train Ep 17, Sp 3840, loss 0.67379, t print 21.267s, t batch 1.063s
train Ep 17, Sp 4000, loss 0.686165, t print 11.467s, t batch 0.573s
train Ep 17, Sp 4160, loss 0.637178, t print 11.348s, t batch 0.567s
train Ep 17, Sp 4320, loss 0.685734, t print 21.306s, t batch 1.065s
train Ep 17, Sp 4480, loss 0.686123, t print 11.487s, t batch 0.574s
train Ep 17, Sp 4640, loss 0.681056, t print 11.501s, t batch 0.575s
train Ep 17, Sp 4800, loss 0.655242, t print 21.114s, t batch 1.056s
train Ep 17, Sp 4960, loss 0.679725, t print 11.448s, t batch 0.572s
train Ep 17, Sp 5120, loss 0.689591, t print 11.366s, t batch 0.568s
train Ep 17, Sp 5280, loss 0.673674, t print 20.942s, t batch 1.047s
train Ep 17, Sp 5440, loss 0.640055, t print 11.27s, t batch 0.564s
train Ep 17, Sp 5600, loss 0.65952, t print 11.213s, t batch 0.561s
train Ep 17, Sp 5760, loss 0.703624, t print 20.871s, t batch 1.044s
train Ep 17, Sp 5920, loss 0.699888, t print 11.237s, t batch 0.562s
train Ep 17, Sp 6080, loss 0.659842, t print 11.238s, t batch 0.562s
train Ep 17, Sp 6240, loss 0.685141, t print 20.74s, t batch 1.037s
train Ep 17, Sp 6400, loss 0.718772, t print 11.298s, t batch 0.565s
train Ep 17, Sp 6560, loss 0.717512, t print 11.244s, t batch 0.562s
train Ep 17, Sp 6720, loss 0.70624, t print 20.617s, t batch 1.031s
train Ep 17, Sp 6880, loss 0.649037, t print 11.217s, t batch 0.561s
train Ep 17, Sp 7040, loss 0.676346, t print 11.134s, t batch 0.557s
train Ep 17, Sp 7200, loss 0.710666, t print 20.759s, t batch 1.038s
train Ep 17, Sp 7360, loss 0.66773, t print 11.23s, t batch 0.561s
train Ep 17, Sp 7520, loss 0.675715, t print 11.297s, t batch 0.565s
train Ep 17, Sp 7680, loss 0.685228, t print 20.967s, t batch 1.048s
train Ep 17, Sp 7840, loss 0.683936, t print 11.219s, t batch 0.561s
train Ep 17, Sp 8000, loss 0.677079, t print 11.192s, t batch 0.56s
train Ep 17, Sp 8160, loss 0.736179, t print 21.0s, t batch 1.05s
train Ep 17, Sp 8320, loss 0.697961, t print 11.302s, t batch 0.565s
train Ep 17, Sp 8480, loss 0.718735, t print 11.435s, t batch 0.572s
train Ep 17, Sp 8640, loss 0.718679, t print 20.951s, t batch 1.048s
train Ep 17, Sp 8800, loss 0.679046, t print 11.314s, t batch 0.566s
train Ep 17, Sp 8960, loss 0.649106, t print 11.221s, t batch 0.561s
train Ep 17, Sp 9120, loss 0.696752, t print 20.793s, t batch 1.04s
train Ep 17, Sp 9280, loss 0.685463, t print 11.172s, t batch 0.559s
train Ep 17, Sp 9440, loss 0.671253, t print 11.156s, t batch 0.558s
train Ep 17, Sp 9600, loss 0.681794, t print 20.766s, t batch 1.038s
train Ep 17, Sp 9760, loss 0.704728, t print 11.109s, t batch 0.555s
train Ep 17, Sp 9920, loss 0.674875, t print 10.977s, t batch 0.549s
train Ep 17, Sp 10080, loss 0.697377, t print 19.922s, t batch 0.996s
train Ep 17, Sp 10240, loss 0.652092, t print 10.868s, t batch 0.543s
Start looping batches...
validate Ep 17, Sp 160, loss 0.663211, t print 1.035s, t batch 0.052s
validate Ep 17, Sp 320, loss 0.710097, t print 808.189s, t batch 40.409s
validate Ep 17, Sp 480, loss 0.685858, t print 7.201s, t batch 0.36s
validate Ep 17, Sp 640, loss 0.726041, t print 11.218s, t batch 0.561s
validate Ep 17, Sp 800, loss 0.706775, t print 20.52s, t batch 1.026s
validate Ep 17, Sp 960, loss 0.684981, t print 11.148s, t batch 0.557s
validate Ep 17, Sp 1120, loss 0.665285, t print 10.836s, t batch 0.542s
validate Ep 17, Sp 1280, loss 0.715966, t print 20.683s, t batch 1.034s
validate Ep 17, Sp 1440, loss 0.690234, t print 10.999s, t batch 0.55s
validate Ep 17, Sp 1600, loss 0.68, t print 10.739s, t batch 0.537s
validate Ep 17, Sp 1760, loss 0.706603, t print 20.548s, t batch 1.027s
validate Ep 17, Sp 1920, loss 0.679411, t print 11.006s, t batch 0.55s
validate Ep 17, Sp 2080, loss 0.696879, t print 10.788s, t batch 0.539s
validate Ep 17, Sp 2240, loss 0.682512, t print 20.557s, t batch 1.028s
validate Ep 17, Sp 2400, loss 0.686898, t print 10.822s, t batch 0.541s
  Epoch 17, Average Epoch loss = 0.6852466856807838
  Epoch 17, nr_of_updates 23328
current learning rate: 0.001
  Epoch 17, time total 1905.8316142559052s
  Epoch 17, time UNet: 126.63438129425049s
  Epoch 17, time metrics: 0.12609601020812988s
  Epoch 17, time saving files: 0.018588781356811523s
2023-11-30 17:50:05.909369
Start looping batches...
train Ep 18, Sp 160, loss 0.688902, t print 4.243s, t batch 0.212s
train Ep 18, Sp 320, loss 0.665121, t print 10.825s, t batch 0.541s
train Ep 18, Sp 480, loss 0.681544, t print 13.009s, t batch 0.65s
train Ep 18, Sp 640, loss 0.66978, t print 11.73s, t batch 0.587s
train Ep 18, Sp 800, loss 0.682504, t print 18.265s, t batch 0.913s
train Ep 18, Sp 960, loss 0.692055, t print 13.655s, t batch 0.683s
train Ep 18, Sp 1120, loss 0.689414, t print 11.499s, t batch 0.575s
train Ep 18, Sp 1280, loss 0.692074, t print 15.819s, t batch 0.791s
train Ep 18, Sp 1440, loss 0.700746, t print 15.358s, t batch 0.768s
train Ep 18, Sp 1600, loss 0.685951, t print 11.844s, t batch 0.592s
train Ep 18, Sp 1760, loss 0.706972, t print 13.608s, t batch 0.68s
train Ep 18, Sp 1920, loss 0.651696, t print 17.283s, t batch 0.864s
train Ep 18, Sp 2080, loss 0.670615, t print 12.838s, t batch 0.642s
train Ep 18, Sp 2240, loss 0.682021, t print 11.068s, t batch 0.553s
train Ep 18, Sp 2400, loss 0.620948, t print 18.451s, t batch 0.923s
train Ep 18, Sp 2560, loss 0.689697, t print 13.938s, t batch 0.697s
train Ep 18, Sp 2720, loss 0.692129, t print 11.29s, t batch 0.565s
train Ep 18, Sp 2880, loss 0.663299, t print 16.63s, t batch 0.832s
train Ep 18, Sp 3040, loss 0.692533, t print 15.819s, t batch 0.791s
train Ep 18, Sp 3200, loss 0.645102, t print 11.444s, t batch 0.572s
train Ep 18, Sp 3360, loss 0.703151, t print 14.357s, t batch 0.718s
train Ep 18, Sp 3520, loss 0.688497, t print 18.079s, t batch 0.904s
train Ep 18, Sp 3680, loss 0.688538, t print 11.256s, t batch 0.563s
train Ep 18, Sp 3840, loss 0.676167, t print 12.001s, t batch 0.6s
train Ep 18, Sp 4000, loss 0.696867, t print 20.147s, t batch 1.007s
train Ep 18, Sp 4160, loss 0.686145, t print 11.241s, t batch 0.562s
train Ep 18, Sp 4320, loss 0.663694, t print 11.299s, t batch 0.565s
train Ep 18, Sp 4480, loss 0.693168, t print 20.86s, t batch 1.043s
train Ep 18, Sp 4640, loss 0.6693, t print 11.354s, t batch 0.568s
train Ep 18, Sp 4800, loss 0.681347, t print 11.2s, t batch 0.56s
train Ep 18, Sp 4960, loss 0.698659, t print 20.766s, t batch 1.038s
train Ep 18, Sp 5120, loss 0.667072, t print 11.232s, t batch 0.562s
train Ep 18, Sp 5280, loss 0.674454, t print 11.061s, t batch 0.553s
train Ep 18, Sp 5440, loss 0.677836, t print 20.692s, t batch 1.035s
train Ep 18, Sp 5600, loss 0.700252, t print 11.186s, t batch 0.559s
train Ep 18, Sp 5760, loss 0.698364, t print 11.253s, t batch 0.563s
train Ep 18, Sp 5920, loss 0.695533, t print 20.614s, t batch 1.031s
train Ep 18, Sp 6080, loss 0.689087, t print 11.068s, t batch 0.553s
train Ep 18, Sp 6240, loss 0.69227, t print 10.967s, t batch 0.548s
train Ep 18, Sp 6400, loss 0.681661, t print 20.75s, t batch 1.037s
train Ep 18, Sp 6560, loss 0.676051, t print 11.038s, t batch 0.552s
train Ep 18, Sp 6720, loss 0.684095, t print 11.095s, t batch 0.555s
train Ep 18, Sp 6880, loss 0.71232, t print 20.613s, t batch 1.031s
train Ep 18, Sp 7040, loss 0.706281, t print 11.152s, t batch 0.558s
train Ep 18, Sp 7200, loss 0.695534, t print 11.216s, t batch 0.561s
train Ep 18, Sp 7360, loss 0.681099, t print 20.652s, t batch 1.033s
train Ep 18, Sp 7520, loss 0.73299, t print 11.207s, t batch 0.56s
train Ep 18, Sp 7680, loss 0.6727, t print 10.917s, t batch 0.546s
train Ep 18, Sp 7840, loss 0.701049, t print 20.909s, t batch 1.045s
train Ep 18, Sp 8000, loss 0.672083, t print 11.297s, t batch 0.565s
train Ep 18, Sp 8160, loss 0.688652, t print 11.281s, t batch 0.564s
train Ep 18, Sp 8320, loss 0.666767, t print 21.466s, t batch 1.073s
train Ep 18, Sp 8480, loss 0.650134, t print 11.518s, t batch 0.576s
train Ep 18, Sp 8640, loss 0.676222, t print 11.331s, t batch 0.567s
train Ep 18, Sp 8800, loss 0.709195, t print 20.979s, t batch 1.049s
train Ep 18, Sp 8960, loss 0.68302, t print 11.527s, t batch 0.576s
train Ep 18, Sp 9120, loss 0.702569, t print 11.363s, t batch 0.568s
train Ep 18, Sp 9280, loss 0.674259, t print 21.075s, t batch 1.054s
train Ep 18, Sp 9440, loss 0.686973, t print 11.251s, t batch 0.563s
train Ep 18, Sp 9600, loss 0.664867, t print 11.236s, t batch 0.562s
train Ep 18, Sp 9760, loss 0.680431, t print 20.811s, t batch 1.041s
train Ep 18, Sp 9920, loss 0.681316, t print 11.16s, t batch 0.558s
train Ep 18, Sp 10080, loss 0.69975, t print 11.008s, t batch 0.55s
train Ep 18, Sp 10240, loss 0.698796, t print 20.796s, t batch 1.04s
Start looping batches...
validate Ep 18, Sp 160, loss 0.692845, t print 0.982s, t batch 0.049s
validate Ep 18, Sp 320, loss 0.70297, t print 338.807s, t batch 16.94s
validate Ep 18, Sp 480, loss 0.70686, t print 10.879s, t batch 0.544s
validate Ep 18, Sp 640, loss 0.730161, t print 10.941s, t batch 0.547s
validate Ep 18, Sp 800, loss 0.687214, t print 20.423s, t batch 1.021s
validate Ep 18, Sp 960, loss 0.671554, t print 11.067s, t batch 0.553s
validate Ep 18, Sp 1120, loss 0.712657, t print 10.856s, t batch 0.543s
validate Ep 18, Sp 1280, loss 0.623765, t print 20.92s, t batch 1.046s
validate Ep 18, Sp 1440, loss 0.703858, t print 10.919s, t batch 0.546s
validate Ep 18, Sp 1600, loss 0.661814, t print 10.762s, t batch 0.538s
validate Ep 18, Sp 1760, loss 0.717827, t print 20.556s, t batch 1.028s
validate Ep 18, Sp 1920, loss 0.726549, t print 10.86s, t batch 0.543s
validate Ep 18, Sp 2080, loss 0.689165, t print 10.633s, t batch 0.532s
validate Ep 18, Sp 2240, loss 0.681213, t print 20.273s, t batch 1.014s
validate Ep 18, Sp 2400, loss 0.694694, t print 10.733s, t batch 0.537s
  Epoch 18, Average Epoch loss = 0.6841196609132084
  Epoch 18, nr_of_updates 24624
current learning rate: 0.001
  Epoch 18, time total 1438.1801722049713s
  Epoch 18, time UNet: 125.83580422401428s
  Epoch 18, time metrics: 0.11916351318359375s
  Epoch 18, time saving files: 0.00029587745666503906s
2023-11-30 18:14:04.097557
Start looping batches...
train Ep 19, Sp 160, loss 0.717111, t print 1.871s, t batch 0.094s
train Ep 19, Sp 320, loss 0.656359, t print 11.171s, t batch 0.559s
train Ep 19, Sp 480, loss 0.681645, t print 12.278s, t batch 0.614s
train Ep 19, Sp 640, loss 0.662365, t print 11.723s, t batch 0.586s
train Ep 19, Sp 800, loss 0.674195, t print 20.958s, t batch 1.048s
train Ep 19, Sp 960, loss 0.645061, t print 11.622s, t batch 0.581s
train Ep 19, Sp 1120, loss 0.695382, t print 11.376s, t batch 0.569s
train Ep 19, Sp 1280, loss 0.710346, t print 20.793s, t batch 1.04s
train Ep 19, Sp 1440, loss 0.706662, t print 11.844s, t batch 0.592s
train Ep 19, Sp 1600, loss 0.684794, t print 11.274s, t batch 0.564s
train Ep 19, Sp 1760, loss 0.662145, t print 19.91s, t batch 0.995s
train Ep 19, Sp 1920, loss 0.655993, t print 12.385s, t batch 0.619s
train Ep 19, Sp 2080, loss 0.712928, t print 11.217s, t batch 0.561s
train Ep 19, Sp 2240, loss 0.724876, t print 18.089s, t batch 0.904s
train Ep 19, Sp 2400, loss 0.71548, t print 13.682s, t batch 0.684s
train Ep 19, Sp 2560, loss 0.65996, t print 11.162s, t batch 0.558s
train Ep 19, Sp 2720, loss 0.684351, t print 16.939s, t batch 0.847s
train Ep 19, Sp 2880, loss 0.694242, t print 14.823s, t batch 0.741s
train Ep 19, Sp 3040, loss 0.673052, t print 11.342s, t batch 0.567s
train Ep 19, Sp 3200, loss 0.677475, t print 16.449s, t batch 0.822s
train Ep 19, Sp 3360, loss 0.718114, t print 15.679s, t batch 0.784s
train Ep 19, Sp 3520, loss 0.68331, t print 11.205s, t batch 0.56s
train Ep 19, Sp 3680, loss 0.673304, t print 15.256s, t batch 0.763s
train Ep 19, Sp 3840, loss 0.702246, t print 16.645s, t batch 0.832s
train Ep 19, Sp 4000, loss 0.703322, t print 11.246s, t batch 0.562s
train Ep 19, Sp 4160, loss 0.662964, t print 13.986s, t batch 0.699s
train Ep 19, Sp 4320, loss 0.644754, t print 17.631s, t batch 0.882s
train Ep 19, Sp 4480, loss 0.66719, t print 11.249s, t batch 0.562s
train Ep 19, Sp 4640, loss 0.645665, t print 13.091s, t batch 0.655s
train Ep 19, Sp 4800, loss 0.705456, t print 18.669s, t batch 0.933s
train Ep 19, Sp 4960, loss 0.680185, t print 11.087s, t batch 0.554s
train Ep 19, Sp 5120, loss 0.680504, t print 12.52s, t batch 0.626s
train Ep 19, Sp 5280, loss 0.722568, t print 18.83s, t batch 0.942s
train Ep 19, Sp 5440, loss 0.678271, t print 11.135s, t batch 0.557s
train Ep 19, Sp 5600, loss 0.71319, t print 12.072s, t batch 0.604s
train Ep 19, Sp 5760, loss 0.695837, t print 19.935s, t batch 0.997s
train Ep 19, Sp 5920, loss 0.704701, t print 11.101s, t batch 0.555s
train Ep 19, Sp 6080, loss 0.703422, t print 11.718s, t batch 0.586s
train Ep 19, Sp 6240, loss 0.692813, t print 20.329s, t batch 1.016s
train Ep 19, Sp 6400, loss 0.699607, t print 11.14s, t batch 0.557s
train Ep 19, Sp 6560, loss 0.69208, t print 11.41s, t batch 0.571s
train Ep 19, Sp 6720, loss 0.730897, t print 20.072s, t batch 1.004s
train Ep 19, Sp 6880, loss 0.690014, t print 10.972s, t batch 0.549s
train Ep 19, Sp 7040, loss 0.697916, t print 11.447s, t batch 0.572s
train Ep 19, Sp 7200, loss 0.665512, t print 20.264s, t batch 1.013s
train Ep 19, Sp 7360, loss 0.7268, t print 11.102s, t batch 0.555s
train Ep 19, Sp 7520, loss 0.736387, t print 11.414s, t batch 0.571s
train Ep 19, Sp 7680, loss 0.665409, t print 20.038s, t batch 1.002s
train Ep 19, Sp 7840, loss 0.684043, t print 11.05s, t batch 0.552s
train Ep 19, Sp 8000, loss 0.669169, t print 11.858s, t batch 0.593s
train Ep 19, Sp 8160, loss 0.689906, t print 19.301s, t batch 0.965s
train Ep 19, Sp 8320, loss 0.675589, t print 10.885s, t batch 0.544s
train Ep 19, Sp 8480, loss 0.67415, t print 12.174s, t batch 0.609s
train Ep 19, Sp 8640, loss 0.686429, t print 18.529s, t batch 0.926s
train Ep 19, Sp 8800, loss 0.709773, t print 11.043s, t batch 0.552s
train Ep 19, Sp 8960, loss 0.734846, t print 12.743s, t batch 0.637s
train Ep 19, Sp 9120, loss 0.712818, t print 18.133s, t batch 0.907s
train Ep 19, Sp 9280, loss 0.704865, t print 10.712s, t batch 0.536s
train Ep 19, Sp 9440, loss 0.703072, t print 13.48s, t batch 0.674s
train Ep 19, Sp 9600, loss 0.689107, t print 17.25s, t batch 0.863s
train Ep 19, Sp 9760, loss 0.696607, t print 10.878s, t batch 0.544s
train Ep 19, Sp 9920, loss 0.66949, t print 14.255s, t batch 0.713s
train Ep 19, Sp 10080, loss 0.680584, t print 16.93s, t batch 0.847s
train Ep 19, Sp 10240, loss 0.715265, t print 10.687s, t batch 0.534s
Start looping batches...
validate Ep 19, Sp 160, loss 0.713856, t print 1.001s, t batch 0.05s
validate Ep 19, Sp 320, loss 0.709267, t print 11.699s, t batch 0.585s
validate Ep 19, Sp 480, loss 0.696792, t print 11.879s, t batch 0.594s
validate Ep 19, Sp 640, loss 0.723923, t print 11.154s, t batch 0.558s
validate Ep 19, Sp 800, loss 0.678716, t print 19.892s, t batch 0.995s
validate Ep 19, Sp 960, loss 0.674396, t print 12.154s, t batch 0.608s
validate Ep 19, Sp 1120, loss 0.683489, t print 11.144s, t batch 0.557s
validate Ep 19, Sp 1280, loss 0.722059, t print 17.816s, t batch 0.891s
validate Ep 19, Sp 1440, loss 0.694732, t print 14.559s, t batch 0.728s
validate Ep 19, Sp 1600, loss 0.65231, t print 11.271s, t batch 0.564s
validate Ep 19, Sp 1760, loss 0.739719, t print 15.04s, t batch 0.752s
validate Ep 19, Sp 1920, loss 0.720675, t print 17.764s, t batch 0.888s
validate Ep 19, Sp 2080, loss 0.687559, t print 11.187s, t batch 0.559s
validate Ep 19, Sp 2240, loss 0.696649, t print 11.433s, t batch 0.572s
validate Ep 19, Sp 2400, loss 0.678581, t print 20.884s, t batch 1.044s
  Epoch 19, Average Epoch loss = 0.6898651244463744
  Epoch 19, nr_of_updates 25920
current learning rate: 0.001
  Epoch 19, time total 1102.1648976802826s
  Epoch 19, time UNet: 124.76131200790405s
  Epoch 19, time metrics: 0.12390851974487305s
  Epoch 19, time saving files: 0.00010013580322265625s
2023-11-30 18:32:26.269282
Start looping batches...
train Ep 20, Sp 160, loss 0.653638, t print 1.595s, t batch 0.08s
train Ep 20, Sp 320, loss 0.630571, t print 194.824s, t batch 9.741s
train Ep 20, Sp 480, loss 0.658653, t print 12.488s, t batch 0.624s
train Ep 20, Sp 640, loss 0.709704, t print 11.648s, t batch 0.582s
train Ep 20, Sp 800, loss 0.684621, t print 20.989s, t batch 1.049s
train Ep 20, Sp 960, loss 0.672387, t print 11.499s, t batch 0.575s
train Ep 20, Sp 1120, loss 0.666877, t print 11.638s, t batch 0.582s
train Ep 20, Sp 1280, loss 0.669845, t print 21.859s, t batch 1.093s
train Ep 20, Sp 1440, loss 0.644689, t print 11.495s, t batch 0.575s
train Ep 20, Sp 1600, loss 0.681657, t print 11.621s, t batch 0.581s
train Ep 20, Sp 1760, loss 0.683455, t print 21.706s, t batch 1.085s
train Ep 20, Sp 1920, loss 0.681344, t print 11.615s, t batch 0.581s
train Ep 20, Sp 2080, loss 0.665507, t print 11.668s, t batch 0.583s
train Ep 20, Sp 2240, loss 0.716736, t print 20.804s, t batch 1.04s
train Ep 20, Sp 2400, loss 0.677741, t print 11.212s, t batch 0.561s
train Ep 20, Sp 2560, loss 0.666142, t print 11.472s, t batch 0.574s
train Ep 20, Sp 2720, loss 0.721234, t print 21.088s, t batch 1.054s
train Ep 20, Sp 2880, loss 0.606354, t print 11.439s, t batch 0.572s
train Ep 20, Sp 3040, loss 0.684315, t print 11.344s, t batch 0.567s
train Ep 20, Sp 3200, loss 0.693159, t print 21.244s, t batch 1.062s
train Ep 20, Sp 3360, loss 0.655138, t print 11.162s, t batch 0.558s
train Ep 20, Sp 3520, loss 0.665607, t print 11.265s, t batch 0.563s
train Ep 20, Sp 3680, loss 0.70367, t print 21.137s, t batch 1.057s
train Ep 20, Sp 3840, loss 0.685591, t print 11.378s, t batch 0.569s
train Ep 20, Sp 4000, loss 0.705462, t print 11.235s, t batch 0.562s
train Ep 20, Sp 4160, loss 0.684292, t print 21.069s, t batch 1.053s
train Ep 20, Sp 4320, loss 0.712211, t print 10.912s, t batch 0.546s
train Ep 20, Sp 4480, loss 0.697595, t print 11.357s, t batch 0.568s
train Ep 20, Sp 4640, loss 0.665274, t print 21.104s, t batch 1.055s
train Ep 20, Sp 4800, loss 0.669525, t print 11.375s, t batch 0.569s
train Ep 20, Sp 4960, loss 0.663394, t print 11.316s, t batch 0.566s
train Ep 20, Sp 5120, loss 0.711214, t print 20.207s, t batch 1.01s
train Ep 20, Sp 5280, loss 0.707713, t print 11.105s, t batch 0.555s
train Ep 20, Sp 5440, loss 0.691477, t print 11.443s, t batch 0.572s
train Ep 20, Sp 5600, loss 0.682395, t print 20.286s, t batch 1.014s
train Ep 20, Sp 5760, loss 0.687554, t print 12.111s, t batch 0.606s
train Ep 20, Sp 5920, loss 0.688527, t print 11.414s, t batch 0.571s
train Ep 20, Sp 6080, loss 0.697074, t print 18.017s, t batch 0.901s
train Ep 20, Sp 6240, loss 0.68409, t print 13.45s, t batch 0.672s
train Ep 20, Sp 6400, loss 0.688068, t print 11.265s, t batch 0.563s
train Ep 20, Sp 6560, loss 0.699114, t print 16.771s, t batch 0.839s
train Ep 20, Sp 6720, loss 0.670278, t print 14.883s, t batch 0.744s
train Ep 20, Sp 6880, loss 0.654678, t print 11.554s, t batch 0.578s
train Ep 20, Sp 7040, loss 0.671269, t print 15.373s, t batch 0.769s
train Ep 20, Sp 7200, loss 0.698535, t print 16.925s, t batch 0.846s
train Ep 20, Sp 7360, loss 0.690145, t print 11.213s, t batch 0.561s
train Ep 20, Sp 7520, loss 0.674812, t print 14.194s, t batch 0.71s
train Ep 20, Sp 7680, loss 0.669683, t print 17.92s, t batch 0.896s
train Ep 20, Sp 7840, loss 0.706419, t print 11.114s, t batch 0.556s
train Ep 20, Sp 8000, loss 0.664782, t print 12.244s, t batch 0.612s
train Ep 20, Sp 8160, loss 0.636845, t print 20.268s, t batch 1.013s
train Ep 20, Sp 8320, loss 0.691061, t print 11.255s, t batch 0.563s
train Ep 20, Sp 8480, loss 0.695704, t print 11.7s, t batch 0.585s
train Ep 20, Sp 8640, loss 0.687667, t print 21.457s, t batch 1.073s
train Ep 20, Sp 8800, loss 0.647068, t print 11.124s, t batch 0.556s
train Ep 20, Sp 8960, loss 0.693896, t print 11.64s, t batch 0.582s
train Ep 20, Sp 9120, loss 0.726023, t print 21.302s, t batch 1.065s
train Ep 20, Sp 9280, loss 0.696353, t print 11.731s, t batch 0.587s
train Ep 20, Sp 9440, loss 0.693831, t print 11.681s, t batch 0.584s
train Ep 20, Sp 9600, loss 0.659146, t print 21.684s, t batch 1.084s
train Ep 20, Sp 9760, loss 0.700759, t print 11.288s, t batch 0.564s
train Ep 20, Sp 9920, loss 0.713077, t print 11.078s, t batch 0.554s
train Ep 20, Sp 10080, loss 0.705059, t print 20.778s, t batch 1.039s
train Ep 20, Sp 10240, loss 0.695757, t print 11.277s, t batch 0.564s
Start looping batches...
validate Ep 20, Sp 160, loss 0.685003, t print 1.101s, t batch 0.055s
validate Ep 20, Sp 320, loss 0.706917, t print 1232.717s, t batch 61.636s
validate Ep 20, Sp 480, loss 0.685146, t print 11.101s, t batch 0.555s
validate Ep 20, Sp 640, loss 0.673286, t print 11.082s, t batch 0.554s
validate Ep 20, Sp 800, loss 0.698687, t print 19.636s, t batch 0.982s
validate Ep 20, Sp 960, loss 0.689817, t print 11.1s, t batch 0.555s
validate Ep 20, Sp 1120, loss 0.693919, t print 10.992s, t batch 0.55s
validate Ep 20, Sp 1280, loss 0.703721, t print 18.804s, t batch 0.94s
validate Ep 20, Sp 1440, loss 0.65526, t print 12.714s, t batch 0.636s
validate Ep 20, Sp 1600, loss 0.687491, t print 11.295s, t batch 0.565s
validate Ep 20, Sp 1760, loss 0.676103, t print 17.045s, t batch 0.852s
validate Ep 20, Sp 1920, loss 0.690963, t print 13.786s, t batch 0.689s
validate Ep 20, Sp 2080, loss 0.668001, t print 11.607s, t batch 0.58s
validate Ep 20, Sp 2240, loss 0.697094, t print 15.239s, t batch 0.762s
validate Ep 20, Sp 2400, loss 0.707173, t print 15.211s, t batch 0.761s
  Epoch 20, Average Epoch loss = 0.682205643504858
  Epoch 20, nr_of_updates 27216
current learning rate: 0.001
  Epoch 20, time total 2523.2040565013885s
  Epoch 20, time UNet: 123.55382442474365s
  Epoch 20, time metrics: 0.1291520595550537s
  Epoch 20, time saving files: 0.0002532005310058594s
2023-11-30 19:14:29.481003
Start looping batches...
train Ep 21, Sp 160, loss 0.691728, t print 2.415s, t batch 0.121s
train Ep 21, Sp 320, loss 0.660613, t print 12.472s, t batch 0.624s
train Ep 21, Sp 480, loss 0.719873, t print 13.1s, t batch 0.655s
train Ep 21, Sp 640, loss 0.680334, t print 10.996s, t batch 0.55s
train Ep 21, Sp 800, loss 0.669595, t print 22.095s, t batch 1.105s
train Ep 21, Sp 960, loss 0.698337, t print 10.9s, t batch 0.545s
train Ep 21, Sp 1120, loss 0.677865, t print 10.662s, t batch 0.533s
train Ep 21, Sp 1280, loss 0.690725, t print 20.001s, t batch 1.0s
train Ep 21, Sp 1440, loss 0.707423, t print 11.154s, t batch 0.558s
train Ep 21, Sp 1600, loss 0.657719, t print 11.159s, t batch 0.558s
train Ep 21, Sp 1760, loss 0.70289, t print 20.237s, t batch 1.012s
train Ep 21, Sp 1920, loss 0.646962, t print 11.27s, t batch 0.563s
train Ep 21, Sp 2080, loss 0.668168, t print 11.335s, t batch 0.567s
train Ep 21, Sp 2240, loss 0.700231, t print 20.591s, t batch 1.03s
train Ep 21, Sp 2400, loss 0.687561, t print 11.443s, t batch 0.572s
train Ep 21, Sp 2560, loss 0.695028, t print 11.367s, t batch 0.568s
train Ep 21, Sp 2720, loss 0.652657, t print 20.299s, t batch 1.015s
train Ep 21, Sp 2880, loss 0.704438, t print 11.247s, t batch 0.562s
train Ep 21, Sp 3040, loss 0.671978, t print 11.178s, t batch 0.559s
train Ep 21, Sp 3200, loss 0.675822, t print 20.7s, t batch 1.035s
train Ep 21, Sp 3360, loss 0.692122, t print 11.196s, t batch 0.56s
train Ep 21, Sp 3520, loss 0.697294, t print 11.546s, t batch 0.577s
train Ep 21, Sp 3680, loss 0.666473, t print 20.073s, t batch 1.004s
train Ep 21, Sp 3840, loss 0.698251, t print 10.788s, t batch 0.539s
train Ep 21, Sp 4000, loss 0.662276, t print 12.725s, t batch 0.636s
train Ep 21, Sp 4160, loss 0.67178, t print 17.909s, t batch 0.895s
train Ep 21, Sp 4320, loss 0.714481, t print 10.752s, t batch 0.538s
train Ep 21, Sp 4480, loss 0.663296, t print 15.041s, t batch 0.752s
train Ep 21, Sp 4640, loss 0.680096, t print 15.764s, t batch 0.788s
train Ep 21, Sp 4800, loss 0.681804, t print 10.819s, t batch 0.541s
train Ep 21, Sp 4960, loss 0.718289, t print 17.257s, t batch 0.863s
train Ep 21, Sp 5120, loss 0.671628, t print 13.495s, t batch 0.675s
train Ep 21, Sp 5280, loss 0.675927, t print 10.676s, t batch 0.534s
train Ep 21, Sp 5440, loss 0.710668, t print 19.729s, t batch 0.986s
train Ep 21, Sp 5600, loss 0.68773, t print 11.499s, t batch 0.575s
train Ep 21, Sp 5760, loss 0.684503, t print 11.256s, t batch 0.563s
train Ep 21, Sp 5920, loss 0.694608, t print 21.009s, t batch 1.05s
train Ep 21, Sp 6080, loss 0.691107, t print 11.341s, t batch 0.567s
train Ep 21, Sp 6240, loss 0.698853, t print 11.3s, t batch 0.565s
train Ep 21, Sp 6400, loss 0.689339, t print 21.054s, t batch 1.053s
train Ep 21, Sp 6560, loss 0.682595, t print 11.253s, t batch 0.563s
train Ep 21, Sp 6720, loss 0.698925, t print 11.334s, t batch 0.567s
train Ep 21, Sp 6880, loss 0.697738, t print 21.028s, t batch 1.051s
train Ep 21, Sp 7040, loss 0.705063, t print 11.313s, t batch 0.566s
train Ep 21, Sp 7200, loss 0.70518, t print 11.299s, t batch 0.565s
train Ep 21, Sp 7360, loss 0.701053, t print 20.901s, t batch 1.045s
train Ep 21, Sp 7520, loss 0.700834, t print 11.228s, t batch 0.561s
train Ep 21, Sp 7680, loss 0.716202, t print 11.121s, t batch 0.556s
train Ep 21, Sp 7840, loss 0.681901, t print 20.649s, t batch 1.032s
train Ep 21, Sp 8000, loss 0.688511, t print 11.081s, t batch 0.554s
train Ep 21, Sp 8160, loss 0.69779, t print 11.059s, t batch 0.553s
train Ep 21, Sp 8320, loss 0.699679, t print 20.805s, t batch 1.04s
train Ep 21, Sp 8480, loss 0.686251, t print 11.101s, t batch 0.555s
train Ep 21, Sp 8640, loss 0.670286, t print 11.191s, t batch 0.56s
train Ep 21, Sp 8800, loss 0.680889, t print 20.563s, t batch 1.028s
train Ep 21, Sp 8960, loss 0.688322, t print 10.842s, t batch 0.542s
train Ep 21, Sp 9120, loss 0.694557, t print 10.98s, t batch 0.549s
train Ep 21, Sp 9280, loss 0.702466, t print 20.341s, t batch 1.017s
train Ep 21, Sp 9440, loss 0.688882, t print 10.954s, t batch 0.548s
train Ep 21, Sp 9600, loss 0.647949, t print 11.593s, t batch 0.58s
train Ep 21, Sp 9760, loss 0.692437, t print 19.636s, t batch 0.982s
train Ep 21, Sp 9920, loss 0.67649, t print 10.895s, t batch 0.545s
train Ep 21, Sp 10080, loss 0.678603, t print 12.119s, t batch 0.606s
train Ep 21, Sp 10240, loss 0.706182, t print 18.661s, t batch 0.933s
Start looping batches...
validate Ep 21, Sp 160, loss 0.719675, t print 1.054s, t batch 0.053s
validate Ep 21, Sp 320, loss 0.661787, t print 11.817s, t batch 0.591s
validate Ep 21, Sp 480, loss 0.709666, t print 11.603s, t batch 0.58s
validate Ep 21, Sp 640, loss 0.680857, t print 11.183s, t batch 0.559s
validate Ep 21, Sp 800, loss 0.698288, t print 20.228s, t batch 1.011s
validate Ep 21, Sp 960, loss 0.655488, t print 11.174s, t batch 0.559s
validate Ep 21, Sp 1120, loss 0.693043, t print 10.59s, t batch 0.529s
validate Ep 21, Sp 1280, loss 0.677773, t print 19.632s, t batch 0.982s
validate Ep 21, Sp 1440, loss 0.719927, t print 11.287s, t batch 0.564s
validate Ep 21, Sp 1600, loss 0.7099, t print 10.61s, t batch 0.53s
validate Ep 21, Sp 1760, loss 0.675891, t print 20.516s, t batch 1.026s
validate Ep 21, Sp 1920, loss 0.658459, t print 10.712s, t batch 0.536s
validate Ep 21, Sp 2080, loss 0.676879, t print 10.873s, t batch 0.544s
validate Ep 21, Sp 2240, loss 0.708899, t print 20.302s, t batch 1.015s
validate Ep 21, Sp 2400, loss 0.673857, t print 10.799s, t batch 0.54s
  Epoch 21, Average Epoch loss = 0.6878770581090156
  Epoch 21, nr_of_updates 28512
current learning rate: 0.001
  Epoch 21, time total 1105.8260378837585s
  Epoch 21, time UNet: 123.89682173728943s
  Epoch 21, time metrics: 0.11876583099365234s
  Epoch 21, time saving files: 0.00029349327087402344s
2023-11-30 19:32:55.315207
Start looping batches...
train Ep 22, Sp 160, loss 0.663417, t print 1.586s, t batch 0.079s
train Ep 22, Sp 320, loss 0.670514, t print 11.32s, t batch 0.566s
train Ep 22, Sp 480, loss 0.65835, t print 12.692s, t batch 0.635s
train Ep 22, Sp 640, loss 0.637465, t print 12.015s, t batch 0.601s
train Ep 22, Sp 800, loss 0.63399, t print 20.463s, t batch 1.023s
train Ep 22, Sp 960, loss 0.701538, t print 12.274s, t batch 0.614s
train Ep 22, Sp 1120, loss 0.693427, t print 11.268s, t batch 0.563s
train Ep 22, Sp 1280, loss 0.708044, t print 19.458s, t batch 0.973s
train Ep 22, Sp 1440, loss 0.689632, t print 13.027s, t batch 0.651s
train Ep 22, Sp 1600, loss 0.716738, t print 11.352s, t batch 0.568s
train Ep 22, Sp 1760, loss 0.679962, t print 17.468s, t batch 0.873s
train Ep 22, Sp 1920, loss 0.666097, t print 14.61s, t batch 0.731s
train Ep 22, Sp 2080, loss 0.68305, t print 11.267s, t batch 0.563s
train Ep 22, Sp 2240, loss 0.649519, t print 14.83s, t batch 0.741s
train Ep 22, Sp 2400, loss 0.668791, t print 17.132s, t batch 0.857s
train Ep 22, Sp 2560, loss 0.677128, t print 11.281s, t batch 0.564s
train Ep 22, Sp 2720, loss 0.698518, t print 11.983s, t batch 0.599s
train Ep 22, Sp 2880, loss 0.690944, t print 19.796s, t batch 0.99s
train Ep 22, Sp 3040, loss 0.677629, t print 11.158s, t batch 0.558s
train Ep 22, Sp 3200, loss 0.671947, t print 11.309s, t batch 0.565s
train Ep 22, Sp 3360, loss 0.696183, t print 20.928s, t batch 1.046s
train Ep 22, Sp 3520, loss 0.684408, t print 11.251s, t batch 0.563s
train Ep 22, Sp 3680, loss 0.713303, t print 11.151s, t batch 0.558s
train Ep 22, Sp 3840, loss 0.692294, t print 20.925s, t batch 1.046s
train Ep 22, Sp 4000, loss 0.668761, t print 11.363s, t batch 0.568s
train Ep 22, Sp 4160, loss 0.651092, t print 11.258s, t batch 0.563s
train Ep 22, Sp 4320, loss 0.690738, t print 20.482s, t batch 1.024s
train Ep 22, Sp 4480, loss 0.658839, t print 11.156s, t batch 0.558s
train Ep 22, Sp 4640, loss 0.693757, t print 11.138s, t batch 0.557s
train Ep 22, Sp 4800, loss 0.687998, t print 21.134s, t batch 1.057s
train Ep 22, Sp 4960, loss 0.652958, t print 11.475s, t batch 0.574s
train Ep 22, Sp 5120, loss 0.672623, t print 11.621s, t batch 0.581s
train Ep 22, Sp 5280, loss 0.686249, t print 20.389s, t batch 1.019s
train Ep 22, Sp 5440, loss 0.680698, t print 11.753s, t batch 0.588s
train Ep 22, Sp 5600, loss 0.703765, t print 11.065s, t batch 0.553s
train Ep 22, Sp 5760, loss 0.702891, t print 20.162s, t batch 1.008s
train Ep 22, Sp 5920, loss 0.699264, t print 12.714s, t batch 0.636s
train Ep 22, Sp 6080, loss 0.661832, t print 11.54s, t batch 0.577s
train Ep 22, Sp 6240, loss 0.66868, t print 18.26s, t batch 0.913s
train Ep 22, Sp 6400, loss 0.677406, t print 13.612s, t batch 0.681s
train Ep 22, Sp 6560, loss 0.664924, t print 11.266s, t batch 0.563s
train Ep 22, Sp 6720, loss 0.683743, t print 16.307s, t batch 0.815s
train Ep 22, Sp 6880, loss 0.720337, t print 15.757s, t batch 0.788s
train Ep 22, Sp 7040, loss 0.692936, t print 11.065s, t batch 0.553s
train Ep 22, Sp 7200, loss 0.705966, t print 14.475s, t batch 0.724s
train Ep 22, Sp 7360, loss 0.696773, t print 17.596s, t batch 0.88s
train Ep 22, Sp 7520, loss 0.669606, t print 11.253s, t batch 0.563s
train Ep 22, Sp 7680, loss 0.723659, t print 12.398s, t batch 0.62s
train Ep 22, Sp 7840, loss 0.683021, t print 19.844s, t batch 0.992s
train Ep 22, Sp 8000, loss 0.682, t print 11.324s, t batch 0.566s
train Ep 22, Sp 8160, loss 0.694527, t print 11.381s, t batch 0.569s
train Ep 22, Sp 8320, loss 0.681515, t print 21.223s, t batch 1.061s
train Ep 22, Sp 8480, loss 0.676631, t print 11.311s, t batch 0.566s
train Ep 22, Sp 8640, loss 0.688479, t print 11.316s, t batch 0.566s
train Ep 22, Sp 8800, loss 0.677567, t print 21.155s, t batch 1.058s
train Ep 22, Sp 8960, loss 0.652736, t print 11.438s, t batch 0.572s
train Ep 22, Sp 9120, loss 0.699326, t print 11.304s, t batch 0.565s
train Ep 22, Sp 9280, loss 0.681643, t print 20.855s, t batch 1.043s
train Ep 22, Sp 9440, loss 0.702839, t print 11.193s, t batch 0.56s
train Ep 22, Sp 9600, loss 0.689124, t print 11.244s, t batch 0.562s
train Ep 22, Sp 9760, loss 0.687348, t print 20.752s, t batch 1.038s
train Ep 22, Sp 9920, loss 0.686635, t print 10.987s, t batch 0.549s
train Ep 22, Sp 10080, loss 0.685744, t print 11.209s, t batch 0.56s
train Ep 22, Sp 10240, loss 0.683982, t print 20.649s, t batch 1.032s
Start looping batches...
validate Ep 22, Sp 160, loss 0.715597, t print 1.127s, t batch 0.056s
validate Ep 22, Sp 320, loss 0.691353, t print 11.504s, t batch 0.575s
validate Ep 22, Sp 480, loss 0.650926, t print 11.942s, t batch 0.597s
validate Ep 22, Sp 640, loss 0.69069, t print 11.222s, t batch 0.561s
validate Ep 22, Sp 800, loss 0.676062, t print 19.752s, t batch 0.988s
validate Ep 22, Sp 960, loss 0.672296, t print 11.068s, t batch 0.553s
validate Ep 22, Sp 1120, loss 0.702141, t print 11.198s, t batch 0.56s
validate Ep 22, Sp 1280, loss 0.732365, t print 20.487s, t batch 1.024s
validate Ep 22, Sp 1440, loss 0.723496, t print 11.124s, t batch 0.556s
validate Ep 22, Sp 1600, loss 0.677633, t print 10.72s, t batch 0.536s
validate Ep 22, Sp 1760, loss 0.733511, t print 20.52s, t batch 1.026s
validate Ep 22, Sp 1920, loss 0.676936, t print 10.907s, t batch 0.545s
validate Ep 22, Sp 2080, loss 0.727441, t print 10.998s, t batch 0.55s
validate Ep 22, Sp 2240, loss 0.719283, t print 20.619s, t batch 1.031s
validate Ep 22, Sp 2400, loss 0.745984, t print 10.803s, t batch 0.54s
  Epoch 22, Average Epoch loss = 0.6825204069415728
  Epoch 22, nr_of_updates 29808
current learning rate: 0.001
  Epoch 22, time total 1112.579062461853s
  Epoch 22, time UNet: 123.87260699272156s
  Epoch 22, time metrics: 0.11989951133728027s
  Epoch 22, time saving files: 0.0001220703125s
2023-11-30 19:51:27.902220
Start looping batches...
train Ep 23, Sp 160, loss 0.674437, t print 1.674s, t batch 0.084s
train Ep 23, Sp 320, loss 0.704204, t print 11.522s, t batch 0.576s
train Ep 23, Sp 480, loss 0.677965, t print 13.36s, t batch 0.668s
train Ep 23, Sp 640, loss 0.695193, t print 11.39s, t batch 0.57s
train Ep 23, Sp 800, loss 0.686319, t print 20.826s, t batch 1.041s
train Ep 23, Sp 960, loss 0.710495, t print 11.676s, t batch 0.584s
train Ep 23, Sp 1120, loss 0.689669, t print 11.559s, t batch 0.578s
train Ep 23, Sp 1280, loss 0.67818, t print 20.248s, t batch 1.012s
train Ep 23, Sp 1440, loss 0.676845, t print 12.897s, t batch 0.645s
train Ep 23, Sp 1600, loss 0.685887, t print 11.398s, t batch 0.57s
train Ep 23, Sp 1760, loss 0.681133, t print 18.716s, t batch 0.936s
train Ep 23, Sp 1920, loss 0.687104, t print 13.71s, t batch 0.686s
train Ep 23, Sp 2080, loss 0.669519, t print 11.646s, t batch 0.582s
train Ep 23, Sp 2240, loss 0.662444, t print 17.588s, t batch 0.879s
train Ep 23, Sp 2400, loss 0.717867, t print 14.886s, t batch 0.744s
train Ep 23, Sp 2560, loss 0.66868, t print 11.476s, t batch 0.574s
train Ep 23, Sp 2720, loss 0.665212, t print 15.898s, t batch 0.795s
train Ep 23, Sp 2880, loss 0.661307, t print 17.252s, t batch 0.863s
train Ep 23, Sp 3040, loss 0.686572, t print 11.646s, t batch 0.582s
train Ep 23, Sp 3200, loss 0.661352, t print 13.146s, t batch 0.657s
train Ep 23, Sp 3360, loss 0.713222, t print 19.629s, t batch 0.981s
train Ep 23, Sp 3520, loss 0.652746, t print 12.079s, t batch 0.604s
train Ep 23, Sp 3680, loss 0.674595, t print 11.488s, t batch 0.574s
train Ep 23, Sp 3840, loss 0.691792, t print 20.65s, t batch 1.033s
train Ep 23, Sp 4000, loss 0.671593, t print 11.271s, t batch 0.564s
train Ep 23, Sp 4160, loss 0.691916, t print 11.839s, t batch 0.592s
train Ep 23, Sp 4320, loss 0.657696, t print 20.588s, t batch 1.029s
train Ep 23, Sp 4480, loss 0.696977, t print 11.127s, t batch 0.556s
train Ep 23, Sp 4640, loss 0.662899, t print 11.414s, t batch 0.571s
train Ep 23, Sp 4800, loss 0.701854, t print 20.566s, t batch 1.028s
train Ep 23, Sp 4960, loss 0.700458, t print 11.116s, t batch 0.556s
train Ep 23, Sp 5120, loss 0.700517, t print 11.504s, t batch 0.575s
train Ep 23, Sp 5280, loss 0.694125, t print 20.325s, t batch 1.016s
train Ep 23, Sp 5440, loss 0.657238, t print 11.334s, t batch 0.567s
train Ep 23, Sp 5600, loss 0.68326, t print 11.557s, t batch 0.578s
train Ep 23, Sp 5760, loss 0.670816, t print 20.336s, t batch 1.017s
train Ep 23, Sp 5920, loss 0.689922, t print 11.396s, t batch 0.57s
train Ep 23, Sp 6080, loss 0.693997, t print 11.449s, t batch 0.572s
train Ep 23, Sp 6240, loss 0.709346, t print 20.148s, t batch 1.007s
train Ep 23, Sp 6400, loss 0.655363, t print 11.461s, t batch 0.573s
train Ep 23, Sp 6560, loss 0.677309, t print 11.109s, t batch 0.555s
train Ep 23, Sp 6720, loss 0.671318, t print 20.287s, t batch 1.014s
train Ep 23, Sp 6880, loss 0.664032, t print 11.218s, t batch 0.561s
train Ep 23, Sp 7040, loss 0.69133, t print 11.274s, t batch 0.564s
train Ep 23, Sp 7200, loss 0.671683, t print 20.774s, t batch 1.039s
train Ep 23, Sp 7360, loss 0.706877, t print 11.425s, t batch 0.571s
train Ep 23, Sp 7520, loss 0.676069, t print 11.328s, t batch 0.566s
train Ep 23, Sp 7680, loss 0.681893, t print 20.63s, t batch 1.032s
train Ep 23, Sp 7840, loss 0.73271, t print 11.443s, t batch 0.572s
train Ep 23, Sp 8000, loss 0.665329, t print 11.246s, t batch 0.562s
train Ep 23, Sp 8160, loss 0.687494, t print 19.98s, t batch 0.999s
train Ep 23, Sp 8320, loss 0.686335, t print 12.144s, t batch 0.607s
train Ep 23, Sp 8480, loss 0.679123, t print 11.375s, t batch 0.569s
train Ep 23, Sp 8640, loss 0.707835, t print 19.135s, t batch 0.957s
train Ep 23, Sp 8800, loss 0.707191, t print 12.576s, t batch 0.629s
train Ep 23, Sp 8960, loss 0.665036, t print 11.757s, t batch 0.588s
train Ep 23, Sp 9120, loss 0.671023, t print 18.275s, t batch 0.914s
train Ep 23, Sp 9280, loss 0.672971, t print 13.126s, t batch 0.656s
train Ep 23, Sp 9440, loss 0.663433, t print 11.585s, t batch 0.579s
train Ep 23, Sp 9600, loss 0.722037, t print 17.524s, t batch 0.876s
train Ep 23, Sp 9760, loss 0.666374, t print 13.464s, t batch 0.673s
train Ep 23, Sp 9920, loss 0.700479, t print 12.335s, t batch 0.617s
train Ep 23, Sp 10080, loss 0.672448, t print 16.409s, t batch 0.82s
train Ep 23, Sp 10240, loss 0.688221, t print 12.601s, t batch 0.63s
Start looping batches...
validate Ep 23, Sp 160, loss 0.673727, t print 1.021s, t batch 0.051s
validate Ep 23, Sp 320, loss 0.68213, t print 11.952s, t batch 0.598s
validate Ep 23, Sp 480, loss 0.64083, t print 11.618s, t batch 0.581s
validate Ep 23, Sp 640, loss 0.743853, t print 10.974s, t batch 0.549s
validate Ep 23, Sp 800, loss 0.711337, t print 19.832s, t batch 0.992s
validate Ep 23, Sp 960, loss 0.633968, t print 10.974s, t batch 0.549s
validate Ep 23, Sp 1120, loss 0.700447, t print 11.159s, t batch 0.558s
validate Ep 23, Sp 1280, loss 0.68687, t print 20.087s, t batch 1.004s
validate Ep 23, Sp 1440, loss 0.670515, t print 11.071s, t batch 0.554s
validate Ep 23, Sp 1600, loss 0.697204, t print 11.123s, t batch 0.556s
validate Ep 23, Sp 1760, loss 0.666025, t print 20.805s, t batch 1.04s
validate Ep 23, Sp 1920, loss 0.694536, t print 11.08s, t batch 0.554s
validate Ep 23, Sp 2080, loss 0.675917, t print 11.1s, t batch 0.555s
validate Ep 23, Sp 2240, loss 0.692681, t print 20.731s, t batch 1.037s
validate Ep 23, Sp 2400, loss 0.674097, t print 10.954s, t batch 0.548s
  Epoch 23, Average Epoch loss = 0.6835877362316773
  Epoch 23, nr_of_updates 31104
current learning rate: 0.001
  Epoch 23, time total 1115.3301005363464s
  Epoch 23, time UNet: 124.10721707344055s
  Epoch 23, time metrics: 0.12461590766906738s
  Epoch 23, time saving files: 0.00010132789611816406s
2023-11-30 20:10:03.239431
Start looping batches...
train Ep 24, Sp 160, loss 0.715297, t print 1.717s, t batch 0.086s
train Ep 24, Sp 320, loss 0.670599, t print 11.323s, t batch 0.566s
train Ep 24, Sp 480, loss 0.706602, t print 12.913s, t batch 0.646s
train Ep 24, Sp 640, loss 0.665091, t print 11.831s, t batch 0.592s
train Ep 24, Sp 800, loss 0.697752, t print 20.305s, t batch 1.015s
train Ep 24, Sp 960, loss 0.680271, t print 12.643s, t batch 0.632s
train Ep 24, Sp 1120, loss 0.671402, t print 11.343s, t batch 0.567s
train Ep 24, Sp 1280, loss 0.669728, t print 19.322s, t batch 0.966s
train Ep 24, Sp 1440, loss 0.683826, t print 13.923s, t batch 0.696s
train Ep 24, Sp 1600, loss 0.681044, t print 10.94s, t batch 0.547s
train Ep 24, Sp 1760, loss 0.698032, t print 16.916s, t batch 0.846s
train Ep 24, Sp 1920, loss 0.646508, t print 15.218s, t batch 0.761s
train Ep 24, Sp 2080, loss 0.642849, t print 11.156s, t batch 0.558s
train Ep 24, Sp 2240, loss 0.709245, t print 15.37s, t batch 0.769s
train Ep 24, Sp 2400, loss 0.689391, t print 17.231s, t batch 0.862s
train Ep 24, Sp 2560, loss 0.701094, t print 11.113s, t batch 0.556s
train Ep 24, Sp 2720, loss 0.68036, t print 13.366s, t batch 0.668s
train Ep 24, Sp 2880, loss 0.658183, t print 18.788s, t batch 0.939s
train Ep 24, Sp 3040, loss 0.671191, t print 11.087s, t batch 0.554s
train Ep 24, Sp 3200, loss 0.683581, t print 11.715s, t batch 0.586s
train Ep 24, Sp 3360, loss 0.715759, t print 20.328s, t batch 1.016s
train Ep 24, Sp 3520, loss 0.702499, t print 11.17s, t batch 0.559s
train Ep 24, Sp 3680, loss 0.704291, t print 11.38s, t batch 0.569s
train Ep 24, Sp 3840, loss 0.701691, t print 20.853s, t batch 1.043s
train Ep 24, Sp 4000, loss 0.674056, t print 11.31s, t batch 0.566s
train Ep 24, Sp 4160, loss 0.683545, t print 11.321s, t batch 0.566s
train Ep 24, Sp 4320, loss 0.661162, t print 20.781s, t batch 1.039s
train Ep 24, Sp 4480, loss 0.673862, t print 11.169s, t batch 0.558s
train Ep 24, Sp 4640, loss 0.701157, t print 11.252s, t batch 0.563s
train Ep 24, Sp 4800, loss 0.661787, t print 20.856s, t batch 1.043s
train Ep 24, Sp 4960, loss 0.663447, t print 11.111s, t batch 0.556s
train Ep 24, Sp 5120, loss 0.671797, t print 11.228s, t batch 0.561s
train Ep 24, Sp 5280, loss 0.710767, t print 20.924s, t batch 1.046s
train Ep 24, Sp 5440, loss 0.669365, t print 11.117s, t batch 0.556s
train Ep 24, Sp 5600, loss 0.687108, t print 11.346s, t batch 0.567s
train Ep 24, Sp 5760, loss 0.682748, t print 21.15s, t batch 1.057s
train Ep 24, Sp 5920, loss 0.667508, t print 11.101s, t batch 0.555s
train Ep 24, Sp 6080, loss 0.718895, t print 11.087s, t batch 0.554s
train Ep 24, Sp 6240, loss 0.671506, t print 20.435s, t batch 1.022s
train Ep 24, Sp 6400, loss 0.713044, t print 11.632s, t batch 0.582s
train Ep 24, Sp 6560, loss 0.630569, t print 11.494s, t batch 0.575s
train Ep 24, Sp 6720, loss 0.658519, t print 19.047s, t batch 0.952s
train Ep 24, Sp 6880, loss 0.681985, t print 12.469s, t batch 0.623s
train Ep 24, Sp 7040, loss 0.650761, t print 11.256s, t batch 0.563s
train Ep 24, Sp 7200, loss 0.671812, t print 17.438s, t batch 0.872s
train Ep 24, Sp 7360, loss 0.732634, t print 14.333s, t batch 0.717s
train Ep 24, Sp 7520, loss 0.706052, t print 11.003s, t batch 0.55s
train Ep 24, Sp 7680, loss 0.715711, t print 15.958s, t batch 0.798s
train Ep 24, Sp 7840, loss 0.653172, t print 15.111s, t batch 0.756s
train Ep 24, Sp 8000, loss 0.716127, t print 10.932s, t batch 0.547s
train Ep 24, Sp 8160, loss 0.650209, t print 15.259s, t batch 0.763s
train Ep 24, Sp 8320, loss 0.68342, t print 16.026s, t batch 0.801s
train Ep 24, Sp 8480, loss 0.6785, t print 10.977s, t batch 0.549s
train Ep 24, Sp 8640, loss 0.658921, t print 14.294s, t batch 0.715s
train Ep 24, Sp 8800, loss 0.685694, t print 17.302s, t batch 0.865s
train Ep 24, Sp 8960, loss 0.67874, t print 11.027s, t batch 0.551s
train Ep 24, Sp 9120, loss 0.681578, t print 14.127s, t batch 0.706s
train Ep 24, Sp 9280, loss 0.666044, t print 17.507s, t batch 0.875s
train Ep 24, Sp 9440, loss 0.675056, t print 11.159s, t batch 0.558s
train Ep 24, Sp 9600, loss 0.701191, t print 13.965s, t batch 0.698s
train Ep 24, Sp 9760, loss 0.666346, t print 17.555s, t batch 0.878s
train Ep 24, Sp 9920, loss 0.693101, t print 11.59s, t batch 0.58s
train Ep 24, Sp 10080, loss 0.670469, t print 13.274s, t batch 0.664s
train Ep 24, Sp 10240, loss 0.631515, t print 17.128s, t batch 0.856s
Start looping batches...
validate Ep 24, Sp 160, loss 0.662276, t print 1.105s, t batch 0.055s
validate Ep 24, Sp 320, loss 0.693745, t print 11.406s, t batch 0.57s
validate Ep 24, Sp 480, loss 0.680914, t print 12.178s, t batch 0.609s
validate Ep 24, Sp 640, loss 0.691279, t print 10.988s, t batch 0.549s
validate Ep 24, Sp 800, loss 0.699642, t print 19.8s, t batch 0.99s
validate Ep 24, Sp 960, loss 0.716264, t print 11.774s, t batch 0.589s
validate Ep 24, Sp 1120, loss 0.698605, t print 10.823s, t batch 0.541s
validate Ep 24, Sp 1280, loss 0.670384, t print 19.938s, t batch 0.997s
validate Ep 24, Sp 1440, loss 0.692756, t print 12.005s, t batch 0.6s
validate Ep 24, Sp 1600, loss 0.678605, t print 10.887s, t batch 0.544s
validate Ep 24, Sp 1760, loss 0.701643, t print 19.566s, t batch 0.978s
validate Ep 24, Sp 1920, loss 0.660318, t print 12.087s, t batch 0.604s
validate Ep 24, Sp 2080, loss 0.699293, t print 10.753s, t batch 0.538s
validate Ep 24, Sp 2240, loss 0.667345, t print 18.3s, t batch 0.915s
validate Ep 24, Sp 2400, loss 0.709751, t print 12.94s, t batch 0.647s
  Epoch 24, Average Epoch loss = 0.6810594937407676
  Epoch 24, nr_of_updates 32400
current learning rate: 0.001
  Epoch 24, time total 1106.4696526527405s
  Epoch 24, time UNet: 126.05754256248474s
  Epoch 24, time metrics: 0.12819337844848633s
  Epoch 24, time saving files: 0.0012640953063964844s
2023-11-30 20:28:29.717121
Start looping batches...
train Ep 25, Sp 160, loss 0.706099, t print 1.742s, t batch 0.087s
train Ep 25, Sp 320, loss 0.676577, t print 11.244s, t batch 0.562s
train Ep 25, Sp 480, loss 0.624632, t print 12.524s, t batch 0.626s
train Ep 25, Sp 640, loss 0.664582, t print 11.668s, t batch 0.583s
train Ep 25, Sp 800, loss 0.686904, t print 21.659s, t batch 1.083s
train Ep 25, Sp 960, loss 0.675226, t print 11.679s, t batch 0.584s
train Ep 25, Sp 1120, loss 0.702064, t print 11.493s, t batch 0.575s
train Ep 25, Sp 1280, loss 0.698854, t print 21.193s, t batch 1.06s
train Ep 25, Sp 1440, loss 0.702921, t print 11.534s, t batch 0.577s
train Ep 25, Sp 1600, loss 0.684417, t print 11.414s, t batch 0.571s
train Ep 25, Sp 1760, loss 0.684074, t print 20.986s, t batch 1.049s
train Ep 25, Sp 1920, loss 0.629128, t print 11.364s, t batch 0.568s
train Ep 25, Sp 2080, loss 0.668947, t print 11.304s, t batch 0.565s
train Ep 25, Sp 2240, loss 0.670733, t print 21.17s, t batch 1.059s
train Ep 25, Sp 2400, loss 0.697044, t print 11.327s, t batch 0.566s
train Ep 25, Sp 2560, loss 0.677655, t print 11.116s, t batch 0.556s
train Ep 25, Sp 2720, loss 0.652416, t print 20.904s, t batch 1.045s
train Ep 25, Sp 2880, loss 0.721633, t print 11.42s, t batch 0.571s
train Ep 25, Sp 3040, loss 0.709214, t print 11.303s, t batch 0.565s
train Ep 25, Sp 3200, loss 0.662334, t print 21.018s, t batch 1.051s
train Ep 25, Sp 3360, loss 0.670277, t print 11.259s, t batch 0.563s
train Ep 25, Sp 3520, loss 0.676763, t print 10.93s, t batch 0.546s
train Ep 25, Sp 3680, loss 0.64634, t print 20.774s, t batch 1.039s
train Ep 25, Sp 3840, loss 0.657349, t print 11.413s, t batch 0.571s
train Ep 25, Sp 4000, loss 0.704415, t print 11.316s, t batch 0.566s
train Ep 25, Sp 4160, loss 0.697085, t print 20.911s, t batch 1.046s
train Ep 25, Sp 4320, loss 0.690796, t print 11.141s, t batch 0.557s
train Ep 25, Sp 4480, loss 0.653442, t print 11.355s, t batch 0.568s
train Ep 25, Sp 4640, loss 0.667181, t print 21.008s, t batch 1.05s
train Ep 25, Sp 4800, loss 0.642022, t print 11.229s, t batch 0.561s
train Ep 25, Sp 4960, loss 0.686495, t print 11.136s, t batch 0.557s
train Ep 25, Sp 5120, loss 0.680232, t print 20.91s, t batch 1.046s
train Ep 25, Sp 5280, loss 0.658867, t print 11.186s, t batch 0.559s
train Ep 25, Sp 5440, loss 0.710031, t print 11.235s, t batch 0.562s
train Ep 25, Sp 5600, loss 0.677005, t print 20.761s, t batch 1.038s
train Ep 25, Sp 5760, loss 0.70066, t print 11.244s, t batch 0.562s
train Ep 25, Sp 5920, loss 0.688147, t print 11.157s, t batch 0.558s
train Ep 25, Sp 6080, loss 0.666372, t print 20.936s, t batch 1.047s
train Ep 25, Sp 6240, loss 0.65957, t print 11.357s, t batch 0.568s
train Ep 25, Sp 6400, loss 0.655948, t print 11.237s, t batch 0.562s
train Ep 25, Sp 6560, loss 0.721068, t print 20.766s, t batch 1.038s
train Ep 25, Sp 6720, loss 0.677769, t print 11.28s, t batch 0.564s
train Ep 25, Sp 6880, loss 0.645248, t print 11.271s, t batch 0.564s
train Ep 25, Sp 7040, loss 0.720063, t print 20.858s, t batch 1.043s
train Ep 25, Sp 7200, loss 0.684905, t print 11.328s, t batch 0.566s
train Ep 25, Sp 7360, loss 0.671645, t print 11.346s, t batch 0.567s
train Ep 25, Sp 7520, loss 0.700859, t print 20.994s, t batch 1.05s
train Ep 25, Sp 7680, loss 0.711527, t print 11.348s, t batch 0.567s
train Ep 25, Sp 7840, loss 0.660963, t print 11.255s, t batch 0.563s
train Ep 25, Sp 8000, loss 0.698855, t print 21.066s, t batch 1.053s
train Ep 25, Sp 8160, loss 0.676994, t print 11.279s, t batch 0.564s
train Ep 25, Sp 8320, loss 0.691209, t print 11.249s, t batch 0.562s
train Ep 25, Sp 8480, loss 0.693274, t print 20.715s, t batch 1.036s
train Ep 25, Sp 8640, loss 0.690412, t print 10.973s, t batch 0.549s
train Ep 25, Sp 8800, loss 0.696824, t print 10.715s, t batch 0.536s
train Ep 25, Sp 8960, loss 0.657649, t print 19.901s, t batch 0.995s
train Ep 25, Sp 9120, loss 0.69322, t print 10.791s, t batch 0.54s
train Ep 25, Sp 9280, loss 0.673319, t print 10.789s, t batch 0.539s
train Ep 25, Sp 9440, loss 0.661796, t print 20.054s, t batch 1.003s
train Ep 25, Sp 9600, loss 0.670091, t print 10.864s, t batch 0.543s
train Ep 25, Sp 9760, loss 0.700709, t print 10.723s, t batch 0.536s
train Ep 25, Sp 9920, loss 0.669575, t print 20.045s, t batch 1.002s
train Ep 25, Sp 10080, loss 0.669131, t print 10.881s, t batch 0.544s
train Ep 25, Sp 10240, loss 0.696612, t print 10.901s, t batch 0.545s
Start looping batches...
validate Ep 25, Sp 160, loss 0.696412, t print 0.991s, t batch 0.05s
validate Ep 25, Sp 320, loss 0.664457, t print 11.27s, t batch 0.564s
validate Ep 25, Sp 480, loss 0.701977, t print 12.013s, t batch 0.601s
validate Ep 25, Sp 640, loss 0.704388, t print 11.266s, t batch 0.563s
validate Ep 25, Sp 800, loss 0.707388, t print 19.951s, t batch 0.998s
validate Ep 25, Sp 960, loss 0.658411, t print 11.351s, t batch 0.568s
validate Ep 25, Sp 1120, loss 0.704827, t print 10.861s, t batch 0.543s
validate Ep 25, Sp 1280, loss 0.713412, t print 19.253s, t batch 0.963s
validate Ep 25, Sp 1440, loss 0.69817, t print 11.988s, t batch 0.599s
validate Ep 25, Sp 1600, loss 0.707044, t print 10.792s, t batch 0.54s
validate Ep 25, Sp 1760, loss 0.740228, t print 18.11s, t batch 0.905s
validate Ep 25, Sp 1920, loss 0.703228, t print 13.148s, t batch 0.657s
validate Ep 25, Sp 2080, loss 0.706053, t print 10.848s, t batch 0.542s
validate Ep 25, Sp 2240, loss 0.689431, t print 16.492s, t batch 0.825s
validate Ep 25, Sp 2400, loss 0.657764, t print 14.373s, t batch 0.719s
  Epoch 25, Average Epoch loss = 0.679592825104425
  Epoch 25, nr_of_updates 33696
current learning rate: 0.001
  Epoch 25, time total 1105.936565876007s
  Epoch 25, time UNet: 122.88366651535034s
  Epoch 25, time metrics: 0.12619590759277344s
  Epoch 25, time saving files: 0.000118255615234375s
2023-11-30 20:46:55.661315
Start looping batches...
train Ep 26, Sp 160, loss 0.681529, t print 1.646s, t batch 0.082s
train Ep 26, Sp 320, loss 0.684913, t print 11.258s, t batch 0.563s
train Ep 26, Sp 480, loss 0.695399, t print 12.657s, t batch 0.633s
train Ep 26, Sp 640, loss 0.715636, t print 11.854s, t batch 0.593s
train Ep 26, Sp 800, loss 0.701675, t print 20.973s, t batch 1.049s
train Ep 26, Sp 960, loss 0.694922, t print 11.629s, t batch 0.581s
train Ep 26, Sp 1120, loss 0.669662, t print 11.485s, t batch 0.574s
train Ep 26, Sp 1280, loss 0.676682, t print 20.595s, t batch 1.03s
train Ep 26, Sp 1440, loss 0.654814, t print 12.119s, t batch 0.606s
train Ep 26, Sp 1600, loss 0.683759, t print 11.319s, t batch 0.566s
train Ep 26, Sp 1760, loss 0.674264, t print 19.834s, t batch 0.992s
train Ep 26, Sp 1920, loss 0.69546, t print 12.577s, t batch 0.629s
train Ep 26, Sp 2080, loss 0.709405, t print 11.305s, t batch 0.565s
train Ep 26, Sp 2240, loss 0.661019, t print 18.475s, t batch 0.924s
train Ep 26, Sp 2400, loss 0.683645, t print 13.619s, t batch 0.681s
train Ep 26, Sp 2560, loss 0.65264, t print 11.25s, t batch 0.562s
train Ep 26, Sp 2720, loss 0.684017, t print 17.364s, t batch 0.868s
train Ep 26, Sp 2880, loss 0.699427, t print 14.861s, t batch 0.743s
train Ep 26, Sp 3040, loss 0.668558, t print 11.325s, t batch 0.566s
train Ep 26, Sp 3200, loss 0.701258, t print 15.941s, t batch 0.797s
train Ep 26, Sp 3360, loss 0.675021, t print 16.418s, t batch 0.821s
train Ep 26, Sp 3520, loss 0.659286, t print 11.36s, t batch 0.568s
train Ep 26, Sp 3680, loss 0.651391, t print 14.203s, t batch 0.71s
train Ep 26, Sp 3840, loss 0.678934, t print 18.01s, t batch 0.9s
train Ep 26, Sp 4000, loss 0.682583, t print 11.258s, t batch 0.563s
train Ep 26, Sp 4160, loss 0.725248, t print 12.062s, t batch 0.603s
train Ep 26, Sp 4320, loss 0.665499, t print 19.97s, t batch 0.999s
train Ep 26, Sp 4480, loss 0.652754, t print 11.308s, t batch 0.565s
train Ep 26, Sp 4640, loss 0.687187, t print 11.134s, t batch 0.557s
train Ep 26, Sp 4800, loss 0.717173, t print 20.643s, t batch 1.032s
train Ep 26, Sp 4960, loss 0.715797, t print 11.459s, t batch 0.573s
train Ep 26, Sp 5120, loss 0.696355, t print 11.196s, t batch 0.56s
train Ep 26, Sp 5280, loss 0.707599, t print 20.092s, t batch 1.005s
train Ep 26, Sp 5440, loss 0.677024, t print 12.017s, t batch 0.601s
train Ep 26, Sp 5600, loss 0.692438, t print 10.975s, t batch 0.549s
train Ep 26, Sp 5760, loss 0.675957, t print 19.086s, t batch 0.954s
train Ep 26, Sp 5920, loss 0.677823, t print 12.794s, t batch 0.64s
train Ep 26, Sp 6080, loss 0.678739, t print 11.086s, t batch 0.554s
train Ep 26, Sp 6240, loss 0.65743, t print 17.303s, t batch 0.865s
train Ep 26, Sp 6400, loss 0.727741, t print 14.288s, t batch 0.714s
train Ep 26, Sp 6560, loss 0.673788, t print 11.13s, t batch 0.557s
train Ep 26, Sp 6720, loss 0.69017, t print 15.833s, t batch 0.792s
train Ep 26, Sp 6880, loss 0.693422, t print 15.935s, t batch 0.797s
train Ep 26, Sp 7040, loss 0.668713, t print 11.126s, t batch 0.556s
train Ep 26, Sp 7200, loss 0.670109, t print 14.065s, t batch 0.703s
train Ep 26, Sp 7360, loss 0.676336, t print 17.957s, t batch 0.898s
train Ep 26, Sp 7520, loss 0.682762, t print 11.039s, t batch 0.552s
train Ep 26, Sp 7680, loss 0.664868, t print 11.991s, t batch 0.6s
train Ep 26, Sp 7840, loss 0.634875, t print 19.985s, t batch 0.999s
train Ep 26, Sp 8000, loss 0.68658, t print 11.254s, t batch 0.563s
train Ep 26, Sp 8160, loss 0.664045, t print 11.33s, t batch 0.567s
train Ep 26, Sp 8320, loss 0.719508, t print 20.72s, t batch 1.036s
train Ep 26, Sp 8480, loss 0.676599, t print 11.296s, t batch 0.565s
train Ep 26, Sp 8640, loss 0.683205, t print 11.315s, t batch 0.566s
train Ep 26, Sp 8800, loss 0.709436, t print 21.098s, t batch 1.055s
train Ep 26, Sp 8960, loss 0.732845, t print 11.2s, t batch 0.56s
train Ep 26, Sp 9120, loss 0.65144, t print 11.337s, t batch 0.567s
train Ep 26, Sp 9280, loss 0.730591, t print 21.127s, t batch 1.056s
train Ep 26, Sp 9440, loss 0.715964, t print 11.405s, t batch 0.57s
train Ep 26, Sp 9600, loss 0.666961, t print 11.316s, t batch 0.566s
train Ep 26, Sp 9760, loss 0.662677, t print 20.857s, t batch 1.043s
train Ep 26, Sp 9920, loss 0.699879, t print 11.17s, t batch 0.559s
train Ep 26, Sp 10080, loss 0.675015, t print 11.27s, t batch 0.564s
train Ep 26, Sp 10240, loss 0.695088, t print 20.948s, t batch 1.047s
Start looping batches...
validate Ep 26, Sp 160, loss 0.689684, t print 0.99s, t batch 0.049s
validate Ep 26, Sp 320, loss 0.732715, t print 12.639s, t batch 0.632s
validate Ep 26, Sp 480, loss 0.690596, t print 11.454s, t batch 0.573s
validate Ep 26, Sp 640, loss 0.680688, t print 11.006s, t batch 0.55s
validate Ep 26, Sp 800, loss 0.691061, t print 20.154s, t batch 1.008s
validate Ep 26, Sp 960, loss 0.681372, t print 11.471s, t batch 0.574s
validate Ep 26, Sp 1120, loss 0.657161, t print 10.901s, t batch 0.545s
validate Ep 26, Sp 1280, loss 0.680201, t print 19.44s, t batch 0.972s
validate Ep 26, Sp 1440, loss 0.670132, t print 11.432s, t batch 0.572s
validate Ep 26, Sp 1600, loss 0.717895, t print 10.555s, t batch 0.528s
validate Ep 26, Sp 1760, loss 0.693533, t print 19.428s, t batch 0.971s
validate Ep 26, Sp 1920, loss 0.700029, t print 10.982s, t batch 0.549s
validate Ep 26, Sp 2080, loss 0.68567, t print 10.62s, t batch 0.531s
validate Ep 26, Sp 2240, loss 0.691465, t print 20.199s, t batch 1.01s
validate Ep 26, Sp 2400, loss 0.747199, t print 10.85s, t batch 0.543s
  Epoch 26, Average Epoch loss = 0.6847176705889496
  Epoch 26, nr_of_updates 34992
current learning rate: 0.001
  Epoch 26, time total 1109.3245587348938s
  Epoch 26, time UNet: 123.6175549030304s
  Epoch 26, time metrics: 0.12506532669067383s
  Epoch 26, time saving files: 0.00010418891906738281s
2023-11-30 21:05:24.993832
Start looping batches...
train Ep 27, Sp 160, loss 0.68361, t print 1.578s, t batch 0.079s
train Ep 27, Sp 320, loss 0.665357, t print 10.997s, t batch 0.55s
train Ep 27, Sp 480, loss 0.721444, t print 12.886s, t batch 0.644s
train Ep 27, Sp 640, loss 0.686208, t print 12.165s, t batch 0.608s
train Ep 27, Sp 800, loss 0.664173, t print 19.707s, t batch 0.985s
train Ep 27, Sp 960, loss 0.69047, t print 12.787s, t batch 0.639s
train Ep 27, Sp 1120, loss 0.658231, t print 11.658s, t batch 0.583s
train Ep 27, Sp 1280, loss 0.70398, t print 17.052s, t batch 0.853s
train Ep 27, Sp 1440, loss 0.689365, t print 15.515s, t batch 0.776s
train Ep 27, Sp 1600, loss 0.690452, t print 11.703s, t batch 0.585s
train Ep 27, Sp 1760, loss 0.622255, t print 13.655s, t batch 0.683s
train Ep 27, Sp 1920, loss 0.648519, t print 18.753s, t batch 0.938s
train Ep 27, Sp 2080, loss 0.684899, t print 11.122s, t batch 0.556s
train Ep 27, Sp 2240, loss 0.693572, t print 11.461s, t batch 0.573s
train Ep 27, Sp 2400, loss 0.662943, t print 21.191s, t batch 1.06s
train Ep 27, Sp 2560, loss 0.682439, t print 11.032s, t batch 0.552s
train Ep 27, Sp 2720, loss 0.672075, t print 10.5s, t batch 0.525s
train Ep 27, Sp 2880, loss 0.67465, t print 21.468s, t batch 1.073s
train Ep 27, Sp 3040, loss 0.678223, t print 11.528s, t batch 0.576s
train Ep 27, Sp 3200, loss 0.684932, t print 11.521s, t batch 0.576s
train Ep 27, Sp 3360, loss 0.712692, t print 21.287s, t batch 1.064s
train Ep 27, Sp 3520, loss 0.680852, t print 11.436s, t batch 0.572s
train Ep 27, Sp 3680, loss 0.674189, t print 11.21s, t batch 0.561s
train Ep 27, Sp 3840, loss 0.659156, t print 21.169s, t batch 1.058s
train Ep 27, Sp 4000, loss 0.677537, t print 11.985s, t batch 0.599s
train Ep 27, Sp 4160, loss 0.670041, t print 11.571s, t batch 0.579s
train Ep 27, Sp 4320, loss 0.702986, t print 20.994s, t batch 1.05s
train Ep 27, Sp 4480, loss 0.691853, t print 11.391s, t batch 0.57s
train Ep 27, Sp 4640, loss 0.679524, t print 11.053s, t batch 0.553s
train Ep 27, Sp 4800, loss 0.637132, t print 21.065s, t batch 1.053s
train Ep 27, Sp 4960, loss 0.727835, t print 11.291s, t batch 0.565s
train Ep 27, Sp 5120, loss 0.674571, t print 11.171s, t batch 0.559s
train Ep 27, Sp 5280, loss 0.682282, t print 21.369s, t batch 1.068s
train Ep 27, Sp 5440, loss 0.663304, t print 11.299s, t batch 0.565s
train Ep 27, Sp 5600, loss 0.653572, t print 11.428s, t batch 0.571s
train Ep 27, Sp 5760, loss 0.678482, t print 21.343s, t batch 1.067s
train Ep 27, Sp 5920, loss 0.714909, t print 11.17s, t batch 0.558s
train Ep 27, Sp 6080, loss 0.668412, t print 11.32s, t batch 0.566s
train Ep 27, Sp 6240, loss 0.663786, t print 20.884s, t batch 1.044s
train Ep 27, Sp 6400, loss 0.700153, t print 11.329s, t batch 0.566s
train Ep 27, Sp 6560, loss 0.692911, t print 11.37s, t batch 0.568s
train Ep 27, Sp 6720, loss 0.683338, t print 20.702s, t batch 1.035s
train Ep 27, Sp 6880, loss 0.665606, t print 11.088s, t batch 0.554s
train Ep 27, Sp 7040, loss 0.674139, t print 11.335s, t batch 0.567s
train Ep 27, Sp 7200, loss 0.675694, t print 20.664s, t batch 1.033s
train Ep 27, Sp 7360, loss 0.721249, t print 10.968s, t batch 0.548s
train Ep 27, Sp 7520, loss 0.667537, t print 11.004s, t batch 0.55s
train Ep 27, Sp 7680, loss 0.68225, t print 20.508s, t batch 1.025s
train Ep 27, Sp 7840, loss 0.678244, t print 11.239s, t batch 0.562s
train Ep 27, Sp 8000, loss 0.658476, t print 11.002s, t batch 0.55s
train Ep 27, Sp 8160, loss 0.679558, t print 20.577s, t batch 1.029s
train Ep 27, Sp 8320, loss 0.651698, t print 11.089s, t batch 0.554s
train Ep 27, Sp 8480, loss 0.726204, t print 11.087s, t batch 0.554s
train Ep 27, Sp 8640, loss 0.686911, t print 20.238s, t batch 1.012s
train Ep 27, Sp 8800, loss 0.698838, t print 11.281s, t batch 0.564s
train Ep 27, Sp 8960, loss 0.674448, t print 11.148s, t batch 0.557s
train Ep 27, Sp 9120, loss 0.713413, t print 20.286s, t batch 1.014s
train Ep 27, Sp 9280, loss 0.700807, t print 11.825s, t batch 0.591s
train Ep 27, Sp 9440, loss 0.703179, t print 11.458s, t batch 0.573s
train Ep 27, Sp 9600, loss 0.681259, t print 20.448s, t batch 1.022s
train Ep 27, Sp 9760, loss 0.69284, t print 11.844s, t batch 0.592s
train Ep 27, Sp 9920, loss 0.693441, t print 11.347s, t batch 0.567s
train Ep 27, Sp 10080, loss 0.681371, t print 19.916s, t batch 0.996s
train Ep 27, Sp 10240, loss 0.701384, t print 12.085s, t batch 0.604s
Start looping batches...
validate Ep 27, Sp 160, loss 0.667532, t print 0.977s, t batch 0.049s
validate Ep 27, Sp 320, loss 0.711303, t print 1801.667s, t batch 90.083s
validate Ep 27, Sp 480, loss 0.665961, t print 7.464s, t batch 0.373s
validate Ep 27, Sp 640, loss 0.699805, t print 11.119s, t batch 0.556s
validate Ep 27, Sp 800, loss 0.694107, t print 20.792s, t batch 1.04s
validate Ep 27, Sp 960, loss 0.681556, t print 10.826s, t batch 0.541s
validate Ep 27, Sp 1120, loss 0.689206, t print 11.105s, t batch 0.555s
validate Ep 27, Sp 1280, loss 0.664182, t print 20.939s, t batch 1.047s
validate Ep 27, Sp 1440, loss 0.674797, t print 11.059s, t batch 0.553s
validate Ep 27, Sp 1600, loss 0.691364, t print 10.988s, t batch 0.549s
validate Ep 27, Sp 1760, loss 0.685705, t print 20.988s, t batch 1.049s
validate Ep 27, Sp 1920, loss 0.713591, t print 11.017s, t batch 0.551s
validate Ep 27, Sp 2080, loss 0.693787, t print 10.939s, t batch 0.547s
validate Ep 27, Sp 2240, loss 0.669561, t print 20.791s, t batch 1.04s
validate Ep 27, Sp 2400, loss 0.672754, t print 10.808s, t batch 0.54s
  Epoch 27, Average Epoch loss = 0.6826854444764279
  Epoch 27, nr_of_updates 36288
current learning rate: 0.001
  Saving weights...
  Epoch 27, time total 2904.708518266678s
  Epoch 27, time UNet: 127.36670351028442s
  Epoch 27, time metrics: 0.1269378662109375s
  Epoch 27, time saving files: 0.4861111640930176s
2023-11-30 21:53:49.709951
Start looping batches...
train Ep 28, Sp 160, loss 0.727869, t print 4.051s, t batch 0.203s
train Ep 28, Sp 320, loss 0.659341, t print 10.34s, t batch 0.517s
train Ep 28, Sp 480, loss 0.706215, t print 13.562s, t batch 0.678s
train Ep 28, Sp 640, loss 0.705623, t print 11.73s, t batch 0.586s
train Ep 28, Sp 800, loss 0.674055, t print 18.251s, t batch 0.913s
train Ep 28, Sp 960, loss 0.686817, t print 14.273s, t batch 0.714s
train Ep 28, Sp 1120, loss 0.699845, t print 11.466s, t batch 0.573s
train Ep 28, Sp 1280, loss 0.669128, t print 15.455s, t batch 0.773s
train Ep 28, Sp 1440, loss 0.670584, t print 16.751s, t batch 0.838s
train Ep 28, Sp 1600, loss 0.690392, t print 11.398s, t batch 0.57s
train Ep 28, Sp 1760, loss 0.687086, t print 12.805s, t batch 0.64s
train Ep 28, Sp 1920, loss 0.694045, t print 19.683s, t batch 0.984s
train Ep 28, Sp 2080, loss 0.681804, t print 11.49s, t batch 0.575s
train Ep 28, Sp 2240, loss 0.725129, t print 11.338s, t batch 0.567s
train Ep 28, Sp 2400, loss 0.648429, t print 21.266s, t batch 1.063s
train Ep 28, Sp 2560, loss 0.701406, t print 11.354s, t batch 0.568s
train Ep 28, Sp 2720, loss 0.696759, t print 11.32s, t batch 0.566s
train Ep 28, Sp 2880, loss 0.634367, t print 21.08s, t batch 1.054s
train Ep 28, Sp 3040, loss 0.683305, t print 11.433s, t batch 0.572s
train Ep 28, Sp 3200, loss 0.66481, t print 11.198s, t batch 0.56s
train Ep 28, Sp 3360, loss 0.680826, t print 20.93s, t batch 1.047s
train Ep 28, Sp 3520, loss 0.657962, t print 11.373s, t batch 0.569s
train Ep 28, Sp 3680, loss 0.659132, t print 11.355s, t batch 0.568s
train Ep 28, Sp 3840, loss 0.684849, t print 20.825s, t batch 1.041s
train Ep 28, Sp 4000, loss 0.683275, t print 11.279s, t batch 0.564s
train Ep 28, Sp 4160, loss 0.664353, t print 11.179s, t batch 0.559s
train Ep 28, Sp 4320, loss 0.689485, t print 20.72s, t batch 1.036s
train Ep 28, Sp 4480, loss 0.638362, t print 11.306s, t batch 0.565s
train Ep 28, Sp 4640, loss 0.687989, t print 11.178s, t batch 0.559s
train Ep 28, Sp 4800, loss 0.681433, t print 20.792s, t batch 1.04s
train Ep 28, Sp 4960, loss 0.70397, t print 11.254s, t batch 0.563s
train Ep 28, Sp 5120, loss 0.65282, t print 11.399s, t batch 0.57s
train Ep 28, Sp 5280, loss 0.667713, t print 20.686s, t batch 1.034s
train Ep 28, Sp 5440, loss 0.705666, t print 11.306s, t batch 0.565s
train Ep 28, Sp 5600, loss 0.686014, t print 11.289s, t batch 0.564s
train Ep 28, Sp 5760, loss 0.682096, t print 20.974s, t batch 1.049s
train Ep 28, Sp 5920, loss 0.701325, t print 11.179s, t batch 0.559s
train Ep 28, Sp 6080, loss 0.726005, t print 11.27s, t batch 0.563s
train Ep 28, Sp 6240, loss 0.663669, t print 20.943s, t batch 1.047s
train Ep 28, Sp 6400, loss 0.681574, t print 11.21s, t batch 0.561s
train Ep 28, Sp 6560, loss 0.654795, t print 11.229s, t batch 0.561s
train Ep 28, Sp 6720, loss 0.710271, t print 20.846s, t batch 1.042s
train Ep 28, Sp 6880, loss 0.690953, t print 11.104s, t batch 0.555s
train Ep 28, Sp 7040, loss 0.725713, t print 11.24s, t batch 0.562s
train Ep 28, Sp 7200, loss 0.665217, t print 20.942s, t batch 1.047s
train Ep 28, Sp 7360, loss 0.67919, t print 11.183s, t batch 0.559s
train Ep 28, Sp 7520, loss 0.679234, t print 11.185s, t batch 0.559s
train Ep 28, Sp 7680, loss 0.671645, t print 20.869s, t batch 1.043s
train Ep 28, Sp 7840, loss 0.689392, t print 11.329s, t batch 0.566s
train Ep 28, Sp 8000, loss 0.652609, t print 11.352s, t batch 0.568s
train Ep 28, Sp 8160, loss 0.625222, t print 20.929s, t batch 1.046s
train Ep 28, Sp 8320, loss 0.7151, t print 11.182s, t batch 0.559s
train Ep 28, Sp 8480, loss 0.652102, t print 11.156s, t batch 0.558s
train Ep 28, Sp 8640, loss 0.714104, t print 20.662s, t batch 1.033s
train Ep 28, Sp 8800, loss 0.736147, t print 11.23s, t batch 0.562s
train Ep 28, Sp 8960, loss 0.692587, t print 11.081s, t batch 0.554s
train Ep 28, Sp 9120, loss 0.668134, t print 20.694s, t batch 1.035s
train Ep 28, Sp 9280, loss 0.684589, t print 11.166s, t batch 0.558s
train Ep 28, Sp 9440, loss 0.639921, t print 11.252s, t batch 0.563s
train Ep 28, Sp 9600, loss 0.706968, t print 21.132s, t batch 1.057s
train Ep 28, Sp 9760, loss 0.659702, t print 11.211s, t batch 0.561s
train Ep 28, Sp 9920, loss 0.643895, t print 11.123s, t batch 0.556s
train Ep 28, Sp 10080, loss 0.712893, t print 20.808s, t batch 1.04s
train Ep 28, Sp 10240, loss 0.678494, t print 11.053s, t batch 0.553s
Start looping batches...
validate Ep 28, Sp 160, loss 0.683203, t print 0.988s, t batch 0.049s
validate Ep 28, Sp 320, loss 0.698824, t print 1373.583s, t batch 68.679s
validate Ep 28, Sp 480, loss 0.680647, t print 11.235s, t batch 0.562s
validate Ep 28, Sp 640, loss 0.712373, t print 11.16s, t batch 0.558s
validate Ep 28, Sp 800, loss 0.704372, t print 20.04s, t batch 1.002s
validate Ep 28, Sp 960, loss 0.677143, t print 10.845s, t batch 0.542s
validate Ep 28, Sp 1120, loss 0.678745, t print 10.848s, t batch 0.542s
validate Ep 28, Sp 1280, loss 0.675545, t print 20.195s, t batch 1.01s
validate Ep 28, Sp 1440, loss 0.653678, t print 10.813s, t batch 0.541s
validate Ep 28, Sp 1600, loss 0.665403, t print 10.561s, t batch 0.528s
validate Ep 28, Sp 1760, loss 0.674889, t print 20.137s, t batch 1.007s
validate Ep 28, Sp 1920, loss 0.672907, t print 10.591s, t batch 0.53s
validate Ep 28, Sp 2080, loss 0.686433, t print 10.603s, t batch 0.53s
validate Ep 28, Sp 2240, loss 0.683799, t print 20.102s, t batch 1.005s
validate Ep 28, Sp 2400, loss 0.705369, t print 10.449s, t batch 0.522s
  Epoch 28, Average Epoch loss = 0.6819699008339717
  Epoch 28, nr_of_updates 37584
current learning rate: 0.001
  Epoch 28, time total 2472.414202451706s
  Epoch 28, time UNet: 210.70686769485474s
  Epoch 28, time metrics: 0.1260662078857422s
  Epoch 28, time saving files: 0.006046295166015625s
2023-11-30 22:35:02.132132
Start looping batches...
train Ep 29, Sp 160, loss 0.690583, t print 1.798s, t batch 0.09s
train Ep 29, Sp 320, loss 0.707068, t print 11.413s, t batch 0.571s
train Ep 29, Sp 480, loss 0.707198, t print 12.73s, t batch 0.637s
train Ep 29, Sp 640, loss 0.63875, t print 12.005s, t batch 0.6s
train Ep 29, Sp 800, loss 0.688804, t print 20.231s, t batch 1.012s
train Ep 29, Sp 960, loss 0.70819, t print 13.193s, t batch 0.66s
train Ep 29, Sp 1120, loss 0.656859, t print 11.408s, t batch 0.57s
train Ep 29, Sp 1280, loss 0.677619, t print 17.798s, t batch 0.89s
train Ep 29, Sp 1440, loss 0.653732, t print 15.27s, t batch 0.764s
train Ep 29, Sp 1600, loss 0.651139, t print 11.52s, t batch 0.576s
train Ep 29, Sp 1760, loss 0.672406, t print 15.682s, t batch 0.784s
train Ep 29, Sp 1920, loss 0.667659, t print 17.203s, t batch 0.86s
train Ep 29, Sp 2080, loss 0.680995, t print 11.524s, t batch 0.576s
train Ep 29, Sp 2240, loss 0.666084, t print 13.624s, t batch 0.681s
train Ep 29, Sp 2400, loss 0.68415, t print 18.809s, t batch 0.94s
train Ep 29, Sp 2560, loss 0.668502, t print 11.384s, t batch 0.569s
train Ep 29, Sp 2720, loss 0.675452, t print 11.862s, t batch 0.593s
train Ep 29, Sp 2880, loss 0.694357, t print 20.446s, t batch 1.022s
train Ep 29, Sp 3040, loss 0.719118, t print 11.17s, t batch 0.559s
train Ep 29, Sp 3200, loss 0.649464, t print 11.512s, t batch 0.576s
train Ep 29, Sp 3360, loss 0.672751, t print 20.482s, t batch 1.024s
train Ep 29, Sp 3520, loss 0.714737, t print 11.148s, t batch 0.557s
train Ep 29, Sp 3680, loss 0.680656, t print 11.468s, t batch 0.573s
train Ep 29, Sp 3840, loss 0.687221, t print 20.86s, t batch 1.043s
train Ep 29, Sp 4000, loss 0.69073, t print 11.373s, t batch 0.569s
train Ep 29, Sp 4160, loss 0.638492, t print 11.175s, t batch 0.559s
train Ep 29, Sp 4320, loss 0.685011, t print 21.022s, t batch 1.051s
train Ep 29, Sp 4480, loss 0.665311, t print 11.228s, t batch 0.561s
train Ep 29, Sp 4640, loss 0.681497, t print 11.222s, t batch 0.561s
train Ep 29, Sp 4800, loss 0.654665, t print 20.65s, t batch 1.033s
train Ep 29, Sp 4960, loss 0.67371, t print 11.086s, t batch 0.554s
train Ep 29, Sp 5120, loss 0.662217, t print 11.239s, t batch 0.562s
train Ep 29, Sp 5280, loss 0.65865, t print 20.731s, t batch 1.037s
train Ep 29, Sp 5440, loss 0.685175, t print 11.007s, t batch 0.55s
train Ep 29, Sp 5600, loss 0.665588, t print 11.012s, t batch 0.551s
train Ep 29, Sp 5760, loss 0.69583, t print 20.362s, t batch 1.018s
train Ep 29, Sp 5920, loss 0.709833, t print 10.915s, t batch 0.546s
train Ep 29, Sp 6080, loss 0.645229, t print 11.209s, t batch 0.56s
train Ep 29, Sp 6240, loss 0.684681, t print 20.053s, t batch 1.003s
train Ep 29, Sp 6400, loss 0.685667, t print 10.893s, t batch 0.545s
train Ep 29, Sp 6560, loss 0.684965, t print 11.763s, t batch 0.588s
train Ep 29, Sp 6720, loss 0.632714, t print 19.548s, t batch 0.977s
train Ep 29, Sp 6880, loss 0.669463, t print 11.033s, t batch 0.552s
train Ep 29, Sp 7040, loss 0.649081, t print 12.124s, t batch 0.606s
train Ep 29, Sp 7200, loss 0.64135, t print 18.951s, t batch 0.948s
train Ep 29, Sp 7360, loss 0.663342, t print 11.042s, t batch 0.552s
train Ep 29, Sp 7520, loss 0.677238, t print 12.564s, t batch 0.628s
train Ep 29, Sp 7680, loss 0.666032, t print 18.437s, t batch 0.922s
train Ep 29, Sp 7840, loss 0.708881, t print 10.909s, t batch 0.545s
train Ep 29, Sp 8000, loss 0.681188, t print 12.366s, t batch 0.618s
train Ep 29, Sp 8160, loss 0.673016, t print 18.592s, t batch 0.93s
train Ep 29, Sp 8320, loss 0.659782, t print 10.89s, t batch 0.544s
train Ep 29, Sp 8480, loss 0.671702, t print 11.273s, t batch 0.564s
train Ep 29, Sp 8640, loss 0.650691, t print 19.561s, t batch 0.978s
train Ep 29, Sp 8800, loss 0.677618, t print 10.851s, t batch 0.543s
train Ep 29, Sp 8960, loss 0.67293, t print 10.764s, t batch 0.538s
train Ep 29, Sp 9120, loss 0.696192, t print 20.096s, t batch 1.005s
train Ep 29, Sp 9280, loss 0.703059, t print 10.926s, t batch 0.546s
train Ep 29, Sp 9440, loss 0.710648, t print 10.99s, t batch 0.55s
train Ep 29, Sp 9600, loss 0.687616, t print 20.195s, t batch 1.01s
train Ep 29, Sp 9760, loss 0.672744, t print 10.971s, t batch 0.549s
train Ep 29, Sp 9920, loss 0.675311, t print 10.885s, t batch 0.544s
train Ep 29, Sp 10080, loss 0.64453, t print 19.969s, t batch 0.998s
train Ep 29, Sp 10240, loss 0.682735, t print 10.666s, t batch 0.533s
Start looping batches...
validate Ep 29, Sp 160, loss 0.671634, t print 1.005s, t batch 0.05s
validate Ep 29, Sp 320, loss 0.704132, t print 11.728s, t batch 0.586s
validate Ep 29, Sp 480, loss 0.66225, t print 12.183s, t batch 0.609s
validate Ep 29, Sp 640, loss 0.69155, t print 11.431s, t batch 0.572s
validate Ep 29, Sp 800, loss 0.696713, t print 20.286s, t batch 1.014s
validate Ep 29, Sp 960, loss 0.651041, t print 10.792s, t batch 0.54s
validate Ep 29, Sp 1120, loss 0.694768, t print 10.649s, t batch 0.532s
validate Ep 29, Sp 1280, loss 0.629588, t print 20.282s, t batch 1.014s
validate Ep 29, Sp 1440, loss 0.698619, t print 10.739s, t batch 0.537s
validate Ep 29, Sp 1600, loss 0.73301, t print 10.669s, t batch 0.533s
validate Ep 29, Sp 1760, loss 0.70461, t print 20.046s, t batch 1.002s
validate Ep 29, Sp 1920, loss 0.736863, t print 10.834s, t batch 0.542s
validate Ep 29, Sp 2080, loss 0.665424, t print 10.525s, t batch 0.526s
validate Ep 29, Sp 2240, loss 0.671903, t print 20.022s, t batch 1.001s
validate Ep 29, Sp 2400, loss 0.692857, t print 10.562s, t batch 0.528s
  Epoch 29, Average Epoch loss = 0.6755707663610394
  Epoch 29, nr_of_updates 38880
current learning rate: 0.001
  Epoch 29, time total 1097.8941729068756s
  Epoch 29, time UNet: 124.26794385910034s
  Epoch 29, time metrics: 0.13241362571716309s
  Epoch 29, time saving files: 0.00023794174194335938s
2023-11-30 22:53:20.033806
Start looping batches...
train Ep 30, Sp 160, loss 0.653571, t print 1.596s, t batch 0.08s
train Ep 30, Sp 320, loss 0.694074, t print 11.503s, t batch 0.575s
train Ep 30, Sp 480, loss 0.683102, t print 12.825s, t batch 0.641s
train Ep 30, Sp 640, loss 0.653374, t print 12.187s, t batch 0.609s
train Ep 30, Sp 800, loss 0.712317, t print 21.307s, t batch 1.065s
train Ep 30, Sp 960, loss 0.687571, t print 11.479s, t batch 0.574s
train Ep 30, Sp 1120, loss 0.689517, t print 11.58s, t batch 0.579s
train Ep 30, Sp 1280, loss 0.647535, t print 21.529s, t batch 1.076s
train Ep 30, Sp 1440, loss 0.698484, t print 11.55s, t batch 0.577s
train Ep 30, Sp 1600, loss 0.654647, t print 11.603s, t batch 0.58s
train Ep 30, Sp 1760, loss 0.692472, t print 21.724s, t batch 1.086s
train Ep 30, Sp 1920, loss 0.657048, t print 11.698s, t batch 0.585s
train Ep 30, Sp 2080, loss 0.68858, t print 11.633s, t batch 0.582s
train Ep 30, Sp 2240, loss 0.727235, t print 21.801s, t batch 1.09s
train Ep 30, Sp 2400, loss 0.657105, t print 11.665s, t batch 0.583s
train Ep 30, Sp 2560, loss 0.651862, t print 11.642s, t batch 0.582s
train Ep 30, Sp 2720, loss 0.656497, t print 21.019s, t batch 1.051s
train Ep 30, Sp 2880, loss 0.667413, t print 11.546s, t batch 0.577s
train Ep 30, Sp 3040, loss 0.74004, t print 11.461s, t batch 0.573s
train Ep 30, Sp 3200, loss 0.683705, t print 21.076s, t batch 1.054s
train Ep 30, Sp 3360, loss 0.676844, t print 11.394s, t batch 0.57s
train Ep 30, Sp 3520, loss 0.678112, t print 11.378s, t batch 0.569s
train Ep 30, Sp 3680, loss 0.722909, t print 20.978s, t batch 1.049s
train Ep 30, Sp 3840, loss 0.715262, t print 11.948s, t batch 0.597s
train Ep 30, Sp 4000, loss 0.667222, t print 10.779s, t batch 0.539s
train Ep 30, Sp 4160, loss 0.702539, t print 21.243s, t batch 1.062s
train Ep 30, Sp 4320, loss 0.70054, t print 11.434s, t batch 0.572s
train Ep 30, Sp 4480, loss 0.654296, t print 11.319s, t batch 0.566s
train Ep 30, Sp 4640, loss 0.680705, t print 20.743s, t batch 1.037s
train Ep 30, Sp 4800, loss 0.699905, t print 11.237s, t batch 0.562s
train Ep 30, Sp 4960, loss 0.650006, t print 11.245s, t batch 0.562s
train Ep 30, Sp 5120, loss 0.673815, t print 20.778s, t batch 1.039s
train Ep 30, Sp 5280, loss 0.697439, t print 11.181s, t batch 0.559s
train Ep 30, Sp 5440, loss 0.718765, t print 11.103s, t batch 0.555s
train Ep 30, Sp 5600, loss 0.662546, t print 20.558s, t batch 1.028s
train Ep 30, Sp 5760, loss 0.681831, t print 11.065s, t batch 0.553s
train Ep 30, Sp 5920, loss 0.651666, t print 11.109s, t batch 0.555s
train Ep 30, Sp 6080, loss 0.698103, t print 20.437s, t batch 1.022s
train Ep 30, Sp 6240, loss 0.669636, t print 11.01s, t batch 0.551s
train Ep 30, Sp 6400, loss 0.703254, t print 10.986s, t batch 0.549s
train Ep 30, Sp 6560, loss 0.693715, t print 20.434s, t batch 1.022s
train Ep 30, Sp 6720, loss 0.698434, t print 10.992s, t batch 0.55s
train Ep 30, Sp 6880, loss 0.683561, t print 10.791s, t batch 0.54s
train Ep 30, Sp 7040, loss 0.668854, t print 20.237s, t batch 1.012s
train Ep 30, Sp 7200, loss 0.633427, t print 10.971s, t batch 0.549s
train Ep 30, Sp 7360, loss 0.686988, t print 11.001s, t batch 0.55s
train Ep 30, Sp 7520, loss 0.663084, t print 20.303s, t batch 1.015s
train Ep 30, Sp 7680, loss 0.690299, t print 10.923s, t batch 0.546s
train Ep 30, Sp 7840, loss 0.684245, t print 11.103s, t batch 0.555s
train Ep 30, Sp 8000, loss 0.709179, t print 20.476s, t batch 1.024s
train Ep 30, Sp 8160, loss 0.705429, t print 10.868s, t batch 0.543s
train Ep 30, Sp 8320, loss 0.701823, t print 10.95s, t batch 0.548s
train Ep 30, Sp 8480, loss 0.668484, t print 20.38s, t batch 1.019s
train Ep 30, Sp 8640, loss 0.711868, t print 11.071s, t batch 0.554s
train Ep 30, Sp 8800, loss 0.662807, t print 10.95s, t batch 0.547s
train Ep 30, Sp 8960, loss 0.690674, t print 20.178s, t batch 1.009s
train Ep 30, Sp 9120, loss 0.670772, t print 10.845s, t batch 0.542s
train Ep 30, Sp 9280, loss 0.694746, t print 10.891s, t batch 0.545s
train Ep 30, Sp 9440, loss 0.65325, t print 20.294s, t batch 1.015s
train Ep 30, Sp 9600, loss 0.696635, t print 11.085s, t batch 0.554s
train Ep 30, Sp 9760, loss 0.720392, t print 10.935s, t batch 0.547s
train Ep 30, Sp 9920, loss 0.683908, t print 20.364s, t batch 1.018s
train Ep 30, Sp 10080, loss 0.660269, t print 11.029s, t batch 0.551s
train Ep 30, Sp 10240, loss 0.692145, t print 10.919s, t batch 0.546s
Start looping batches...
validate Ep 30, Sp 160, loss 0.65236, t print 1.006s, t batch 0.05s
validate Ep 30, Sp 320, loss 0.684904, t print 1102.664s, t batch 55.133s
validate Ep 30, Sp 480, loss 0.681766, t print 12.212s, t batch 0.611s
validate Ep 30, Sp 640, loss 0.708318, t print 10.478s, t batch 0.524s
validate Ep 30, Sp 800, loss 0.656893, t print 20.761s, t batch 1.038s
validate Ep 30, Sp 960, loss 0.69132, t print 10.918s, t batch 0.546s
validate Ep 30, Sp 1120, loss 0.699693, t print 10.739s, t batch 0.537s
validate Ep 30, Sp 1280, loss 0.653115, t print 20.583s, t batch 1.029s
validate Ep 30, Sp 1440, loss 0.689344, t print 10.946s, t batch 0.547s
validate Ep 30, Sp 1600, loss 0.700074, t print 10.411s, t batch 0.521s
validate Ep 30, Sp 1760, loss 0.677917, t print 19.901s, t batch 0.995s
validate Ep 30, Sp 1920, loss 0.695543, t print 10.913s, t batch 0.546s
validate Ep 30, Sp 2080, loss 0.698784, t print 11.023s, t batch 0.551s
validate Ep 30, Sp 2240, loss 0.680945, t print 18.919s, t batch 0.946s
validate Ep 30, Sp 2400, loss 0.659463, t print 11.3s, t batch 0.565s
  Epoch 30, Average Epoch loss = 0.6831534761981464
  Epoch 30, nr_of_updates 40176
current learning rate: 0.001
  Epoch 30, time total 2196.986697912216s
  Epoch 30, time UNet: 123.10844206809998s
  Epoch 30, time metrics: 0.13344407081604004s
  Epoch 30, time saving files: 0.012420177459716797s
2023-11-30 23:29:57.028122
Start looping batches...
train Ep 31, Sp 160, loss 0.718575, t print 1.725s, t batch 0.086s
train Ep 31, Sp 320, loss 0.67946, t print 11.336s, t batch 0.567s
train Ep 31, Sp 480, loss 0.727732, t print 13.24s, t batch 0.662s
train Ep 31, Sp 640, loss 0.655251, t print 11.761s, t batch 0.588s
train Ep 31, Sp 800, loss 0.636946, t print 19.693s, t batch 0.985s
train Ep 31, Sp 960, loss 0.67873, t print 13.997s, t batch 0.7s
train Ep 31, Sp 1120, loss 0.670683, t print 11.25s, t batch 0.562s
train Ep 31, Sp 1280, loss 0.650189, t print 17.271s, t batch 0.864s
train Ep 31, Sp 1440, loss 0.667665, t print 15.833s, t batch 0.792s
train Ep 31, Sp 1600, loss 0.673787, t print 11.329s, t batch 0.566s
train Ep 31, Sp 1760, loss 0.655857, t print 14.699s, t batch 0.735s
train Ep 31, Sp 1920, loss 0.719569, t print 18.64s, t batch 0.932s
train Ep 31, Sp 2080, loss 0.682502, t print 11.62s, t batch 0.581s
train Ep 31, Sp 2240, loss 0.691325, t print 12.215s, t batch 0.611s
train Ep 31, Sp 2400, loss 0.742685, t print 20.705s, t batch 1.035s
train Ep 31, Sp 2560, loss 0.69318, t print 11.77s, t batch 0.589s
train Ep 31, Sp 2720, loss 0.645822, t print 11.555s, t batch 0.578s
train Ep 31, Sp 2880, loss 0.700767, t print 21.652s, t batch 1.083s
train Ep 31, Sp 3040, loss 0.652416, t print 11.511s, t batch 0.576s
train Ep 31, Sp 3200, loss 0.677727, t print 11.578s, t batch 0.579s
train Ep 31, Sp 3360, loss 0.644868, t print 21.862s, t batch 1.093s
train Ep 31, Sp 3520, loss 0.633216, t print 11.856s, t batch 0.593s
train Ep 31, Sp 3680, loss 0.660106, t print 11.599s, t batch 0.58s
train Ep 31, Sp 3840, loss 0.675663, t print 21.862s, t batch 1.093s
train Ep 31, Sp 4000, loss 0.689019, t print 11.582s, t batch 0.579s
train Ep 31, Sp 4160, loss 0.700622, t print 11.54s, t batch 0.577s
train Ep 31, Sp 4320, loss 0.673795, t print 21.225s, t batch 1.061s
train Ep 31, Sp 4480, loss 0.733999, t print 11.633s, t batch 0.582s
train Ep 31, Sp 4640, loss 0.654775, t print 11.369s, t batch 0.568s
train Ep 31, Sp 4800, loss 0.6761, t print 21.404s, t batch 1.07s
train Ep 31, Sp 4960, loss 0.695075, t print 11.456s, t batch 0.573s
train Ep 31, Sp 5120, loss 0.68879, t print 11.396s, t batch 0.57s
train Ep 31, Sp 5280, loss 0.674172, t print 21.114s, t batch 1.056s
train Ep 31, Sp 5440, loss 0.662835, t print 11.328s, t batch 0.566s
train Ep 31, Sp 5600, loss 0.698313, t print 11.383s, t batch 0.569s
train Ep 31, Sp 5760, loss 0.679174, t print 21.152s, t batch 1.058s
train Ep 31, Sp 5920, loss 0.695478, t print 11.322s, t batch 0.566s
train Ep 31, Sp 6080, loss 0.658361, t print 11.354s, t batch 0.568s
train Ep 31, Sp 6240, loss 0.673903, t print 20.769s, t batch 1.038s
train Ep 31, Sp 6400, loss 0.690148, t print 11.156s, t batch 0.558s
train Ep 31, Sp 6560, loss 0.650457, t print 11.232s, t batch 0.562s
train Ep 31, Sp 6720, loss 0.688946, t print 20.786s, t batch 1.039s
train Ep 31, Sp 6880, loss 0.674018, t print 11.319s, t batch 0.566s
train Ep 31, Sp 7040, loss 0.693621, t print 11.021s, t batch 0.551s
train Ep 31, Sp 7200, loss 0.702005, t print 20.389s, t batch 1.019s
train Ep 31, Sp 7360, loss 0.656689, t print 11.261s, t batch 0.563s
train Ep 31, Sp 7520, loss 0.688428, t print 11.099s, t batch 0.555s
train Ep 31, Sp 7680, loss 0.683911, t print 20.6s, t batch 1.03s
train Ep 31, Sp 7840, loss 0.693765, t print 11.16s, t batch 0.558s
train Ep 31, Sp 8000, loss 0.670642, t print 11.445s, t batch 0.572s
train Ep 31, Sp 8160, loss 0.718384, t print 19.5s, t batch 0.975s
train Ep 31, Sp 8320, loss 0.701644, t print 10.949s, t batch 0.547s
train Ep 31, Sp 8480, loss 0.648885, t print 13.777s, t batch 0.689s
train Ep 31, Sp 8640, loss 0.701019, t print 17.125s, t batch 0.856s
train Ep 31, Sp 8800, loss 0.709455, t print 10.751s, t batch 0.538s
train Ep 31, Sp 8960, loss 0.696275, t print 14.639s, t batch 0.732s
train Ep 31, Sp 9120, loss 0.659885, t print 16.303s, t batch 0.815s
train Ep 31, Sp 9280, loss 0.65555, t print 10.84s, t batch 0.542s
train Ep 31, Sp 9440, loss 0.665102, t print 16.214s, t batch 0.811s
train Ep 31, Sp 9600, loss 0.713353, t print 14.66s, t batch 0.733s
train Ep 31, Sp 9760, loss 0.663152, t print 10.868s, t batch 0.543s
train Ep 31, Sp 9920, loss 0.674658, t print 16.972s, t batch 0.849s
train Ep 31, Sp 10080, loss 0.653853, t print 14.046s, t batch 0.702s
train Ep 31, Sp 10240, loss 0.640928, t print 10.767s, t batch 0.538s
Start looping batches...
validate Ep 31, Sp 160, loss 0.681264, t print 1.032s, t batch 0.052s
validate Ep 31, Sp 320, loss 0.665682, t print 11.096s, t batch 0.555s
validate Ep 31, Sp 480, loss 0.684716, t print 12.353s, t batch 0.618s
validate Ep 31, Sp 640, loss 0.698894, t print 10.99s, t batch 0.549s
validate Ep 31, Sp 800, loss 0.694262, t print 19.847s, t batch 0.992s
validate Ep 31, Sp 960, loss 0.721177, t print 13.251s, t batch 0.663s
validate Ep 31, Sp 1120, loss 0.675149, t print 11.384s, t batch 0.569s
validate Ep 31, Sp 1280, loss 0.702543, t print 15.981s, t batch 0.799s
validate Ep 31, Sp 1440, loss 0.695273, t print 17.092s, t batch 0.855s
validate Ep 31, Sp 1600, loss 0.675771, t print 11.445s, t batch 0.572s
validate Ep 31, Sp 1760, loss 0.666755, t print 11.515s, t batch 0.576s
validate Ep 31, Sp 1920, loss 0.70072, t print 20.51s, t batch 1.026s
validate Ep 31, Sp 2080, loss 0.719981, t print 11.048s, t batch 0.552s
validate Ep 31, Sp 2240, loss 0.686735, t print 11.07s, t batch 0.554s
validate Ep 31, Sp 2400, loss 0.685175, t print 20.789s, t batch 1.039s
  Epoch 31, Average Epoch loss = 0.6793586215303268
  Epoch 31, nr_of_updates 41472
current learning rate: 0.001
  Epoch 31, time total 1124.270178079605s
  Epoch 31, time UNet: 124.6744954586029s
  Epoch 31, time metrics: 0.13893532752990723s
  Epoch 31, time saving files: 0.00023365020751953125s
2023-11-30 23:48:41.306798
Start looping batches...
train Ep 32, Sp 160, loss 0.717104, t print 1.593s, t batch 0.08s
train Ep 32, Sp 320, loss 0.629897, t print 11.78s, t batch 0.589s
train Ep 32, Sp 480, loss 0.69479, t print 12.872s, t batch 0.644s
train Ep 32, Sp 640, loss 0.68893, t print 11.709s, t batch 0.585s
train Ep 32, Sp 800, loss 0.667295, t print 22.175s, t batch 1.109s
train Ep 32, Sp 960, loss 0.697976, t print 11.922s, t batch 0.596s
train Ep 32, Sp 1120, loss 0.700402, t print 11.68s, t batch 0.584s
train Ep 32, Sp 1280, loss 0.642149, t print 21.777s, t batch 1.089s
train Ep 32, Sp 1440, loss 0.687046, t print 11.625s, t batch 0.581s
train Ep 32, Sp 1600, loss 0.694274, t print 11.694s, t batch 0.585s
train Ep 32, Sp 1760, loss 0.654747, t print 21.313s, t batch 1.066s
train Ep 32, Sp 1920, loss 0.655334, t print 11.493s, t batch 0.575s
train Ep 32, Sp 2080, loss 0.693435, t print 11.452s, t batch 0.573s
train Ep 32, Sp 2240, loss 0.689222, t print 20.562s, t batch 1.028s
train Ep 32, Sp 2400, loss 0.669501, t print 11.482s, t batch 0.574s
train Ep 32, Sp 2560, loss 0.666465, t print 11.175s, t batch 0.559s
train Ep 32, Sp 2720, loss 0.690998, t print 20.275s, t batch 1.014s
train Ep 32, Sp 2880, loss 0.672829, t print 11.595s, t batch 0.58s
train Ep 32, Sp 3040, loss 0.682151, t print 11.086s, t batch 0.554s
train Ep 32, Sp 3200, loss 0.69135, t print 20.142s, t batch 1.007s
train Ep 32, Sp 3360, loss 0.649599, t print 11.806s, t batch 0.59s
train Ep 32, Sp 3520, loss 0.688635, t print 11.634s, t batch 0.582s
train Ep 32, Sp 3680, loss 0.673806, t print 20.089s, t batch 1.004s
train Ep 32, Sp 3840, loss 0.689917, t print 12.322s, t batch 0.616s
train Ep 32, Sp 4000, loss 0.685238, t print 11.098s, t batch 0.555s
train Ep 32, Sp 4160, loss 0.671574, t print 19.547s, t batch 0.977s
train Ep 32, Sp 4320, loss 0.688439, t print 12.547s, t batch 0.627s
train Ep 32, Sp 4480, loss 0.695975, t print 10.978s, t batch 0.549s
train Ep 32, Sp 4640, loss 0.694488, t print 18.285s, t batch 0.914s
train Ep 32, Sp 4800, loss 0.659115, t print 13.546s, t batch 0.677s
train Ep 32, Sp 4960, loss 0.698778, t print 11.229s, t batch 0.561s
train Ep 32, Sp 5120, loss 0.678994, t print 17.419s, t batch 0.871s
train Ep 32, Sp 5280, loss 0.684524, t print 14.796s, t batch 0.74s
train Ep 32, Sp 5440, loss 0.675, t print 10.874s, t batch 0.544s
train Ep 32, Sp 5600, loss 0.681183, t print 16.672s, t batch 0.834s
train Ep 32, Sp 5760, loss 0.671741, t print 14.6s, t batch 0.73s
train Ep 32, Sp 5920, loss 0.657691, t print 11.171s, t batch 0.559s
train Ep 32, Sp 6080, loss 0.750036, t print 16.472s, t batch 0.824s
train Ep 32, Sp 6240, loss 0.69114, t print 15.094s, t batch 0.755s
train Ep 32, Sp 6400, loss 0.682538, t print 10.998s, t batch 0.55s
train Ep 32, Sp 6560, loss 0.661017, t print 15.915s, t batch 0.796s
train Ep 32, Sp 6720, loss 0.701812, t print 15.397s, t batch 0.77s
train Ep 32, Sp 6880, loss 0.660296, t print 10.98s, t batch 0.549s
train Ep 32, Sp 7040, loss 0.701321, t print 15.475s, t batch 0.774s
train Ep 32, Sp 7200, loss 0.707078, t print 15.977s, t batch 0.799s
train Ep 32, Sp 7360, loss 0.681769, t print 11.067s, t batch 0.553s
train Ep 32, Sp 7520, loss 0.646289, t print 15.392s, t batch 0.77s
train Ep 32, Sp 7680, loss 0.673182, t print 16.246s, t batch 0.812s
train Ep 32, Sp 7840, loss 0.673668, t print 11.119s, t batch 0.556s
train Ep 32, Sp 8000, loss 0.688637, t print 15.155s, t batch 0.758s
train Ep 32, Sp 8160, loss 0.682941, t print 16.423s, t batch 0.821s
train Ep 32, Sp 8320, loss 0.692113, t print 10.947s, t batch 0.547s
train Ep 32, Sp 8480, loss 0.66427, t print 15.368s, t batch 0.768s
train Ep 32, Sp 8640, loss 0.692406, t print 15.779s, t batch 0.789s
train Ep 32, Sp 8800, loss 0.671439, t print 10.949s, t batch 0.547s
train Ep 32, Sp 8960, loss 0.719018, t print 16.242s, t batch 0.812s
train Ep 32, Sp 9120, loss 0.670245, t print 15.303s, t batch 0.765s
train Ep 32, Sp 9280, loss 0.697666, t print 10.862s, t batch 0.543s
train Ep 32, Sp 9440, loss 0.689553, t print 17.208s, t batch 0.86s
train Ep 32, Sp 9600, loss 0.709253, t print 14.336s, t batch 0.717s
train Ep 32, Sp 9760, loss 0.71203, t print 11.033s, t batch 0.552s
train Ep 32, Sp 9920, loss 0.649311, t print 18.291s, t batch 0.915s
train Ep 32, Sp 10080, loss 0.688212, t print 13.049s, t batch 0.652s
train Ep 32, Sp 10240, loss 0.641991, t print 11.021s, t batch 0.551s
Start looping batches...
validate Ep 32, Sp 160, loss 0.687459, t print 0.989s, t batch 0.049s
validate Ep 32, Sp 320, loss 0.685821, t print 12.485s, t batch 0.624s
validate Ep 32, Sp 480, loss 0.671817, t print 12.3s, t batch 0.615s
validate Ep 32, Sp 640, loss 0.70682, t print 11.566s, t batch 0.578s
validate Ep 32, Sp 800, loss 0.696267, t print 20.293s, t batch 1.015s
validate Ep 32, Sp 960, loss 0.67656, t print 10.718s, t batch 0.536s
validate Ep 32, Sp 1120, loss 0.682257, t print 10.698s, t batch 0.535s
validate Ep 32, Sp 1280, loss 0.645737, t print 20.689s, t batch 1.034s
validate Ep 32, Sp 1440, loss 0.691966, t print 10.93s, t batch 0.546s
validate Ep 32, Sp 1600, loss 0.661051, t print 11.004s, t batch 0.55s
validate Ep 32, Sp 1760, loss 0.684812, t print 20.788s, t batch 1.039s
validate Ep 32, Sp 1920, loss 0.664205, t print 10.866s, t batch 0.543s
validate Ep 32, Sp 2080, loss 0.65457, t print 10.783s, t batch 0.539s
validate Ep 32, Sp 2240, loss 0.681083, t print 20.833s, t batch 1.042s
validate Ep 32, Sp 2400, loss 0.67347, t print 10.933s, t batch 0.547s
  Epoch 32, Average Epoch loss = 0.6818418639401594
  Epoch 32, nr_of_updates 42768
current learning rate: 0.001
  Saving weights...
  Epoch 32, time total 1107.9138362407684s
  Epoch 32, time UNet: 123.85235452651978s
  Epoch 32, time metrics: 0.13994431495666504s
  Epoch 32, time saving files: 0.3819284439086914s
2023-12-01 00:07:09.228818
Start looping batches...
train Ep 33, Sp 160, loss 0.678068, t print 1.636s, t batch 0.082s
train Ep 33, Sp 320, loss 0.662984, t print 11.755s, t batch 0.588s
train Ep 33, Sp 480, loss 0.732989, t print 12.387s, t batch 0.619s
train Ep 33, Sp 640, loss 0.717577, t print 11.492s, t batch 0.575s
train Ep 33, Sp 800, loss 0.701197, t print 19.968s, t batch 0.998s
train Ep 33, Sp 960, loss 0.673897, t print 13.5s, t batch 0.675s
train Ep 33, Sp 1120, loss 0.661953, t print 11.765s, t batch 0.588s
train Ep 33, Sp 1280, loss 0.682436, t print 16.551s, t batch 0.828s
train Ep 33, Sp 1440, loss 0.674889, t print 15.824s, t batch 0.791s
train Ep 33, Sp 1600, loss 0.646549, t print 11.157s, t batch 0.558s
train Ep 33, Sp 1760, loss 0.672848, t print 14.955s, t batch 0.748s
train Ep 33, Sp 1920, loss 0.722807, t print 14.382s, t batch 0.719s
train Ep 33, Sp 2080, loss 0.650129, t print 13.918s, t batch 0.696s
train Ep 33, Sp 2240, loss 0.699838, t print 13.456s, t batch 0.673s
train Ep 33, Sp 2400, loss 0.6948, t print 14.119s, t batch 0.706s
train Ep 33, Sp 2560, loss 0.684186, t print 14.93s, t batch 0.746s
train Ep 33, Sp 2720, loss 0.638968, t print 12.347s, t batch 0.617s
train Ep 33, Sp 2880, loss 0.63535, t print 14.198s, t batch 0.71s
train Ep 33, Sp 3040, loss 0.664464, t print 16.515s, t batch 0.826s
train Ep 33, Sp 3200, loss 0.681941, t print 11.193s, t batch 0.56s
train Ep 33, Sp 3360, loss 0.679808, t print 14.556s, t batch 0.728s
train Ep 33, Sp 3520, loss 0.674837, t print 17.476s, t batch 0.874s
train Ep 33, Sp 3680, loss 0.688148, t print 11.089s, t batch 0.554s
train Ep 33, Sp 3840, loss 0.670023, t print 14.797s, t batch 0.74s
train Ep 33, Sp 4000, loss 0.633426, t print 17.384s, t batch 0.869s
train Ep 33, Sp 4160, loss 0.666839, t print 11.202s, t batch 0.56s
train Ep 33, Sp 4320, loss 0.686403, t print 14.642s, t batch 0.732s
train Ep 33, Sp 4480, loss 0.697232, t print 17.315s, t batch 0.866s
train Ep 33, Sp 4640, loss 0.682165, t print 11.292s, t batch 0.565s
train Ep 33, Sp 4800, loss 0.696736, t print 15.144s, t batch 0.757s
train Ep 33, Sp 4960, loss 0.658633, t print 16.974s, t batch 0.849s
train Ep 33, Sp 5120, loss 0.693022, t print 11.048s, t batch 0.552s
train Ep 33, Sp 5280, loss 0.69002, t print 12.811s, t batch 0.641s
train Ep 33, Sp 5440, loss 0.642861, t print 18.855s, t batch 0.943s
train Ep 33, Sp 5600, loss 0.683224, t print 11.214s, t batch 0.561s
train Ep 33, Sp 5760, loss 0.666865, t print 12.206s, t batch 0.61s
train Ep 33, Sp 5920, loss 0.701154, t print 19.717s, t batch 0.986s
train Ep 33, Sp 6080, loss 0.706204, t print 11.189s, t batch 0.559s
train Ep 33, Sp 6240, loss 0.707364, t print 12.395s, t batch 0.62s
train Ep 33, Sp 6400, loss 0.685584, t print 19.574s, t batch 0.979s
train Ep 33, Sp 6560, loss 0.65922, t print 11.167s, t batch 0.558s
train Ep 33, Sp 6720, loss 0.702447, t print 12.176s, t batch 0.609s
train Ep 33, Sp 6880, loss 0.659379, t print 20.074s, t batch 1.004s
train Ep 33, Sp 7040, loss 0.671687, t print 11.182s, t batch 0.559s
train Ep 33, Sp 7200, loss 0.669768, t print 11.902s, t batch 0.595s
train Ep 33, Sp 7360, loss 0.68477, t print 20.21s, t batch 1.011s
train Ep 33, Sp 7520, loss 0.689004, t print 11.099s, t batch 0.555s
train Ep 33, Sp 7680, loss 0.671852, t print 11.812s, t batch 0.591s
train Ep 33, Sp 7840, loss 0.657479, t print 19.957s, t batch 0.998s
train Ep 33, Sp 8000, loss 0.720298, t print 11.18s, t batch 0.559s
train Ep 33, Sp 8160, loss 0.677769, t print 11.885s, t batch 0.594s
train Ep 33, Sp 8320, loss 0.668244, t print 20.392s, t batch 1.02s
train Ep 33, Sp 8480, loss 0.65799, t print 11.267s, t batch 0.563s
train Ep 33, Sp 8640, loss 0.650813, t print 11.63s, t batch 0.581s
train Ep 33, Sp 8800, loss 0.680128, t print 20.629s, t batch 1.031s
train Ep 33, Sp 8960, loss 0.699758, t print 11.183s, t batch 0.559s
train Ep 33, Sp 9120, loss 0.695333, t print 11.887s, t batch 0.594s
train Ep 33, Sp 9280, loss 0.674891, t print 21.472s, t batch 1.074s
train Ep 33, Sp 9440, loss 0.713493, t print 11.678s, t batch 0.584s
train Ep 33, Sp 9600, loss 0.697849, t print 11.721s, t batch 0.586s
train Ep 33, Sp 9760, loss 0.683449, t print 21.533s, t batch 1.077s
train Ep 33, Sp 9920, loss 0.706938, t print 11.494s, t batch 0.575s
train Ep 33, Sp 10080, loss 0.712092, t print 11.444s, t batch 0.572s
train Ep 33, Sp 10240, loss 0.683692, t print 21.311s, t batch 1.066s
Start looping batches...
validate Ep 33, Sp 160, loss 0.690896, t print 0.988s, t batch 0.049s
validate Ep 33, Sp 320, loss 0.719, t print 1252.477s, t batch 62.624s
validate Ep 33, Sp 480, loss 0.690827, t print 11.821s, t batch 0.591s
validate Ep 33, Sp 640, loss 0.66206, t print 11.213s, t batch 0.561s
validate Ep 33, Sp 800, loss 0.661907, t print 19.747s, t batch 0.987s
validate Ep 33, Sp 960, loss 0.674349, t print 11.592s, t batch 0.58s
validate Ep 33, Sp 1120, loss 0.717346, t print 11.101s, t batch 0.555s
validate Ep 33, Sp 1280, loss 0.702987, t print 19.463s, t batch 0.973s
validate Ep 33, Sp 1440, loss 0.697036, t print 12.084s, t batch 0.604s
validate Ep 33, Sp 1600, loss 0.67584, t print 10.768s, t batch 0.538s
validate Ep 33, Sp 1760, loss 0.713767, t print 18.981s, t batch 0.949s
validate Ep 33, Sp 1920, loss 0.720078, t print 12.243s, t batch 0.612s
validate Ep 33, Sp 2080, loss 0.703438, t print 10.837s, t batch 0.542s
validate Ep 33, Sp 2240, loss 0.681857, t print 17.551s, t batch 0.878s
validate Ep 33, Sp 2400, loss 0.677161, t print 14.019s, t batch 0.701s
  Epoch 33, Average Epoch loss = 0.6807252981320575
  Epoch 33, nr_of_updates 44064
current learning rate: 0.001
  Epoch 33, time total 2354.990254163742s
  Epoch 33, time UNet: 124.98076272010803s
  Epoch 33, time metrics: 0.1447288990020752s
  Epoch 33, time saving files: 0.00023818016052246094s
2023-12-01 00:46:24.227305
Start looping batches...
train Ep 34, Sp 160, loss 0.67224, t print 1.766s, t batch 0.088s
train Ep 34, Sp 320, loss 0.712048, t print 10.843s, t batch 0.542s
train Ep 34, Sp 480, loss 0.691906, t print 12.68s, t batch 0.634s
train Ep 34, Sp 640, loss 0.695106, t print 12.016s, t batch 0.601s
train Ep 34, Sp 800, loss 0.712223, t print 19.892s, t batch 0.995s
train Ep 34, Sp 960, loss 0.678794, t print 12.259s, t batch 0.613s
train Ep 34, Sp 1120, loss 0.656373, t print 11.349s, t batch 0.567s
train Ep 34, Sp 1280, loss 0.681513, t print 19.537s, t batch 0.977s
train Ep 34, Sp 1440, loss 0.710849, t print 13.315s, t batch 0.666s
train Ep 34, Sp 1600, loss 0.656802, t print 11.446s, t batch 0.572s
train Ep 34, Sp 1760, loss 0.666473, t print 16.508s, t batch 0.825s
train Ep 34, Sp 1920, loss 0.650325, t print 16.093s, t batch 0.805s
train Ep 34, Sp 2080, loss 0.690474, t print 11.343s, t batch 0.567s
train Ep 34, Sp 2240, loss 0.662371, t print 14.369s, t batch 0.718s
train Ep 34, Sp 2400, loss 0.681403, t print 18.02s, t batch 0.901s
train Ep 34, Sp 2560, loss 0.685095, t print 11.279s, t batch 0.564s
train Ep 34, Sp 2720, loss 0.662439, t print 12.038s, t batch 0.602s
train Ep 34, Sp 2880, loss 0.670869, t print 20.196s, t batch 1.01s
train Ep 34, Sp 3040, loss 0.671878, t print 11.418s, t batch 0.571s
train Ep 34, Sp 3200, loss 0.686577, t print 11.416s, t batch 0.571s
train Ep 34, Sp 3360, loss 0.703587, t print 21.014s, t batch 1.051s
train Ep 34, Sp 3520, loss 0.707985, t print 11.244s, t batch 0.562s
train Ep 34, Sp 3680, loss 0.722946, t print 11.316s, t batch 0.566s
train Ep 34, Sp 3840, loss 0.638283, t print 21.473s, t batch 1.074s
train Ep 34, Sp 4000, loss 0.677791, t print 11.385s, t batch 0.569s
train Ep 34, Sp 4160, loss 0.688495, t print 11.542s, t batch 0.577s
train Ep 34, Sp 4320, loss 0.681992, t print 21.22s, t batch 1.061s
train Ep 34, Sp 4480, loss 0.659682, t print 11.294s, t batch 0.565s
train Ep 34, Sp 4640, loss 0.66524, t print 11.255s, t batch 0.563s
train Ep 34, Sp 4800, loss 0.686741, t print 21.257s, t batch 1.063s
train Ep 34, Sp 4960, loss 0.722092, t print 11.33s, t batch 0.567s
train Ep 34, Sp 5120, loss 0.647861, t print 11.415s, t batch 0.571s
train Ep 34, Sp 5280, loss 0.671437, t print 21.353s, t batch 1.068s
train Ep 34, Sp 5440, loss 0.696417, t print 11.359s, t batch 0.568s
train Ep 34, Sp 5600, loss 0.67558, t print 11.363s, t batch 0.568s
train Ep 34, Sp 5760, loss 0.66356, t print 21.073s, t batch 1.054s
train Ep 34, Sp 5920, loss 0.679443, t print 11.254s, t batch 0.563s
train Ep 34, Sp 6080, loss 0.680475, t print 11.43s, t batch 0.571s
train Ep 34, Sp 6240, loss 0.681007, t print 21.003s, t batch 1.05s
train Ep 34, Sp 6400, loss 0.674268, t print 11.251s, t batch 0.563s
train Ep 34, Sp 6560, loss 0.672288, t print 11.132s, t batch 0.557s
train Ep 34, Sp 6720, loss 0.675223, t print 20.817s, t batch 1.041s
train Ep 34, Sp 6880, loss 0.670673, t print 11.104s, t batch 0.555s
train Ep 34, Sp 7040, loss 0.697107, t print 11.097s, t batch 0.555s
train Ep 34, Sp 7200, loss 0.669905, t print 20.618s, t batch 1.031s
train Ep 34, Sp 7360, loss 0.685912, t print 11.16s, t batch 0.558s
train Ep 34, Sp 7520, loss 0.697594, t print 11.099s, t batch 0.555s
train Ep 34, Sp 7680, loss 0.668861, t print 20.722s, t batch 1.036s
train Ep 34, Sp 7840, loss 0.66527, t print 11.169s, t batch 0.558s
train Ep 34, Sp 8000, loss 0.666208, t print 11.13s, t batch 0.556s
train Ep 34, Sp 8160, loss 0.665776, t print 20.576s, t batch 1.029s
train Ep 34, Sp 8320, loss 0.70106, t print 11.087s, t batch 0.554s
train Ep 34, Sp 8480, loss 0.700376, t print 11.137s, t batch 0.557s
train Ep 34, Sp 8640, loss 0.677723, t print 20.298s, t batch 1.015s
train Ep 34, Sp 8800, loss 0.685959, t print 10.81s, t batch 0.54s
train Ep 34, Sp 8960, loss 0.687427, t print 10.726s, t batch 0.536s
train Ep 34, Sp 9120, loss 0.669897, t print 19.865s, t batch 0.993s
train Ep 34, Sp 9280, loss 0.652357, t print 10.852s, t batch 0.543s
train Ep 34, Sp 9440, loss 0.687915, t print 10.919s, t batch 0.546s
train Ep 34, Sp 9600, loss 0.68481, t print 20.348s, t batch 1.017s
train Ep 34, Sp 9760, loss 0.684299, t print 10.822s, t batch 0.541s
train Ep 34, Sp 9920, loss 0.669077, t print 10.886s, t batch 0.544s
train Ep 34, Sp 10080, loss 0.694934, t print 20.39s, t batch 1.019s
train Ep 34, Sp 10240, loss 0.659033, t print 10.968s, t batch 0.548s
Start looping batches...
validate Ep 34, Sp 160, loss 0.692598, t print 1.102s, t batch 0.055s
validate Ep 34, Sp 320, loss 0.705412, t print 11.469s, t batch 0.573s
validate Ep 34, Sp 480, loss 0.711432, t print 12.049s, t batch 0.602s
validate Ep 34, Sp 640, loss 0.701267, t print 11.463s, t batch 0.573s
validate Ep 34, Sp 800, loss 0.692691, t print 21.167s, t batch 1.058s
validate Ep 34, Sp 960, loss 0.710115, t print 10.725s, t batch 0.536s
validate Ep 34, Sp 1120, loss 0.692834, t print 11.143s, t batch 0.557s
validate Ep 34, Sp 1280, loss 0.720675, t print 20.59s, t batch 1.03s
validate Ep 34, Sp 1440, loss 0.663631, t print 10.945s, t batch 0.547s
validate Ep 34, Sp 1600, loss 0.685733, t print 11.039s, t batch 0.552s
validate Ep 34, Sp 1760, loss 0.680441, t print 20.81s, t batch 1.04s
validate Ep 34, Sp 1920, loss 0.695867, t print 10.855s, t batch 0.543s
validate Ep 34, Sp 2080, loss 0.655119, t print 10.931s, t batch 0.547s
validate Ep 34, Sp 2240, loss 0.687078, t print 20.97s, t batch 1.048s
validate Ep 34, Sp 2400, loss 0.706393, t print 10.919s, t batch 0.546s
  Epoch 34, Average Epoch loss = 0.6802474501324288
  Epoch 34, nr_of_updates 45360
current learning rate: 0.001
  Epoch 34, time total 1110.738634109497s
  Epoch 34, time UNet: 122.57415342330933s
  Epoch 34, time metrics: 0.13342547416687012s
  Epoch 34, time saving files: 0.0001327991485595703s
2023-12-01 01:04:54.974209
Start looping batches...
train Ep 35, Sp 160, loss 0.688219, t print 1.707s, t batch 0.085s
train Ep 35, Sp 320, loss 0.693151, t print 11.52s, t batch 0.576s
train Ep 35, Sp 480, loss 0.695949, t print 13.231s, t batch 0.662s
train Ep 35, Sp 640, loss 0.677931, t print 12.129s, t batch 0.606s
train Ep 35, Sp 800, loss 0.679077, t print 20.818s, t batch 1.041s
train Ep 35, Sp 960, loss 0.667154, t print 11.413s, t batch 0.571s
train Ep 35, Sp 1120, loss 0.654781, t print 11.374s, t batch 0.569s
train Ep 35, Sp 1280, loss 0.670946, t print 21.631s, t batch 1.082s
train Ep 35, Sp 1440, loss 0.695203, t print 11.627s, t batch 0.581s
train Ep 35, Sp 1600, loss 0.666884, t print 11.65s, t batch 0.582s
train Ep 35, Sp 1760, loss 0.681069, t print 21.913s, t batch 1.096s
train Ep 35, Sp 1920, loss 0.6723, t print 11.512s, t batch 0.576s
train Ep 35, Sp 2080, loss 0.659156, t print 11.529s, t batch 0.576s
train Ep 35, Sp 2240, loss 0.710822, t print 21.553s, t batch 1.078s
train Ep 35, Sp 2400, loss 0.705643, t print 11.499s, t batch 0.575s
train Ep 35, Sp 2560, loss 0.667185, t print 11.648s, t batch 0.582s
train Ep 35, Sp 2720, loss 0.705016, t print 21.159s, t batch 1.058s
train Ep 35, Sp 2880, loss 0.660835, t print 11.444s, t batch 0.572s
train Ep 35, Sp 3040, loss 0.683325, t print 11.283s, t batch 0.564s
train Ep 35, Sp 3200, loss 0.619034, t print 21.401s, t batch 1.07s
train Ep 35, Sp 3360, loss 0.651484, t print 11.282s, t batch 0.564s
train Ep 35, Sp 3520, loss 0.677772, t print 11.144s, t batch 0.557s
train Ep 35, Sp 3680, loss 0.651838, t print 20.949s, t batch 1.047s
train Ep 35, Sp 3840, loss 0.662828, t print 11.185s, t batch 0.559s
train Ep 35, Sp 4000, loss 0.645334, t print 11.241s, t batch 0.562s
train Ep 35, Sp 4160, loss 0.640589, t print 20.912s, t batch 1.046s
train Ep 35, Sp 4320, loss 0.682412, t print 11.378s, t batch 0.569s
train Ep 35, Sp 4480, loss 0.693728, t print 11.122s, t batch 0.556s
train Ep 35, Sp 4640, loss 0.649847, t print 20.87s, t batch 1.044s
train Ep 35, Sp 4800, loss 0.688603, t print 11.275s, t batch 0.564s
train Ep 35, Sp 4960, loss 0.680539, t print 11.12s, t batch 0.556s
train Ep 35, Sp 5120, loss 0.687046, t print 20.601s, t batch 1.03s
train Ep 35, Sp 5280, loss 0.684609, t print 11.018s, t batch 0.551s
train Ep 35, Sp 5440, loss 0.681322, t print 11.178s, t batch 0.559s
train Ep 35, Sp 5600, loss 0.679526, t print 20.22s, t batch 1.011s
train Ep 35, Sp 5760, loss 0.644022, t print 10.899s, t batch 0.545s
train Ep 35, Sp 5920, loss 0.675209, t print 11.921s, t batch 0.596s
train Ep 35, Sp 6080, loss 0.667707, t print 18.838s, t batch 0.942s
train Ep 35, Sp 6240, loss 0.66625, t print 10.94s, t batch 0.547s
train Ep 35, Sp 6400, loss 0.701909, t print 12.916s, t batch 0.646s
train Ep 35, Sp 6560, loss 0.669021, t print 18.115s, t batch 0.906s
train Ep 35, Sp 6720, loss 0.649848, t print 10.865s, t batch 0.543s
train Ep 35, Sp 6880, loss 0.68439, t print 12.67s, t batch 0.633s
train Ep 35, Sp 7040, loss 0.666634, t print 18.249s, t batch 0.912s
train Ep 35, Sp 7200, loss 0.681852, t print 10.923s, t batch 0.546s
train Ep 35, Sp 7360, loss 0.676488, t print 12.82s, t batch 0.641s
train Ep 35, Sp 7520, loss 0.65786, t print 18.082s, t batch 0.904s
train Ep 35, Sp 7680, loss 0.707132, t print 10.763s, t batch 0.538s
train Ep 35, Sp 7840, loss 0.684096, t print 12.906s, t batch 0.645s
train Ep 35, Sp 8000, loss 0.705748, t print 18.367s, t batch 0.918s
train Ep 35, Sp 8160, loss 0.700685, t print 11.022s, t batch 0.551s
train Ep 35, Sp 8320, loss 0.657473, t print 12.294s, t batch 0.615s
train Ep 35, Sp 8480, loss 0.710369, t print 19.438s, t batch 0.972s
train Ep 35, Sp 8640, loss 0.664851, t print 11.19s, t batch 0.559s
train Ep 35, Sp 8800, loss 0.674694, t print 11.352s, t batch 0.568s
train Ep 35, Sp 8960, loss 0.673676, t print 21.066s, t batch 1.053s
train Ep 35, Sp 9120, loss 0.655422, t print 11.425s, t batch 0.571s
train Ep 35, Sp 9280, loss 0.674978, t print 11.452s, t batch 0.573s
train Ep 35, Sp 9440, loss 0.723056, t print 21.151s, t batch 1.058s
train Ep 35, Sp 9600, loss 0.672768, t print 11.419s, t batch 0.571s
train Ep 35, Sp 9760, loss 0.689652, t print 11.28s, t batch 0.564s
train Ep 35, Sp 9920, loss 0.687549, t print 21.044s, t batch 1.052s
train Ep 35, Sp 10080, loss 0.662388, t print 11.243s, t batch 0.562s
train Ep 35, Sp 10240, loss 0.63299, t print 11.363s, t batch 0.568s
Start looping batches...
validate Ep 35, Sp 160, loss 0.686815, t print 1.043s, t batch 0.052s
validate Ep 35, Sp 320, loss 0.688534, t print 12.546s, t batch 0.627s
validate Ep 35, Sp 480, loss 0.698424, t print 12.766s, t batch 0.638s
validate Ep 35, Sp 640, loss 0.663521, t print 11.342s, t batch 0.567s
validate Ep 35, Sp 800, loss 0.665816, t print 19.565s, t batch 0.978s
validate Ep 35, Sp 960, loss 0.667027, t print 11.593s, t batch 0.58s
validate Ep 35, Sp 1120, loss 0.681399, t print 10.852s, t batch 0.543s
validate Ep 35, Sp 1280, loss 0.720268, t print 19.096s, t batch 0.955s
validate Ep 35, Sp 1440, loss 0.649553, t print 12.483s, t batch 0.624s
validate Ep 35, Sp 1600, loss 0.671028, t print 10.854s, t batch 0.543s
validate Ep 35, Sp 1760, loss 0.712971, t print 17.969s, t batch 0.898s
validate Ep 35, Sp 1920, loss 0.709331, t print 14.079s, t batch 0.704s
validate Ep 35, Sp 2080, loss 0.689182, t print 10.675s, t batch 0.534s
validate Ep 35, Sp 2240, loss 0.708153, t print 16.21s, t batch 0.811s
validate Ep 35, Sp 2400, loss 0.676504, t print 15.491s, t batch 0.775s
  Epoch 35, Average Epoch loss = 0.6753987624413438
  Epoch 35, nr_of_updates 46656
current learning rate: 0.001
  Epoch 35, time total 1111.888514995575s
  Epoch 35, time UNet: 124.2775673866272s
  Epoch 35, time metrics: 0.12928152084350586s
  Epoch 35, time saving files: 0.00030732154846191406s
2023-12-01 01:23:26.869960
Start looping batches...
train Ep 36, Sp 160, loss 0.676574, t print 1.644s, t batch 0.082s
train Ep 36, Sp 320, loss 0.670239, t print 11.057s, t batch 0.553s
train Ep 36, Sp 480, loss 0.666039, t print 13.589s, t batch 0.679s
train Ep 36, Sp 640, loss 0.698224, t print 11.788s, t batch 0.589s
train Ep 36, Sp 800, loss 0.701264, t print 19.66s, t batch 0.983s
train Ep 36, Sp 960, loss 0.685423, t print 13.808s, t batch 0.69s
train Ep 36, Sp 1120, loss 0.664668, t print 11.583s, t batch 0.579s
train Ep 36, Sp 1280, loss 0.691775, t print 17.173s, t batch 0.859s
train Ep 36, Sp 1440, loss 0.675638, t print 16.47s, t batch 0.824s
train Ep 36, Sp 1600, loss 0.648616, t print 11.685s, t batch 0.584s
train Ep 36, Sp 1760, loss 0.682191, t print 14.354s, t batch 0.718s
train Ep 36, Sp 1920, loss 0.686378, t print 18.677s, t batch 0.934s
train Ep 36, Sp 2080, loss 0.678776, t print 11.625s, t batch 0.581s
train Ep 36, Sp 2240, loss 0.677132, t print 11.793s, t batch 0.59s
train Ep 36, Sp 2400, loss 0.677874, t print 20.873s, t batch 1.044s
train Ep 36, Sp 2560, loss 0.648722, t print 11.453s, t batch 0.573s
train Ep 36, Sp 2720, loss 0.680452, t print 11.384s, t batch 0.569s
train Ep 36, Sp 2880, loss 0.639573, t print 20.965s, t batch 1.048s
train Ep 36, Sp 3040, loss 0.662889, t print 11.291s, t batch 0.565s
train Ep 36, Sp 3200, loss 0.675849, t print 11.366s, t batch 0.568s
train Ep 36, Sp 3360, loss 0.699479, t print 21.18s, t batch 1.059s
train Ep 36, Sp 3520, loss 0.692884, t print 11.432s, t batch 0.572s
train Ep 36, Sp 3680, loss 0.664467, t print 10.957s, t batch 0.548s
train Ep 36, Sp 3840, loss 0.691447, t print 20.408s, t batch 1.02s
train Ep 36, Sp 4000, loss 0.707886, t print 11.127s, t batch 0.556s
train Ep 36, Sp 4160, loss 0.701763, t print 11.031s, t batch 0.552s
train Ep 36, Sp 4320, loss 0.71557, t print 19.517s, t batch 0.976s
train Ep 36, Sp 4480, loss 0.688037, t print 12.659s, t batch 0.633s
train Ep 36, Sp 4640, loss 0.690293, t print 11.329s, t batch 0.566s
train Ep 36, Sp 4800, loss 0.691565, t print 16.492s, t batch 0.825s
train Ep 36, Sp 4960, loss 0.651034, t print 15.931s, t batch 0.797s
train Ep 36, Sp 5120, loss 0.668398, t print 11.403s, t batch 0.57s
train Ep 36, Sp 5280, loss 0.659121, t print 13.113s, t batch 0.656s
train Ep 36, Sp 5440, loss 0.704376, t print 19.612s, t batch 0.981s
train Ep 36, Sp 5600, loss 0.669983, t print 11.152s, t batch 0.558s
train Ep 36, Sp 5760, loss 0.690558, t print 11.669s, t batch 0.583s
train Ep 36, Sp 5920, loss 0.673725, t print 20.426s, t batch 1.021s
train Ep 36, Sp 6080, loss 0.697983, t print 11.472s, t batch 0.574s
train Ep 36, Sp 6240, loss 0.663059, t print 11.859s, t batch 0.593s
train Ep 36, Sp 6400, loss 0.714908, t print 20.787s, t batch 1.039s
train Ep 36, Sp 6560, loss 0.648563, t print 11.412s, t batch 0.571s
train Ep 36, Sp 6720, loss 0.690497, t print 11.32s, t batch 0.566s
train Ep 36, Sp 6880, loss 0.675909, t print 21.156s, t batch 1.058s
train Ep 36, Sp 7040, loss 0.686619, t print 11.252s, t batch 0.563s
train Ep 36, Sp 7200, loss 0.681068, t print 11.239s, t batch 0.562s
train Ep 36, Sp 7360, loss 0.671794, t print 20.735s, t batch 1.037s
train Ep 36, Sp 7520, loss 0.69128, t print 11.226s, t batch 0.561s
train Ep 36, Sp 7680, loss 0.688171, t print 11.513s, t batch 0.576s
train Ep 36, Sp 7840, loss 0.719317, t print 20.635s, t batch 1.032s
train Ep 36, Sp 8000, loss 0.694932, t print 11.256s, t batch 0.563s
train Ep 36, Sp 8160, loss 0.682374, t print 11.612s, t batch 0.581s
train Ep 36, Sp 8320, loss 0.633709, t print 20.369s, t batch 1.018s
train Ep 36, Sp 8480, loss 0.675427, t print 11.097s, t batch 0.555s
train Ep 36, Sp 8640, loss 0.708484, t print 11.846s, t batch 0.592s
train Ep 36, Sp 8800, loss 0.670411, t print 19.859s, t batch 0.993s
train Ep 36, Sp 8960, loss 0.688317, t print 11.062s, t batch 0.553s
train Ep 36, Sp 9120, loss 0.691235, t print 12.205s, t batch 0.61s
train Ep 36, Sp 9280, loss 0.647636, t print 19.305s, t batch 0.965s
train Ep 36, Sp 9440, loss 0.67322, t print 11.042s, t batch 0.552s
train Ep 36, Sp 9600, loss 0.653566, t print 11.944s, t batch 0.597s
train Ep 36, Sp 9760, loss 0.688647, t print 19.695s, t batch 0.985s
train Ep 36, Sp 9920, loss 0.699908, t print 10.98s, t batch 0.549s
train Ep 36, Sp 10080, loss 0.681375, t print 11.715s, t batch 0.586s
train Ep 36, Sp 10240, loss 0.6641, t print 19.472s, t batch 0.974s
Start looping batches...
validate Ep 36, Sp 160, loss 0.699621, t print 1.022s, t batch 0.051s
validate Ep 36, Sp 320, loss 0.677302, t print 384.882s, t batch 19.244s
validate Ep 36, Sp 480, loss 0.708541, t print 11.922s, t batch 0.596s
validate Ep 36, Sp 640, loss 0.720486, t print 11.122s, t batch 0.556s
validate Ep 36, Sp 800, loss 0.710806, t print 18.965s, t batch 0.948s
validate Ep 36, Sp 960, loss 0.655514, t print 13.078s, t batch 0.654s
validate Ep 36, Sp 1120, loss 0.681864, t print 11.121s, t batch 0.556s
validate Ep 36, Sp 1280, loss 0.696633, t print 16.718s, t batch 0.836s
validate Ep 36, Sp 1440, loss 0.69231, t print 15.119s, t batch 0.756s
validate Ep 36, Sp 1600, loss 0.700903, t print 10.99s, t batch 0.549s
validate Ep 36, Sp 1760, loss 0.683662, t print 14.435s, t batch 0.722s
validate Ep 36, Sp 1920, loss 0.687048, t print 17.322s, t batch 0.866s
validate Ep 36, Sp 2080, loss 0.682809, t print 10.95s, t batch 0.547s
validate Ep 36, Sp 2240, loss 0.674271, t print 12.006s, t batch 0.6s
validate Ep 36, Sp 2400, loss 0.660527, t print 19.512s, t batch 0.976s
  Epoch 36, Average Epoch loss = 0.6795495638600838
  Epoch 36, nr_of_updates 47952
current learning rate: 0.001
  Epoch 36, time total 1490.2233757972717s
  Epoch 36, time UNet: 123.84253263473511s
  Epoch 36, time metrics: 0.13486242294311523s
  Epoch 36, time saving files: 0.00012731552124023438s
2023-12-01 01:48:17.101842
Start looping batches...
train Ep 37, Sp 160, loss 0.684368, t print 1.753s, t batch 0.088s
train Ep 37, Sp 320, loss 0.694985, t print 11.375s, t batch 0.569s
train Ep 37, Sp 480, loss 0.6865, t print 12.733s, t batch 0.637s
train Ep 37, Sp 640, loss 0.669304, t print 12.23s, t batch 0.612s
train Ep 37, Sp 800, loss 0.657679, t print 20.079s, t batch 1.004s
train Ep 37, Sp 960, loss 0.675046, t print 11.486s, t batch 0.574s
train Ep 37, Sp 1120, loss 0.724573, t print 12.375s, t batch 0.619s
train Ep 37, Sp 1280, loss 0.630235, t print 20.108s, t batch 1.005s
train Ep 37, Sp 1440, loss 0.652186, t print 11.331s, t batch 0.567s
train Ep 37, Sp 1600, loss 0.653637, t print 11.596s, t batch 0.58s
train Ep 37, Sp 1760, loss 0.634751, t print 20.72s, t batch 1.036s
train Ep 37, Sp 1920, loss 0.699669, t print 11.333s, t batch 0.567s
train Ep 37, Sp 2080, loss 0.677388, t print 11.194s, t batch 0.56s
train Ep 37, Sp 2240, loss 0.698323, t print 20.844s, t batch 1.042s
train Ep 37, Sp 2400, loss 0.700626, t print 11.85s, t batch 0.593s
train Ep 37, Sp 2560, loss 0.682987, t print 10.288s, t batch 0.514s
train Ep 37, Sp 2720, loss 0.671241, t print 20.809s, t batch 1.04s
train Ep 37, Sp 2880, loss 0.70496, t print 11.224s, t batch 0.561s
train Ep 37, Sp 3040, loss 0.690978, t print 11.036s, t batch 0.552s
train Ep 37, Sp 3200, loss 0.677975, t print 20.651s, t batch 1.033s
train Ep 37, Sp 3360, loss 0.674921, t print 11.066s, t batch 0.553s
train Ep 37, Sp 3520, loss 0.702126, t print 11.227s, t batch 0.561s
train Ep 37, Sp 3680, loss 0.671761, t print 20.561s, t batch 1.028s
train Ep 37, Sp 3840, loss 0.692678, t print 11.14s, t batch 0.557s
train Ep 37, Sp 4000, loss 0.688891, t print 11.068s, t batch 0.553s
train Ep 37, Sp 4160, loss 0.661844, t print 20.676s, t batch 1.034s
train Ep 37, Sp 4320, loss 0.654835, t print 11.172s, t batch 0.559s
train Ep 37, Sp 4480, loss 0.691639, t print 11.134s, t batch 0.557s
train Ep 37, Sp 4640, loss 0.701555, t print 20.668s, t batch 1.033s
train Ep 37, Sp 4800, loss 0.689865, t print 11.294s, t batch 0.565s
train Ep 37, Sp 4960, loss 0.686695, t print 11.1s, t batch 0.555s
train Ep 37, Sp 5120, loss 0.654933, t print 20.673s, t batch 1.034s
train Ep 37, Sp 5280, loss 0.665781, t print 11.222s, t batch 0.561s
train Ep 37, Sp 5440, loss 0.673117, t print 11.185s, t batch 0.559s
train Ep 37, Sp 5600, loss 0.685405, t print 20.245s, t batch 1.012s
train Ep 37, Sp 5760, loss 0.695388, t print 11.451s, t batch 0.573s
train Ep 37, Sp 5920, loss 0.66989, t print 11.042s, t batch 0.552s
train Ep 37, Sp 6080, loss 0.66677, t print 20.006s, t batch 1.0s
train Ep 37, Sp 6240, loss 0.670861, t print 11.794s, t batch 0.59s
train Ep 37, Sp 6400, loss 0.700327, t print 11.155s, t batch 0.558s
train Ep 37, Sp 6560, loss 0.659934, t print 18.79s, t batch 0.939s
train Ep 37, Sp 6720, loss 0.668797, t print 12.951s, t batch 0.648s
train Ep 37, Sp 6880, loss 0.677549, t print 11.023s, t batch 0.551s
train Ep 37, Sp 7040, loss 0.678199, t print 17.302s, t batch 0.865s
train Ep 37, Sp 7200, loss 0.685938, t print 14.613s, t batch 0.731s
train Ep 37, Sp 7360, loss 0.677766, t print 11.144s, t batch 0.557s
train Ep 37, Sp 7520, loss 0.661094, t print 15.658s, t batch 0.783s
train Ep 37, Sp 7680, loss 0.650342, t print 16.19s, t batch 0.809s
train Ep 37, Sp 7840, loss 0.680023, t print 11.395s, t batch 0.57s
train Ep 37, Sp 8000, loss 0.69171, t print 13.93s, t batch 0.697s
train Ep 37, Sp 8160, loss 0.671362, t print 18.478s, t batch 0.924s
train Ep 37, Sp 8320, loss 0.684774, t print 11.532s, t batch 0.577s
train Ep 37, Sp 8480, loss 0.676663, t print 11.872s, t batch 0.594s
train Ep 37, Sp 8640, loss 0.705063, t print 21.213s, t batch 1.061s
train Ep 37, Sp 8800, loss 0.643916, t print 11.409s, t batch 0.57s
train Ep 37, Sp 8960, loss 0.669325, t print 11.488s, t batch 0.574s
train Ep 37, Sp 9120, loss 0.698379, t print 21.315s, t batch 1.066s
train Ep 37, Sp 9280, loss 0.6858, t print 11.363s, t batch 0.568s
train Ep 37, Sp 9440, loss 0.69032, t print 11.192s, t batch 0.56s
train Ep 37, Sp 9600, loss 0.694927, t print 20.664s, t batch 1.033s
train Ep 37, Sp 9760, loss 0.689627, t print 11.141s, t batch 0.557s
train Ep 37, Sp 9920, loss 0.693416, t print 11.166s, t batch 0.558s
train Ep 37, Sp 10080, loss 0.676731, t print 20.807s, t batch 1.04s
train Ep 37, Sp 10240, loss 0.717748, t print 11.408s, t batch 0.57s
Start looping batches...
validate Ep 37, Sp 160, loss 0.684253, t print 0.99s, t batch 0.049s
validate Ep 37, Sp 320, loss 0.702306, t print 854.831s, t batch 42.742s
validate Ep 37, Sp 480, loss 0.681005, t print 11.699s, t batch 0.585s
validate Ep 37, Sp 640, loss 0.697372, t print 11.013s, t batch 0.551s
validate Ep 37, Sp 800, loss 0.682925, t print 20.998s, t batch 1.05s
validate Ep 37, Sp 960, loss 0.711577, t print 10.927s, t batch 0.546s
validate Ep 37, Sp 1120, loss 0.725237, t print 10.929s, t batch 0.546s
validate Ep 37, Sp 1280, loss 0.682556, t print 20.919s, t batch 1.046s
validate Ep 37, Sp 1440, loss 0.707456, t print 11.026s, t batch 0.551s
validate Ep 37, Sp 1600, loss 0.686588, t print 10.786s, t batch 0.539s
validate Ep 37, Sp 1760, loss 0.719644, t print 20.872s, t batch 1.044s
validate Ep 37, Sp 1920, loss 0.718254, t print 10.927s, t batch 0.546s
validate Ep 37, Sp 2080, loss 0.695739, t print 10.848s, t batch 0.542s
validate Ep 37, Sp 2240, loss 0.706046, t print 20.493s, t batch 1.025s
validate Ep 37, Sp 2400, loss 0.712665, t print 10.921s, t batch 0.546s
  Epoch 37, Average Epoch loss = 0.6792671045771351
  Epoch 37, nr_of_updates 49248
current learning rate: 0.001
  Epoch 37, time total 1952.9391255378723s
  Epoch 37, time UNet: 123.55865812301636s
  Epoch 37, time metrics: 0.12550902366638184s
  Epoch 37, time saving files: 0.0008904933929443359s
2023-12-01 02:20:50.048335
Start looping batches...
train Ep 38, Sp 160, loss 0.736601, t print 1.832s, t batch 0.092s
train Ep 38, Sp 320, loss 0.642435, t print 11.007s, t batch 0.55s
train Ep 38, Sp 480, loss 0.634792, t print 12.655s, t batch 0.633s
train Ep 38, Sp 640, loss 0.73853, t print 11.492s, t batch 0.575s
train Ep 38, Sp 800, loss 0.696279, t print 20.209s, t batch 1.01s
train Ep 38, Sp 960, loss 0.699821, t print 11.556s, t batch 0.578s
train Ep 38, Sp 1120, loss 0.695278, t print 11.99s, t batch 0.599s
train Ep 38, Sp 1280, loss 0.66276, t print 18.663s, t batch 0.933s
train Ep 38, Sp 1440, loss 0.667506, t print 12.086s, t batch 0.604s
train Ep 38, Sp 1600, loss 0.678444, t print 12.926s, t batch 0.646s
train Ep 38, Sp 1760, loss 0.668418, t print 17.295s, t batch 0.865s
train Ep 38, Sp 1920, loss 0.649803, t print 12.142s, t batch 0.607s
train Ep 38, Sp 2080, loss 0.691752, t print 14.481s, t batch 0.724s
train Ep 38, Sp 2240, loss 0.665279, t print 15.952s, t batch 0.798s
train Ep 38, Sp 2400, loss 0.728148, t print 11.527s, t batch 0.576s
train Ep 38, Sp 2560, loss 0.684945, t print 15.823s, t batch 0.791s
train Ep 38, Sp 2720, loss 0.652353, t print 14.655s, t batch 0.733s
train Ep 38, Sp 2880, loss 0.66709, t print 11.144s, t batch 0.557s
train Ep 38, Sp 3040, loss 0.693325, t print 17.418s, t batch 0.871s
train Ep 38, Sp 3200, loss 0.672831, t print 13.785s, t batch 0.689s
train Ep 38, Sp 3360, loss 0.683091, t print 10.891s, t batch 0.545s
train Ep 38, Sp 3520, loss 0.707501, t print 18.498s, t batch 0.925s
train Ep 38, Sp 3680, loss 0.690334, t print 12.514s, t batch 0.626s
train Ep 38, Sp 3840, loss 0.679473, t print 10.906s, t batch 0.545s
train Ep 38, Sp 4000, loss 0.669498, t print 20.032s, t batch 1.002s
train Ep 38, Sp 4160, loss 0.654301, t print 11.49s, t batch 0.574s
train Ep 38, Sp 4320, loss 0.687402, t print 11.157s, t batch 0.558s
train Ep 38, Sp 4480, loss 0.683451, t print 20.857s, t batch 1.043s
train Ep 38, Sp 4640, loss 0.658869, t print 11.13s, t batch 0.556s
train Ep 38, Sp 4800, loss 0.644801, t print 11.229s, t batch 0.561s
train Ep 38, Sp 4960, loss 0.692004, t print 20.72s, t batch 1.036s
train Ep 38, Sp 5120, loss 0.68336, t print 11.162s, t batch 0.558s
train Ep 38, Sp 5280, loss 0.659309, t print 10.969s, t batch 0.548s
train Ep 38, Sp 5440, loss 0.71691, t print 20.538s, t batch 1.027s
train Ep 38, Sp 5600, loss 0.666106, t print 11.327s, t batch 0.566s
train Ep 38, Sp 5760, loss 0.684162, t print 11.302s, t batch 0.565s
train Ep 38, Sp 5920, loss 0.65386, t print 20.348s, t batch 1.017s
train Ep 38, Sp 6080, loss 0.668214, t print 11.675s, t batch 0.584s
train Ep 38, Sp 6240, loss 0.702948, t print 11.226s, t batch 0.561s
train Ep 38, Sp 6400, loss 0.675695, t print 20.349s, t batch 1.017s
train Ep 38, Sp 6560, loss 0.70287, t print 11.914s, t batch 0.596s
train Ep 38, Sp 6720, loss 0.706778, t print 11.01s, t batch 0.55s
train Ep 38, Sp 6880, loss 0.697694, t print 19.834s, t batch 0.992s
train Ep 38, Sp 7040, loss 0.69519, t print 12.067s, t batch 0.603s
train Ep 38, Sp 7200, loss 0.680926, t print 11.152s, t batch 0.558s
train Ep 38, Sp 7360, loss 0.679021, t print 18.683s, t batch 0.934s
train Ep 38, Sp 7520, loss 0.674003, t print 13.007s, t batch 0.65s
train Ep 38, Sp 7680, loss 0.722899, t print 10.98s, t batch 0.549s
train Ep 38, Sp 7840, loss 0.70248, t print 16.705s, t batch 0.835s
train Ep 38, Sp 8000, loss 0.66216, t print 14.522s, t batch 0.726s
train Ep 38, Sp 8160, loss 0.682025, t print 10.996s, t batch 0.55s
train Ep 38, Sp 8320, loss 0.695628, t print 15.726s, t batch 0.786s
train Ep 38, Sp 8480, loss 0.699711, t print 15.776s, t batch 0.789s
train Ep 38, Sp 8640, loss 0.667737, t print 10.986s, t batch 0.549s
train Ep 38, Sp 8800, loss 0.68166, t print 14.296s, t batch 0.715s
train Ep 38, Sp 8960, loss 0.697579, t print 16.826s, t batch 0.841s
train Ep 38, Sp 9120, loss 0.68623, t print 11.017s, t batch 0.551s
train Ep 38, Sp 9280, loss 0.679411, t print 14.298s, t batch 0.715s
train Ep 38, Sp 9440, loss 0.652299, t print 17.281s, t batch 0.864s
train Ep 38, Sp 9600, loss 0.678842, t print 10.975s, t batch 0.549s
train Ep 38, Sp 9760, loss 0.689801, t print 13.922s, t batch 0.696s
train Ep 38, Sp 9920, loss 0.689933, t print 17.335s, t batch 0.867s
train Ep 38, Sp 10080, loss 0.660176, t print 10.968s, t batch 0.548s
train Ep 38, Sp 10240, loss 0.650326, t print 14.652s, t batch 0.733s
Start looping batches...
validate Ep 38, Sp 160, loss 0.693746, t print 1.024s, t batch 0.051s
validate Ep 38, Sp 320, loss 0.694007, t print 11.514s, t batch 0.576s
validate Ep 38, Sp 480, loss 0.687316, t print 11.873s, t batch 0.594s
validate Ep 38, Sp 640, loss 0.674788, t print 11.063s, t batch 0.553s
validate Ep 38, Sp 800, loss 0.685501, t print 19.653s, t batch 0.983s
validate Ep 38, Sp 960, loss 0.687014, t print 11.653s, t batch 0.583s
validate Ep 38, Sp 1120, loss 0.701021, t print 10.967s, t batch 0.548s
validate Ep 38, Sp 1280, loss 0.703679, t print 18.989s, t batch 0.949s
validate Ep 38, Sp 1440, loss 0.705092, t print 12.9s, t batch 0.645s
validate Ep 38, Sp 1600, loss 0.702412, t print 10.692s, t batch 0.535s
validate Ep 38, Sp 1760, loss 0.691887, t print 16.528s, t batch 0.826s
validate Ep 38, Sp 1920, loss 0.669582, t print 14.336s, t batch 0.717s
validate Ep 38, Sp 2080, loss 0.694457, t print 10.615s, t batch 0.531s
validate Ep 38, Sp 2240, loss 0.704297, t print 14.863s, t batch 0.743s
validate Ep 38, Sp 2400, loss 0.694233, t print 16.24s, t batch 0.812s
  Epoch 38, Average Epoch loss = 0.681292142443083
  Epoch 38, nr_of_updates 50544
current learning rate: 0.001
  Epoch 38, time total 1102.1082303524017s
  Epoch 38, time UNet: 124.17575573921204s
  Epoch 38, time metrics: 0.13130617141723633s
  Epoch 38, time saving files: 0.00010395050048828125s
2023-12-01 02:39:12.163563
Start looping batches...
train Ep 39, Sp 160, loss 0.677466, t print 1.61s, t batch 0.08s
train Ep 39, Sp 320, loss 0.683393, t print 10.809s, t batch 0.54s
train Ep 39, Sp 480, loss 0.653365, t print 13.092s, t batch 0.655s
train Ep 39, Sp 640, loss 0.715373, t print 11.703s, t batch 0.585s
train Ep 39, Sp 800, loss 0.670652, t print 20.17s, t batch 1.009s
train Ep 39, Sp 960, loss 0.665186, t print 12.757s, t batch 0.638s
train Ep 39, Sp 1120, loss 0.637064, t print 11.54s, t batch 0.577s
train Ep 39, Sp 1280, loss 0.681187, t print 18.213s, t batch 0.911s
train Ep 39, Sp 1440, loss 0.658318, t print 15.29s, t batch 0.765s
train Ep 39, Sp 1600, loss 0.69019, t print 11.748s, t batch 0.587s
train Ep 39, Sp 1760, loss 0.673858, t print 15.136s, t batch 0.757s
train Ep 39, Sp 1920, loss 0.712943, t print 18.136s, t batch 0.907s
train Ep 39, Sp 2080, loss 0.693891, t print 11.525s, t batch 0.576s
train Ep 39, Sp 2240, loss 0.641484, t print 11.671s, t batch 0.584s
train Ep 39, Sp 2400, loss 0.675129, t print 21.328s, t batch 1.066s
train Ep 39, Sp 2560, loss 0.673003, t print 11.315s, t batch 0.566s
train Ep 39, Sp 2720, loss 0.65799, t print 11.579s, t batch 0.579s
train Ep 39, Sp 2880, loss 0.67542, t print 21.399s, t batch 1.07s
train Ep 39, Sp 3040, loss 0.667517, t print 11.472s, t batch 0.574s
train Ep 39, Sp 3200, loss 0.69535, t print 11.374s, t batch 0.569s
train Ep 39, Sp 3360, loss 0.65109, t print 21.022s, t batch 1.051s
train Ep 39, Sp 3520, loss 0.687985, t print 11.299s, t batch 0.565s
train Ep 39, Sp 3680, loss 0.687649, t print 11.225s, t batch 0.561s
train Ep 39, Sp 3840, loss 0.68012, t print 20.815s, t batch 1.041s
train Ep 39, Sp 4000, loss 0.685712, t print 11.322s, t batch 0.566s
train Ep 39, Sp 4160, loss 0.670533, t print 11.301s, t batch 0.565s
train Ep 39, Sp 4320, loss 0.6802, t print 20.889s, t batch 1.044s
train Ep 39, Sp 4480, loss 0.671639, t print 11.177s, t batch 0.559s
train Ep 39, Sp 4640, loss 0.713936, t print 11.289s, t batch 0.564s
train Ep 39, Sp 4800, loss 0.67841, t print 21.091s, t batch 1.055s
train Ep 39, Sp 4960, loss 0.671075, t print 11.254s, t batch 0.563s
train Ep 39, Sp 5120, loss 0.689267, t print 11.322s, t batch 0.566s
train Ep 39, Sp 5280, loss 0.648004, t print 20.857s, t batch 1.043s
train Ep 39, Sp 5440, loss 0.654009, t print 11.216s, t batch 0.561s
train Ep 39, Sp 5600, loss 0.696698, t print 11.203s, t batch 0.56s
train Ep 39, Sp 5760, loss 0.708354, t print 21.103s, t batch 1.055s
train Ep 39, Sp 5920, loss 0.684097, t print 11.295s, t batch 0.565s
train Ep 39, Sp 6080, loss 0.684527, t print 11.138s, t batch 0.557s
train Ep 39, Sp 6240, loss 0.71589, t print 20.924s, t batch 1.046s
train Ep 39, Sp 6400, loss 0.668424, t print 11.262s, t batch 0.563s
train Ep 39, Sp 6560, loss 0.705928, t print 11.177s, t batch 0.559s
train Ep 39, Sp 6720, loss 0.690355, t print 20.86s, t batch 1.043s
train Ep 39, Sp 6880, loss 0.717054, t print 11.257s, t batch 0.563s
train Ep 39, Sp 7040, loss 0.654244, t print 11.278s, t batch 0.564s
train Ep 39, Sp 7200, loss 0.671772, t print 20.972s, t batch 1.049s
train Ep 39, Sp 7360, loss 0.660506, t print 11.183s, t batch 0.559s
train Ep 39, Sp 7520, loss 0.679058, t print 11.15s, t batch 0.557s
train Ep 39, Sp 7680, loss 0.695504, t print 21.054s, t batch 1.053s
train Ep 39, Sp 7840, loss 0.661088, t print 11.198s, t batch 0.56s
train Ep 39, Sp 8000, loss 0.664168, t print 11.327s, t batch 0.566s
train Ep 39, Sp 8160, loss 0.683034, t print 20.856s, t batch 1.043s
train Ep 39, Sp 8320, loss 0.651034, t print 11.179s, t batch 0.559s
train Ep 39, Sp 8480, loss 0.712482, t print 11.227s, t batch 0.561s
train Ep 39, Sp 8640, loss 0.694658, t print 20.872s, t batch 1.044s
train Ep 39, Sp 8800, loss 0.683466, t print 11.164s, t batch 0.558s
train Ep 39, Sp 8960, loss 0.677351, t print 11.116s, t batch 0.556s
train Ep 39, Sp 9120, loss 0.712328, t print 20.72s, t batch 1.036s
train Ep 39, Sp 9280, loss 0.700919, t print 11.159s, t batch 0.558s
train Ep 39, Sp 9440, loss 0.663527, t print 11.023s, t batch 0.551s
train Ep 39, Sp 9600, loss 0.682129, t print 20.061s, t batch 1.003s
train Ep 39, Sp 9760, loss 0.698406, t print 10.856s, t batch 0.543s
train Ep 39, Sp 9920, loss 0.694824, t print 10.972s, t batch 0.549s
train Ep 39, Sp 10080, loss 0.647964, t print 20.23s, t batch 1.012s
train Ep 39, Sp 10240, loss 0.670627, t print 11.033s, t batch 0.552s
Start looping batches...
validate Ep 39, Sp 160, loss 0.710041, t print 1.029s, t batch 0.051s
validate Ep 39, Sp 320, loss 0.672044, t print 11.69s, t batch 0.584s
validate Ep 39, Sp 480, loss 0.666501, t print 11.782s, t batch 0.589s
validate Ep 39, Sp 640, loss 0.720553, t print 11.963s, t batch 0.598s
validate Ep 39, Sp 800, loss 0.70806, t print 20.082s, t batch 1.004s
validate Ep 39, Sp 960, loss 0.695479, t print 10.907s, t batch 0.545s
validate Ep 39, Sp 1120, loss 0.707022, t print 10.965s, t batch 0.548s
validate Ep 39, Sp 1280, loss 0.700033, t print 20.771s, t batch 1.039s
validate Ep 39, Sp 1440, loss 0.704041, t print 10.853s, t batch 0.543s
validate Ep 39, Sp 1600, loss 0.654032, t print 10.843s, t batch 0.542s
validate Ep 39, Sp 1760, loss 0.693474, t print 20.583s, t batch 1.029s
validate Ep 39, Sp 1920, loss 0.682994, t print 10.725s, t batch 0.536s
validate Ep 39, Sp 2080, loss 0.678306, t print 10.837s, t batch 0.542s
validate Ep 39, Sp 2240, loss 0.705272, t print 20.53s, t batch 1.027s
validate Ep 39, Sp 2400, loss 0.683594, t print 10.866s, t batch 0.543s
  Epoch 39, Average Epoch loss = 0.679344286153346
  Epoch 39, nr_of_updates 51840
current learning rate: 0.001
  Saving weights...
  Epoch 39, time total 1115.5309765338898s
  Epoch 39, time UNet: 122.18448162078857s
  Epoch 39, time metrics: 0.1253974437713623s
  Epoch 39, time saving files: 0.6039226055145264s
2023-12-01 02:57:47.702301
Start looping batches...
train Ep 40, Sp 160, loss 0.687993, t print 1.643s, t batch 0.082s
train Ep 40, Sp 320, loss 0.666722, t print 11.33s, t batch 0.566s
train Ep 40, Sp 480, loss 0.676553, t print 12.814s, t batch 0.641s
train Ep 40, Sp 640, loss 0.643073, t print 12.132s, t batch 0.607s
train Ep 40, Sp 800, loss 0.70062, t print 21.021s, t batch 1.051s
train Ep 40, Sp 960, loss 0.704754, t print 11.384s, t batch 0.569s
train Ep 40, Sp 1120, loss 0.694152, t print 11.292s, t batch 0.565s
train Ep 40, Sp 1280, loss 0.64645, t print 21.089s, t batch 1.054s
train Ep 40, Sp 1440, loss 0.657343, t print 11.437s, t batch 0.572s
train Ep 40, Sp 1600, loss 0.69319, t print 11.211s, t batch 0.561s
train Ep 40, Sp 1760, loss 0.667521, t print 21.096s, t batch 1.055s
train Ep 40, Sp 1920, loss 0.693697, t print 10.849s, t batch 0.542s
train Ep 40, Sp 2080, loss 0.662555, t print 11.539s, t batch 0.577s
train Ep 40, Sp 2240, loss 0.684066, t print 20.654s, t batch 1.033s
train Ep 40, Sp 2400, loss 0.666796, t print 10.798s, t batch 0.54s
train Ep 40, Sp 2560, loss 0.652636, t print 10.903s, t batch 0.545s
train Ep 40, Sp 2720, loss 0.709926, t print 20.132s, t batch 1.007s
train Ep 40, Sp 2880, loss 0.719103, t print 10.727s, t batch 0.536s
train Ep 40, Sp 3040, loss 0.653681, t print 11.022s, t batch 0.551s
train Ep 40, Sp 3200, loss 0.687143, t print 20.256s, t batch 1.013s
train Ep 40, Sp 3360, loss 0.671122, t print 11.14s, t batch 0.557s
train Ep 40, Sp 3520, loss 0.662724, t print 11.003s, t batch 0.55s
train Ep 40, Sp 3680, loss 0.689295, t print 20.65s, t batch 1.032s
train Ep 40, Sp 3840, loss 0.66161, t print 11.132s, t batch 0.557s
train Ep 40, Sp 4000, loss 0.702477, t print 11.153s, t batch 0.558s
train Ep 40, Sp 4160, loss 0.660017, t print 20.796s, t batch 1.04s
train Ep 40, Sp 4320, loss 0.670513, t print 11.34s, t batch 0.567s
train Ep 40, Sp 4480, loss 0.674892, t print 11.257s, t batch 0.563s
train Ep 40, Sp 4640, loss 0.680769, t print 20.655s, t batch 1.033s
train Ep 40, Sp 4800, loss 0.716724, t print 11.043s, t batch 0.552s
train Ep 40, Sp 4960, loss 0.7116, t print 11.038s, t batch 0.552s
train Ep 40, Sp 5120, loss 0.682694, t print 20.476s, t batch 1.024s
train Ep 40, Sp 5280, loss 0.683958, t print 10.982s, t batch 0.549s
train Ep 40, Sp 5440, loss 0.679873, t print 11.082s, t batch 0.554s
train Ep 40, Sp 5600, loss 0.664313, t print 20.723s, t batch 1.036s
train Ep 40, Sp 5760, loss 0.704323, t print 11.097s, t batch 0.555s
train Ep 40, Sp 5920, loss 0.666441, t print 10.905s, t batch 0.545s
train Ep 40, Sp 6080, loss 0.668695, t print 20.617s, t batch 1.031s
train Ep 40, Sp 6240, loss 0.678869, t print 11.025s, t batch 0.551s
train Ep 40, Sp 6400, loss 0.669363, t print 10.97s, t batch 0.548s
train Ep 40, Sp 6560, loss 0.647371, t print 20.559s, t batch 1.028s
train Ep 40, Sp 6720, loss 0.690105, t print 11.015s, t batch 0.551s
train Ep 40, Sp 6880, loss 0.668691, t print 11.081s, t batch 0.554s
train Ep 40, Sp 7040, loss 0.66186, t print 20.54s, t batch 1.027s
train Ep 40, Sp 7200, loss 0.705773, t print 10.952s, t batch 0.548s
train Ep 40, Sp 7360, loss 0.663969, t print 11.037s, t batch 0.552s
train Ep 40, Sp 7520, loss 0.631475, t print 20.499s, t batch 1.025s
train Ep 40, Sp 7680, loss 0.667547, t print 10.983s, t batch 0.549s
train Ep 40, Sp 7840, loss 0.685744, t print 11.075s, t batch 0.554s
train Ep 40, Sp 8000, loss 0.670941, t print 20.242s, t batch 1.012s
train Ep 40, Sp 8160, loss 0.727855, t print 10.932s, t batch 0.547s
train Ep 40, Sp 8320, loss 0.702513, t print 11.145s, t batch 0.557s
train Ep 40, Sp 8480, loss 0.644555, t print 19.934s, t batch 0.997s
train Ep 40, Sp 8640, loss 0.709627, t print 10.959s, t batch 0.548s
train Ep 40, Sp 8800, loss 0.641664, t print 10.866s, t batch 0.543s
train Ep 40, Sp 8960, loss 0.656509, t print 20.165s, t batch 1.008s
train Ep 40, Sp 9120, loss 0.685086, t print 10.787s, t batch 0.539s
train Ep 40, Sp 9280, loss 0.644828, t print 10.603s, t batch 0.53s
train Ep 40, Sp 9440, loss 0.68434, t print 19.894s, t batch 0.995s
train Ep 40, Sp 9600, loss 0.649315, t print 10.784s, t batch 0.539s
train Ep 40, Sp 9760, loss 0.647233, t print 10.709s, t batch 0.535s
train Ep 40, Sp 9920, loss 0.730486, t print 19.961s, t batch 0.998s
train Ep 40, Sp 10080, loss 0.669738, t print 10.717s, t batch 0.536s
train Ep 40, Sp 10240, loss 0.666734, t print 10.837s, t batch 0.542s
Start looping batches...
validate Ep 40, Sp 160, loss 0.677594, t print 1.089s, t batch 0.054s
validate Ep 40, Sp 320, loss 0.707193, t print 11.89s, t batch 0.594s
validate Ep 40, Sp 480, loss 0.693185, t print 12.445s, t batch 0.622s
validate Ep 40, Sp 640, loss 0.715354, t print 11.25s, t batch 0.563s
validate Ep 40, Sp 800, loss 0.695037, t print 20.657s, t batch 1.033s
validate Ep 40, Sp 960, loss 0.696558, t print 10.806s, t batch 0.54s
validate Ep 40, Sp 1120, loss 0.691194, t print 10.661s, t batch 0.533s
validate Ep 40, Sp 1280, loss 0.648257, t print 20.307s, t batch 1.015s
validate Ep 40, Sp 1440, loss 0.67781, t print 10.48s, t batch 0.524s
validate Ep 40, Sp 1600, loss 0.717726, t print 10.606s, t batch 0.53s
validate Ep 40, Sp 1760, loss 0.660961, t print 19.986s, t batch 0.999s
validate Ep 40, Sp 1920, loss 0.652179, t print 10.981s, t batch 0.549s
validate Ep 40, Sp 2080, loss 0.657488, t print 10.563s, t batch 0.528s
validate Ep 40, Sp 2240, loss 0.672189, t print 19.918s, t batch 0.996s
validate Ep 40, Sp 2400, loss 0.685635, t print 10.737s, t batch 0.537s
  Epoch 40, Average Epoch loss = 0.6769909307268667
  Epoch 40, nr_of_updates 53136
current learning rate: 0.001
  Epoch 40, time total 1093.4968791007996s
  Epoch 40, time UNet: 122.62053489685059s
  Epoch 40, time metrics: 0.13279509544372559s
  Epoch 40, time saving files: 0.00011277198791503906s
2023-12-01 03:16:01.207063
Start looping batches...
train Ep 41, Sp 160, loss 0.705352, t print 1.617s, t batch 0.081s
train Ep 41, Sp 320, loss 0.65253, t print 11.311s, t batch 0.566s
train Ep 41, Sp 480, loss 0.637345, t print 12.652s, t batch 0.633s
train Ep 41, Sp 640, loss 0.728046, t print 11.993s, t batch 0.6s
train Ep 41, Sp 800, loss 0.685276, t print 19.993s, t batch 1.0s
train Ep 41, Sp 960, loss 0.693863, t print 13.532s, t batch 0.677s
train Ep 41, Sp 1120, loss 0.666858, t print 11.454s, t batch 0.573s
train Ep 41, Sp 1280, loss 0.682444, t print 17.981s, t batch 0.899s
train Ep 41, Sp 1440, loss 0.662117, t print 15.189s, t batch 0.759s
train Ep 41, Sp 1600, loss 0.659054, t print 11.479s, t batch 0.574s
train Ep 41, Sp 1760, loss 0.68367, t print 16.238s, t batch 0.812s
train Ep 41, Sp 1920, loss 0.675265, t print 16.35s, t batch 0.817s
train Ep 41, Sp 2080, loss 0.685092, t print 11.243s, t batch 0.562s
train Ep 41, Sp 2240, loss 0.665371, t print 14.963s, t batch 0.748s
train Ep 41, Sp 2400, loss 0.688393, t print 17.853s, t batch 0.893s
train Ep 41, Sp 2560, loss 0.684928, t print 11.318s, t batch 0.566s
train Ep 41, Sp 2720, loss 0.669956, t print 13.548s, t batch 0.677s
train Ep 41, Sp 2880, loss 0.664953, t print 18.609s, t batch 0.93s
train Ep 41, Sp 3040, loss 0.685112, t print 11.175s, t batch 0.559s
train Ep 41, Sp 3200, loss 0.671984, t print 12.463s, t batch 0.623s
train Ep 41, Sp 3360, loss 0.68443, t print 19.637s, t batch 0.982s
train Ep 41, Sp 3520, loss 0.667837, t print 11.474s, t batch 0.574s
train Ep 41, Sp 3680, loss 0.652822, t print 11.305s, t batch 0.565s
train Ep 41, Sp 3840, loss 0.657421, t print 20.567s, t batch 1.028s
train Ep 41, Sp 4000, loss 0.705744, t print 11.493s, t batch 0.575s
train Ep 41, Sp 4160, loss 0.712949, t print 11.133s, t batch 0.557s
train Ep 41, Sp 4320, loss 0.653565, t print 20.703s, t batch 1.035s
train Ep 41, Sp 4480, loss 0.662066, t print 11.577s, t batch 0.579s
train Ep 41, Sp 4640, loss 0.689578, t print 11.158s, t batch 0.558s
train Ep 41, Sp 4800, loss 0.687322, t print 20.506s, t batch 1.025s
train Ep 41, Sp 4960, loss 0.678685, t print 11.742s, t batch 0.587s
train Ep 41, Sp 5120, loss 0.656181, t print 11.179s, t batch 0.559s
train Ep 41, Sp 5280, loss 0.67746, t print 19.868s, t batch 0.993s
train Ep 41, Sp 5440, loss 0.694413, t print 12.351s, t batch 0.618s
train Ep 41, Sp 5600, loss 0.6927, t print 11.221s, t batch 0.561s
train Ep 41, Sp 5760, loss 0.674584, t print 19.064s, t batch 0.953s
train Ep 41, Sp 5920, loss 0.69021, t print 12.9s, t batch 0.645s
train Ep 41, Sp 6080, loss 0.644663, t print 11.036s, t batch 0.552s
train Ep 41, Sp 6240, loss 0.671475, t print 18.21s, t batch 0.911s
train Ep 41, Sp 6400, loss 0.658443, t print 13.661s, t batch 0.683s
train Ep 41, Sp 6560, loss 0.698817, t print 11.047s, t batch 0.552s
train Ep 41, Sp 6720, loss 0.68903, t print 16.963s, t batch 0.848s
train Ep 41, Sp 6880, loss 0.68331, t print 14.931s, t batch 0.747s
train Ep 41, Sp 7040, loss 0.679835, t print 11.293s, t batch 0.565s
train Ep 41, Sp 7200, loss 0.688328, t print 15.485s, t batch 0.774s
train Ep 41, Sp 7360, loss 0.671196, t print 16.236s, t batch 0.812s
train Ep 41, Sp 7520, loss 0.664094, t print 10.925s, t batch 0.546s
train Ep 41, Sp 7680, loss 0.68674, t print 13.988s, t batch 0.699s
train Ep 41, Sp 7840, loss 0.718764, t print 17.614s, t batch 0.881s
train Ep 41, Sp 8000, loss 0.711699, t print 10.981s, t batch 0.549s
train Ep 41, Sp 8160, loss 0.690673, t print 12.352s, t batch 0.618s
train Ep 41, Sp 8320, loss 0.672103, t print 18.712s, t batch 0.936s
train Ep 41, Sp 8480, loss 0.66497, t print 11.077s, t batch 0.554s
train Ep 41, Sp 8640, loss 0.657676, t print 11.456s, t batch 0.573s
train Ep 41, Sp 8800, loss 0.688675, t print 20.067s, t batch 1.003s
train Ep 41, Sp 8960, loss 0.655021, t print 10.99s, t batch 0.55s
train Ep 41, Sp 9120, loss 0.688537, t print 11.059s, t batch 0.553s
train Ep 41, Sp 9280, loss 0.682472, t print 20.397s, t batch 1.02s
train Ep 41, Sp 9440, loss 0.66098, t print 10.956s, t batch 0.548s
train Ep 41, Sp 9600, loss 0.668564, t print 11.06s, t batch 0.553s
train Ep 41, Sp 9760, loss 0.74955, t print 20.61s, t batch 1.031s
train Ep 41, Sp 9920, loss 0.682282, t print 11.012s, t batch 0.551s
train Ep 41, Sp 10080, loss 0.703136, t print 11.183s, t batch 0.559s
train Ep 41, Sp 10240, loss 0.640531, t print 20.89s, t batch 1.044s
Start looping batches...
validate Ep 41, Sp 160, loss 0.674833, t print 1.066s, t batch 0.053s
validate Ep 41, Sp 320, loss 0.695292, t print 1721.75s, t batch 86.088s
validate Ep 41, Sp 480, loss 0.679344, t print 11.182s, t batch 0.559s
validate Ep 41, Sp 640, loss 0.694389, t print 11.111s, t batch 0.556s
validate Ep 41, Sp 800, loss 0.691652, t print 20.585s, t batch 1.029s
validate Ep 41, Sp 960, loss 0.728156, t print 10.823s, t batch 0.541s
validate Ep 41, Sp 1120, loss 0.671713, t print 11.136s, t batch 0.557s
validate Ep 41, Sp 1280, loss 0.701676, t print 20.899s, t batch 1.045s
validate Ep 41, Sp 1440, loss 0.722678, t print 11.038s, t batch 0.552s
validate Ep 41, Sp 1600, loss 0.703563, t print 10.459s, t batch 0.523s
validate Ep 41, Sp 1760, loss 0.681424, t print 20.086s, t batch 1.004s
validate Ep 41, Sp 1920, loss 0.67545, t print 11.046s, t batch 0.552s
validate Ep 41, Sp 2080, loss 0.696208, t print 10.875s, t batch 0.544s
validate Ep 41, Sp 2240, loss 0.682656, t print 18.841s, t batch 0.942s
validate Ep 41, Sp 2400, loss 0.700441, t print 12.98s, t batch 0.649s
  Epoch 41, Average Epoch loss = 0.6790338572068715
  Epoch 41, nr_of_updates 54432
current learning rate: 0.001
  Epoch 41, time total 2818.9694361686707s
  Epoch 41, time UNet: 124.30805802345276s
  Epoch 41, time metrics: 0.13144636154174805s
  Epoch 41, time saving files: 0.0002570152282714844s
2023-12-01 04:03:00.185957
Start looping batches...
train Ep 42, Sp 160, loss 0.629594, t print 1.739s, t batch 0.087s
train Ep 42, Sp 320, loss 0.693292, t print 11.431s, t batch 0.572s
train Ep 42, Sp 480, loss 0.684018, t print 13.518s, t batch 0.676s
train Ep 42, Sp 640, loss 0.687529, t print 11.44s, t batch 0.572s
train Ep 42, Sp 800, loss 0.706469, t print 19.768s, t batch 0.988s
train Ep 42, Sp 960, loss 0.65398, t print 11.86s, t batch 0.593s
train Ep 42, Sp 1120, loss 0.655085, t print 11.95s, t batch 0.598s
train Ep 42, Sp 1280, loss 0.655681, t print 20.824s, t batch 1.041s
train Ep 42, Sp 1440, loss 0.667654, t print 11.621s, t batch 0.581s
train Ep 42, Sp 1600, loss 0.689123, t print 11.457s, t batch 0.573s
train Ep 42, Sp 1760, loss 0.652556, t print 21.666s, t batch 1.083s
train Ep 42, Sp 1920, loss 0.611301, t print 11.52s, t batch 0.576s
train Ep 42, Sp 2080, loss 0.695368, t print 11.279s, t batch 0.564s
train Ep 42, Sp 2240, loss 0.660769, t print 21.043s, t batch 1.052s
train Ep 42, Sp 2400, loss 0.688288, t print 11.296s, t batch 0.565s
train Ep 42, Sp 2560, loss 0.648918, t print 10.934s, t batch 0.547s
train Ep 42, Sp 2720, loss 0.665353, t print 20.9s, t batch 1.045s
train Ep 42, Sp 2880, loss 0.678994, t print 11.357s, t batch 0.568s
train Ep 42, Sp 3040, loss 0.675758, t print 11.088s, t batch 0.554s
train Ep 42, Sp 3200, loss 0.694648, t print 20.773s, t batch 1.039s
train Ep 42, Sp 3360, loss 0.642501, t print 11.17s, t batch 0.559s
train Ep 42, Sp 3520, loss 0.709684, t print 10.953s, t batch 0.548s
train Ep 42, Sp 3680, loss 0.655242, t print 20.438s, t batch 1.022s
train Ep 42, Sp 3840, loss 0.693244, t print 10.956s, t batch 0.548s
train Ep 42, Sp 4000, loss 0.683076, t print 10.962s, t batch 0.548s
train Ep 42, Sp 4160, loss 0.646331, t print 20.009s, t batch 1.0s
train Ep 42, Sp 4320, loss 0.665973, t print 10.841s, t batch 0.542s
train Ep 42, Sp 4480, loss 0.673149, t print 10.872s, t batch 0.544s
train Ep 42, Sp 4640, loss 0.705684, t print 20.257s, t batch 1.013s
train Ep 42, Sp 4800, loss 0.664961, t print 11.006s, t batch 0.55s
train Ep 42, Sp 4960, loss 0.699079, t print 10.994s, t batch 0.55s
train Ep 42, Sp 5120, loss 0.678061, t print 20.488s, t batch 1.024s
train Ep 42, Sp 5280, loss 0.671646, t print 10.979s, t batch 0.549s
train Ep 42, Sp 5440, loss 0.650044, t print 10.857s, t batch 0.543s
train Ep 42, Sp 5600, loss 0.693044, t print 20.374s, t batch 1.019s
train Ep 42, Sp 5760, loss 0.669606, t print 10.978s, t batch 0.549s
train Ep 42, Sp 5920, loss 0.679647, t print 11.029s, t batch 0.551s
train Ep 42, Sp 6080, loss 0.663026, t print 20.455s, t batch 1.023s
train Ep 42, Sp 6240, loss 0.643922, t print 10.928s, t batch 0.546s
train Ep 42, Sp 6400, loss 0.718008, t print 10.97s, t batch 0.548s
train Ep 42, Sp 6560, loss 0.654862, t print 20.329s, t batch 1.016s
train Ep 42, Sp 6720, loss 0.680335, t print 11.001s, t batch 0.55s
train Ep 42, Sp 6880, loss 0.702141, t print 11.015s, t batch 0.551s
train Ep 42, Sp 7040, loss 0.693138, t print 20.345s, t batch 1.017s
train Ep 42, Sp 7200, loss 0.662861, t print 11.264s, t batch 0.563s
train Ep 42, Sp 7360, loss 0.660688, t print 10.927s, t batch 0.546s
train Ep 42, Sp 7520, loss 0.665378, t print 20.05s, t batch 1.002s
train Ep 42, Sp 7680, loss 0.695318, t print 11.041s, t batch 0.552s
train Ep 42, Sp 7840, loss 0.697463, t print 10.919s, t batch 0.546s
train Ep 42, Sp 8000, loss 0.656048, t print 19.97s, t batch 0.998s
train Ep 42, Sp 8160, loss 0.633405, t print 11.257s, t batch 0.563s
train Ep 42, Sp 8320, loss 0.693645, t print 10.965s, t batch 0.548s
train Ep 42, Sp 8480, loss 0.711822, t print 20.52s, t batch 1.026s
train Ep 42, Sp 8640, loss 0.700406, t print 11.053s, t batch 0.553s
train Ep 42, Sp 8800, loss 0.738348, t print 10.822s, t batch 0.541s
train Ep 42, Sp 8960, loss 0.667001, t print 20.619s, t batch 1.031s
train Ep 42, Sp 9120, loss 0.689744, t print 11.045s, t batch 0.552s
train Ep 42, Sp 9280, loss 0.664694, t print 10.977s, t batch 0.549s
train Ep 42, Sp 9440, loss 0.692016, t print 20.403s, t batch 1.02s
train Ep 42, Sp 9600, loss 0.686236, t print 11.025s, t batch 0.551s
train Ep 42, Sp 9760, loss 0.661091, t print 11.106s, t batch 0.555s
train Ep 42, Sp 9920, loss 0.66732, t print 20.606s, t batch 1.03s
train Ep 42, Sp 10080, loss 0.641216, t print 11.135s, t batch 0.557s
train Ep 42, Sp 10240, loss 0.695062, t print 11.134s, t batch 0.557s
Start looping batches...
validate Ep 42, Sp 160, loss 0.706424, t print 0.99s, t batch 0.05s
validate Ep 42, Sp 320, loss 0.69482, t print 11.288s, t batch 0.564s
validate Ep 42, Sp 480, loss 0.685219, t print 13.689s, t batch 0.684s
validate Ep 42, Sp 640, loss 0.638207, t print 12.276s, t batch 0.614s
validate Ep 42, Sp 800, loss 0.686046, t print 17.214s, t batch 0.861s
validate Ep 42, Sp 960, loss 0.66276, t print 14.617s, t batch 0.731s
validate Ep 42, Sp 1120, loss 0.68991, t print 11.026s, t batch 0.551s
validate Ep 42, Sp 1280, loss 0.689662, t print 15.821s, t batch 0.791s
validate Ep 42, Sp 1440, loss 0.686642, t print 14.903s, t batch 0.745s
validate Ep 42, Sp 1600, loss 0.67309, t print 10.539s, t batch 0.527s
validate Ep 42, Sp 1760, loss 0.711722, t print 15.577s, t batch 0.779s
validate Ep 42, Sp 1920, loss 0.704268, t print 15.294s, t batch 0.765s
validate Ep 42, Sp 2080, loss 0.695255, t print 10.494s, t batch 0.525s
validate Ep 42, Sp 2240, loss 0.704735, t print 20.325s, t batch 1.016s
validate Ep 42, Sp 2400, loss 0.696285, t print 10.733s, t batch 0.537s
  Epoch 42, Average Epoch loss = 0.6751988953278388
  Epoch 42, nr_of_updates 55728
current learning rate: 0.001
  Epoch 42, time total 1099.0855822563171s
  Epoch 42, time UNet: 125.7558183670044s
  Epoch 42, time metrics: 0.12974119186401367s
  Epoch 42, time saving files: 0.0001327991485595703s
2023-12-01 04:21:19.278799
Start looping batches...
train Ep 43, Sp 160, loss 0.668318, t print 3.134s, t batch 0.157s
train Ep 43, Sp 320, loss 0.667632, t print 10.804s, t batch 0.54s
train Ep 43, Sp 480, loss 0.68611, t print 12.086s, t batch 0.604s
train Ep 43, Sp 640, loss 0.704836, t print 13.096s, t batch 0.655s
train Ep 43, Sp 800, loss 0.670857, t print 18.611s, t batch 0.931s
train Ep 43, Sp 960, loss 0.660008, t print 11.415s, t batch 0.571s
train Ep 43, Sp 1120, loss 0.688899, t print 13.934s, t batch 0.697s
train Ep 43, Sp 1280, loss 0.708424, t print 17.167s, t batch 0.858s
train Ep 43, Sp 1440, loss 0.687582, t print 11.8s, t batch 0.59s
train Ep 43, Sp 1600, loss 0.664521, t print 14.902s, t batch 0.745s
train Ep 43, Sp 1760, loss 0.646737, t print 14.882s, t batch 0.744s
train Ep 43, Sp 1920, loss 0.696808, t print 12.956s, t batch 0.648s
train Ep 43, Sp 2080, loss 0.699592, t print 16.291s, t batch 0.815s
train Ep 43, Sp 2240, loss 0.684591, t print 11.471s, t batch 0.574s
train Ep 43, Sp 2400, loss 0.675828, t print 15.181s, t batch 0.759s
train Ep 43, Sp 2560, loss 0.685416, t print 17.316s, t batch 0.866s
train Ep 43, Sp 2720, loss 0.686381, t print 11.505s, t batch 0.575s
train Ep 43, Sp 2880, loss 0.69906, t print 13.847s, t batch 0.692s
train Ep 43, Sp 3040, loss 0.689522, t print 18.716s, t batch 0.936s
train Ep 43, Sp 3200, loss 0.685337, t print 11.484s, t batch 0.574s
train Ep 43, Sp 3360, loss 0.730858, t print 11.812s, t batch 0.591s
train Ep 43, Sp 3520, loss 0.674357, t print 20.91s, t batch 1.045s
train Ep 43, Sp 3680, loss 0.693829, t print 11.34s, t batch 0.567s
train Ep 43, Sp 3840, loss 0.657418, t print 11.306s, t batch 0.565s
train Ep 43, Sp 4000, loss 0.673211, t print 21.141s, t batch 1.057s
train Ep 43, Sp 4160, loss 0.682925, t print 11.329s, t batch 0.566s
train Ep 43, Sp 4320, loss 0.660932, t print 11.213s, t batch 0.561s
train Ep 43, Sp 4480, loss 0.653552, t print 21.196s, t batch 1.06s
train Ep 43, Sp 4640, loss 0.717266, t print 11.166s, t batch 0.558s
train Ep 43, Sp 4800, loss 0.672303, t print 11.189s, t batch 0.559s
train Ep 43, Sp 4960, loss 0.67436, t print 21.155s, t batch 1.058s
train Ep 43, Sp 5120, loss 0.67106, t print 11.331s, t batch 0.567s
train Ep 43, Sp 5280, loss 0.674856, t print 10.957s, t batch 0.548s
train Ep 43, Sp 5440, loss 0.691918, t print 20.529s, t batch 1.026s
train Ep 43, Sp 5600, loss 0.69151, t print 11.091s, t batch 0.555s
train Ep 43, Sp 5760, loss 0.669817, t print 11.1s, t batch 0.555s
train Ep 43, Sp 5920, loss 0.691137, t print 21.022s, t batch 1.051s
train Ep 43, Sp 6080, loss 0.6972, t print 11.282s, t batch 0.564s
train Ep 43, Sp 6240, loss 0.682907, t print 11.313s, t batch 0.566s
train Ep 43, Sp 6400, loss 0.673573, t print 21.123s, t batch 1.056s
train Ep 43, Sp 6560, loss 0.660456, t print 11.362s, t batch 0.568s
train Ep 43, Sp 6720, loss 0.673229, t print 11.443s, t batch 0.572s
train Ep 43, Sp 6880, loss 0.635847, t print 20.814s, t batch 1.041s
train Ep 43, Sp 7040, loss 0.66975, t print 11.281s, t batch 0.564s
train Ep 43, Sp 7200, loss 0.667694, t print 11.216s, t batch 0.561s
train Ep 43, Sp 7360, loss 0.690632, t print 20.753s, t batch 1.038s
train Ep 43, Sp 7520, loss 0.673542, t print 11.32s, t batch 0.566s
train Ep 43, Sp 7680, loss 0.700636, t print 11.238s, t batch 0.562s
train Ep 43, Sp 7840, loss 0.683134, t print 20.7s, t batch 1.035s
train Ep 43, Sp 8000, loss 0.706584, t print 10.909s, t batch 0.545s
train Ep 43, Sp 8160, loss 0.662153, t print 11.192s, t batch 0.56s
train Ep 43, Sp 8320, loss 0.67075, t print 20.627s, t batch 1.031s
train Ep 43, Sp 8480, loss 0.695533, t print 11.167s, t batch 0.558s
train Ep 43, Sp 8640, loss 0.671585, t print 11.118s, t batch 0.556s
train Ep 43, Sp 8800, loss 0.679533, t print 20.607s, t batch 1.03s
train Ep 43, Sp 8960, loss 0.660736, t print 11.036s, t batch 0.552s
train Ep 43, Sp 9120, loss 0.665417, t print 10.983s, t batch 0.549s
train Ep 43, Sp 9280, loss 0.688613, t print 20.469s, t batch 1.023s
train Ep 43, Sp 9440, loss 0.679285, t print 11.091s, t batch 0.555s
train Ep 43, Sp 9600, loss 0.709151, t print 11.021s, t batch 0.551s
train Ep 43, Sp 9760, loss 0.67893, t print 20.705s, t batch 1.035s
train Ep 43, Sp 9920, loss 0.702742, t print 10.951s, t batch 0.548s
train Ep 43, Sp 10080, loss 0.688827, t print 10.958s, t batch 0.548s
train Ep 43, Sp 10240, loss 0.664609, t print 20.629s, t batch 1.031s
Start looping batches...
validate Ep 43, Sp 160, loss 0.659439, t print 1.004s, t batch 0.05s
validate Ep 43, Sp 320, loss 0.684221, t print 11.75s, t batch 0.587s
validate Ep 43, Sp 480, loss 0.681445, t print 11.414s, t batch 0.571s
validate Ep 43, Sp 640, loss 0.711227, t print 10.69s, t batch 0.535s
validate Ep 43, Sp 800, loss 0.714005, t print 20.02s, t batch 1.001s
validate Ep 43, Sp 960, loss 0.68596, t print 11.73s, t batch 0.587s
validate Ep 43, Sp 1120, loss 0.71518, t print 10.901s, t batch 0.545s
validate Ep 43, Sp 1280, loss 0.673786, t print 18.229s, t batch 0.911s
validate Ep 43, Sp 1440, loss 0.719877, t print 13.057s, t batch 0.653s
validate Ep 43, Sp 1600, loss 0.679141, t print 10.617s, t batch 0.531s
validate Ep 43, Sp 1760, loss 0.69575, t print 16.904s, t batch 0.845s
validate Ep 43, Sp 1920, loss 0.693334, t print 14.346s, t batch 0.717s
validate Ep 43, Sp 2080, loss 0.670166, t print 10.786s, t batch 0.539s
validate Ep 43, Sp 2240, loss 0.688316, t print 14.664s, t batch 0.733s
validate Ep 43, Sp 2400, loss 0.693003, t print 16.538s, t batch 0.827s
  Epoch 43, Average Epoch loss = 0.6807218940905583
  Epoch 43, nr_of_updates 57024
current learning rate: 0.001
  Epoch 43, time total 1111.89653134346s
  Epoch 43, time UNet: 124.59282994270325s
  Epoch 43, time metrics: 0.13284945487976074s
  Epoch 43, time saving files: 0.0002796649932861328s
2023-12-01 04:39:51.184242
Start looping batches...
train Ep 44, Sp 160, loss 0.687992, t print 1.597s, t batch 0.08s
train Ep 44, Sp 320, loss 0.680275, t print 11.968s, t batch 0.598s
train Ep 44, Sp 480, loss 0.695757, t print 12.619s, t batch 0.631s
train Ep 44, Sp 640, loss 0.696885, t print 11.827s, t batch 0.591s
train Ep 44, Sp 800, loss 0.64159, t print 20.918s, t batch 1.046s
train Ep 44, Sp 960, loss 0.683306, t print 11.293s, t batch 0.565s
train Ep 44, Sp 1120, loss 0.681143, t print 11.128s, t batch 0.556s
train Ep 44, Sp 1280, loss 0.696894, t print 20.886s, t batch 1.044s
train Ep 44, Sp 1440, loss 0.646795, t print 11.272s, t batch 0.564s
train Ep 44, Sp 1600, loss 0.664668, t print 11.249s, t batch 0.562s
train Ep 44, Sp 1760, loss 0.678151, t print 20.998s, t batch 1.05s
train Ep 44, Sp 1920, loss 0.675846, t print 11.026s, t batch 0.551s
train Ep 44, Sp 2080, loss 0.709805, t print 11.576s, t batch 0.579s
train Ep 44, Sp 2240, loss 0.704257, t print 19.173s, t batch 0.959s
train Ep 44, Sp 2400, loss 0.657468, t print 13.67s, t batch 0.684s
train Ep 44, Sp 2560, loss 0.709694, t print 11.277s, t batch 0.564s
train Ep 44, Sp 2720, loss 0.692388, t print 16.646s, t batch 0.832s
train Ep 44, Sp 2880, loss 0.71492, t print 15.973s, t batch 0.799s
train Ep 44, Sp 3040, loss 0.673629, t print 11.286s, t batch 0.564s
train Ep 44, Sp 3200, loss 0.654839, t print 13.849s, t batch 0.692s
train Ep 44, Sp 3360, loss 0.670049, t print 18.278s, t batch 0.914s
train Ep 44, Sp 3520, loss 0.660155, t print 11.386s, t batch 0.569s
train Ep 44, Sp 3680, loss 0.733825, t print 11.252s, t batch 0.563s
train Ep 44, Sp 3840, loss 0.692026, t print 21.176s, t batch 1.059s
train Ep 44, Sp 4000, loss 0.683137, t print 11.217s, t batch 0.561s
train Ep 44, Sp 4160, loss 0.662814, t print 11.306s, t batch 0.565s
train Ep 44, Sp 4320, loss 0.67583, t print 20.638s, t batch 1.032s
train Ep 44, Sp 4480, loss 0.692265, t print 11.308s, t batch 0.565s
train Ep 44, Sp 4640, loss 0.654806, t print 11.532s, t batch 0.577s
train Ep 44, Sp 4800, loss 0.686784, t print 20.591s, t batch 1.03s
train Ep 44, Sp 4960, loss 0.673324, t print 11.198s, t batch 0.56s
train Ep 44, Sp 5120, loss 0.648069, t print 11.646s, t batch 0.582s
train Ep 44, Sp 5280, loss 0.642089, t print 20.985s, t batch 1.049s
train Ep 44, Sp 5440, loss 0.701736, t print 11.319s, t batch 0.566s
train Ep 44, Sp 5600, loss 0.684281, t print 11.149s, t batch 0.557s
train Ep 44, Sp 5760, loss 0.695033, t print 21.066s, t batch 1.053s
train Ep 44, Sp 5920, loss 0.683668, t print 11.401s, t batch 0.57s
train Ep 44, Sp 6080, loss 0.686197, t print 11.423s, t batch 0.571s
train Ep 44, Sp 6240, loss 0.702681, t print 20.462s, t batch 1.023s
train Ep 44, Sp 6400, loss 0.675884, t print 11.163s, t batch 0.558s
train Ep 44, Sp 6560, loss 0.673683, t print 12.2s, t batch 0.61s
train Ep 44, Sp 6720, loss 0.662739, t print 20.017s, t batch 1.001s
train Ep 44, Sp 6880, loss 0.704646, t print 11.367s, t batch 0.568s
train Ep 44, Sp 7040, loss 0.696878, t print 11.948s, t batch 0.597s
train Ep 44, Sp 7200, loss 0.652477, t print 20.785s, t batch 1.039s
train Ep 44, Sp 7360, loss 0.673109, t print 11.479s, t batch 0.574s
train Ep 44, Sp 7520, loss 0.705077, t print 11.429s, t batch 0.571s
train Ep 44, Sp 7680, loss 0.688477, t print 21.377s, t batch 1.069s
train Ep 44, Sp 7840, loss 0.683218, t print 11.186s, t batch 0.559s
train Ep 44, Sp 8000, loss 0.703431, t print 11.148s, t batch 0.557s
train Ep 44, Sp 8160, loss 0.664031, t print 20.938s, t batch 1.047s
train Ep 44, Sp 8320, loss 0.655, t print 11.103s, t batch 0.555s
train Ep 44, Sp 8480, loss 0.677153, t print 11.291s, t batch 0.565s
train Ep 44, Sp 8640, loss 0.651854, t print 20.879s, t batch 1.044s
train Ep 44, Sp 8800, loss 0.6614, t print 11.44s, t batch 0.572s
train Ep 44, Sp 8960, loss 0.733434, t print 10.971s, t batch 0.549s
train Ep 44, Sp 9120, loss 0.715342, t print 20.803s, t batch 1.04s
train Ep 44, Sp 9280, loss 0.672926, t print 11.404s, t batch 0.57s
train Ep 44, Sp 9440, loss 0.678142, t print 11.094s, t batch 0.555s
train Ep 44, Sp 9600, loss 0.691832, t print 20.347s, t batch 1.017s
train Ep 44, Sp 9760, loss 0.684321, t print 11.17s, t batch 0.559s
train Ep 44, Sp 9920, loss 0.683358, t print 11.613s, t batch 0.581s
train Ep 44, Sp 10080, loss 0.636202, t print 19.856s, t batch 0.993s
train Ep 44, Sp 10240, loss 0.666163, t print 11.062s, t batch 0.553s
Start looping batches...
validate Ep 44, Sp 160, loss 0.683465, t print 1.0s, t batch 0.05s
validate Ep 44, Sp 320, loss 0.663114, t print 1338.333s, t batch 66.917s
validate Ep 44, Sp 480, loss 0.721655, t print 11.428s, t batch 0.571s
validate Ep 44, Sp 640, loss 0.679614, t print 11.301s, t batch 0.565s
validate Ep 44, Sp 800, loss 0.698461, t print 19.776s, t batch 0.989s
validate Ep 44, Sp 960, loss 0.649936, t print 12.175s, t batch 0.609s
validate Ep 44, Sp 1120, loss 0.686512, t print 11.055s, t batch 0.553s
validate Ep 44, Sp 1280, loss 0.70728, t print 18.073s, t batch 0.904s
validate Ep 44, Sp 1440, loss 0.698436, t print 13.816s, t batch 0.691s
validate Ep 44, Sp 1600, loss 0.654307, t print 11.03s, t batch 0.552s
validate Ep 44, Sp 1760, loss 0.693576, t print 16.504s, t batch 0.825s
validate Ep 44, Sp 1920, loss 0.691851, t print 14.964s, t batch 0.748s
validate Ep 44, Sp 2080, loss 0.710406, t print 10.922s, t batch 0.546s
validate Ep 44, Sp 2240, loss 0.701615, t print 15.407s, t batch 0.77s
validate Ep 44, Sp 2400, loss 0.65944, t print 15.901s, t batch 0.795s
  Epoch 44, Average Epoch loss = 0.6806695058389947
  Epoch 44, nr_of_updates 58320
current learning rate: 0.001
  Epoch 44, time total 2441.089282274246s
  Epoch 44, time UNet: 123.74783110618591s
  Epoch 44, time metrics: 0.1367480754852295s
  Epoch 44, time saving files: 0.0002644062042236328s
2023-12-01 05:20:32.282428
Start looping batches...
train Ep 45, Sp 160, loss 0.706516, t print 1.799s, t batch 0.09s
train Ep 45, Sp 320, loss 0.735175, t print 10.742s, t batch 0.537s
train Ep 45, Sp 480, loss 0.698878, t print 13.636s, t batch 0.682s
train Ep 45, Sp 640, loss 0.653589, t print 11.463s, t batch 0.573s
train Ep 45, Sp 800, loss 0.685193, t print 19.585s, t batch 0.979s
train Ep 45, Sp 960, loss 0.682225, t print 12.78s, t batch 0.639s
train Ep 45, Sp 1120, loss 0.668271, t print 11.301s, t batch 0.565s
train Ep 45, Sp 1280, loss 0.6822, t print 17.757s, t batch 0.888s
train Ep 45, Sp 1440, loss 0.675859, t print 14.926s, t batch 0.746s
train Ep 45, Sp 1600, loss 0.679445, t print 11.342s, t batch 0.567s
train Ep 45, Sp 1760, loss 0.660576, t print 15.558s, t batch 0.778s
train Ep 45, Sp 1920, loss 0.673204, t print 16.621s, t batch 0.831s
train Ep 45, Sp 2080, loss 0.681662, t print 10.954s, t batch 0.548s
train Ep 45, Sp 2240, loss 0.711333, t print 13.896s, t batch 0.695s
train Ep 45, Sp 2400, loss 0.669388, t print 17.96s, t batch 0.898s
train Ep 45, Sp 2560, loss 0.658832, t print 11.249s, t batch 0.562s
train Ep 45, Sp 2720, loss 0.681594, t print 12.596s, t batch 0.63s
train Ep 45, Sp 2880, loss 0.682978, t print 19.698s, t batch 0.985s
train Ep 45, Sp 3040, loss 0.702546, t print 11.437s, t batch 0.572s
train Ep 45, Sp 3200, loss 0.631214, t print 10.956s, t batch 0.548s
train Ep 45, Sp 3360, loss 0.678471, t print 20.535s, t batch 1.027s
train Ep 45, Sp 3520, loss 0.685938, t print 11.326s, t batch 0.566s
train Ep 45, Sp 3680, loss 0.673272, t print 11.367s, t batch 0.568s
train Ep 45, Sp 3840, loss 0.683295, t print 20.914s, t batch 1.046s
train Ep 45, Sp 4000, loss 0.665211, t print 11.37s, t batch 0.569s
train Ep 45, Sp 4160, loss 0.647752, t print 11.576s, t batch 0.579s
train Ep 45, Sp 4320, loss 0.668734, t print 21.03s, t batch 1.051s
train Ep 45, Sp 4480, loss 0.710393, t print 11.221s, t batch 0.561s
train Ep 45, Sp 4640, loss 0.674554, t print 11.194s, t batch 0.56s
train Ep 45, Sp 4800, loss 0.662529, t print 21.026s, t batch 1.051s
train Ep 45, Sp 4960, loss 0.693105, t print 11.373s, t batch 0.569s
train Ep 45, Sp 5120, loss 0.681439, t print 11.383s, t batch 0.569s
train Ep 45, Sp 5280, loss 0.684952, t print 21.117s, t batch 1.056s
train Ep 45, Sp 5440, loss 0.695957, t print 11.144s, t batch 0.557s
train Ep 45, Sp 5600, loss 0.640896, t print 11.298s, t batch 0.565s
train Ep 45, Sp 5760, loss 0.678699, t print 21.077s, t batch 1.054s
train Ep 45, Sp 5920, loss 0.70069, t print 11.139s, t batch 0.557s
train Ep 45, Sp 6080, loss 0.658863, t print 11.22s, t batch 0.561s
train Ep 45, Sp 6240, loss 0.676581, t print 20.699s, t batch 1.035s
train Ep 45, Sp 6400, loss 0.693276, t print 11.146s, t batch 0.557s
train Ep 45, Sp 6560, loss 0.681327, t print 11.151s, t batch 0.558s
train Ep 45, Sp 6720, loss 0.679028, t print 21.057s, t batch 1.053s
train Ep 45, Sp 6880, loss 0.644557, t print 11.119s, t batch 0.556s
train Ep 45, Sp 7040, loss 0.667984, t print 11.186s, t batch 0.559s
train Ep 45, Sp 7200, loss 0.628941, t print 20.752s, t batch 1.038s
train Ep 45, Sp 7360, loss 0.682177, t print 11.137s, t batch 0.557s
train Ep 45, Sp 7520, loss 0.695905, t print 11.211s, t batch 0.561s
train Ep 45, Sp 7680, loss 0.650141, t print 20.66s, t batch 1.033s
train Ep 45, Sp 7840, loss 0.661512, t print 11.221s, t batch 0.561s
train Ep 45, Sp 8000, loss 0.700312, t print 11.17s, t batch 0.559s
train Ep 45, Sp 8160, loss 0.658055, t print 20.808s, t batch 1.04s
train Ep 45, Sp 8320, loss 0.709413, t print 11.282s, t batch 0.564s
train Ep 45, Sp 8480, loss 0.668159, t print 11.103s, t batch 0.555s
train Ep 45, Sp 8640, loss 0.640004, t print 20.823s, t batch 1.041s
train Ep 45, Sp 8800, loss 0.634004, t print 11.122s, t batch 0.556s
train Ep 45, Sp 8960, loss 0.665519, t print 11.683s, t batch 0.584s
train Ep 45, Sp 9120, loss 0.649066, t print 19.796s, t batch 0.99s
train Ep 45, Sp 9280, loss 0.670839, t print 10.856s, t batch 0.543s
train Ep 45, Sp 9440, loss 0.694676, t print 12.946s, t batch 0.647s
train Ep 45, Sp 9600, loss 0.667325, t print 17.935s, t batch 0.897s
train Ep 45, Sp 9760, loss 0.661289, t print 10.976s, t batch 0.549s
train Ep 45, Sp 9920, loss 0.665552, t print 14.994s, t batch 0.75s
train Ep 45, Sp 10080, loss 0.676214, t print 16.263s, t batch 0.813s
train Ep 45, Sp 10240, loss 0.664206, t print 10.831s, t batch 0.542s
Start looping batches...
validate Ep 45, Sp 160, loss 0.688668, t print 0.995s, t batch 0.05s
validate Ep 45, Sp 320, loss 0.68373, t print 12.191s, t batch 0.61s
validate Ep 45, Sp 480, loss 0.681376, t print 12.034s, t batch 0.602s
validate Ep 45, Sp 640, loss 0.69666, t print 11.04s, t batch 0.552s
validate Ep 45, Sp 800, loss 0.687037, t print 20.085s, t batch 1.004s
validate Ep 45, Sp 960, loss 0.706818, t print 11.208s, t batch 0.56s
validate Ep 45, Sp 1120, loss 0.689754, t print 11.059s, t batch 0.553s
validate Ep 45, Sp 1280, loss 0.672233, t print 19.84s, t batch 0.992s
validate Ep 45, Sp 1440, loss 0.682824, t print 10.969s, t batch 0.548s
validate Ep 45, Sp 1600, loss 0.677317, t print 10.621s, t batch 0.531s
validate Ep 45, Sp 1760, loss 0.687346, t print 19.365s, t batch 0.968s
validate Ep 45, Sp 1920, loss 0.71156, t print 12.059s, t batch 0.603s
validate Ep 45, Sp 2080, loss 0.692987, t print 10.815s, t batch 0.541s
validate Ep 45, Sp 2240, loss 0.695129, t print 17.997s, t batch 0.9s
validate Ep 45, Sp 2400, loss 0.674133, t print 13.085s, t batch 0.654s
  Epoch 45, Average Epoch loss = 0.6745232190522883
  Epoch 45, nr_of_updates 59616
current learning rate: 0.001
  Epoch 45, time total 1106.3842787742615s
  Epoch 45, time UNet: 124.31399726867676s
  Epoch 45, time metrics: 0.13193607330322266s
  Epoch 45, time saving files: 0.00011849403381347656s
2023-12-01 05:38:58.674780
Start looping batches...
train Ep 46, Sp 160, loss 0.704892, t print 1.583s, t batch 0.079s
train Ep 46, Sp 320, loss 0.701175, t print 11.419s, t batch 0.571s
train Ep 46, Sp 480, loss 0.689132, t print 12.7s, t batch 0.635s
train Ep 46, Sp 640, loss 0.695358, t print 11.775s, t batch 0.589s
train Ep 46, Sp 800, loss 0.685635, t print 21.712s, t batch 1.086s
train Ep 46, Sp 960, loss 0.652954, t print 11.704s, t batch 0.585s
train Ep 46, Sp 1120, loss 0.682807, t print 11.654s, t batch 0.583s
train Ep 46, Sp 1280, loss 0.724696, t print 21.391s, t batch 1.07s
train Ep 46, Sp 1440, loss 0.663065, t print 11.683s, t batch 0.584s
train Ep 46, Sp 1600, loss 0.685131, t print 11.413s, t batch 0.571s
train Ep 46, Sp 1760, loss 0.649713, t print 20.352s, t batch 1.018s
train Ep 46, Sp 1920, loss 0.675451, t print 12.508s, t batch 0.625s
train Ep 46, Sp 2080, loss 0.668298, t print 11.577s, t batch 0.579s
train Ep 46, Sp 2240, loss 0.661069, t print 18.034s, t batch 0.902s
train Ep 46, Sp 2400, loss 0.680962, t print 14.527s, t batch 0.726s
train Ep 46, Sp 2560, loss 0.721629, t print 11.223s, t batch 0.561s
train Ep 46, Sp 2720, loss 0.702386, t print 16.111s, t batch 0.806s
train Ep 46, Sp 2880, loss 0.671448, t print 16.353s, t batch 0.818s
train Ep 46, Sp 3040, loss 0.672187, t print 11.369s, t batch 0.568s
train Ep 46, Sp 3200, loss 0.616783, t print 13.884s, t batch 0.694s
train Ep 46, Sp 3360, loss 0.701922, t print 18.643s, t batch 0.932s
train Ep 46, Sp 3520, loss 0.692411, t print 11.41s, t batch 0.571s
train Ep 46, Sp 3680, loss 0.703786, t print 11.289s, t batch 0.564s
train Ep 46, Sp 3840, loss 0.686684, t print 20.951s, t batch 1.048s
train Ep 46, Sp 4000, loss 0.711094, t print 11.329s, t batch 0.566s
train Ep 46, Sp 4160, loss 0.668036, t print 11.383s, t batch 0.569s
train Ep 46, Sp 4320, loss 0.696415, t print 21.032s, t batch 1.052s
train Ep 46, Sp 4480, loss 0.708155, t print 11.272s, t batch 0.564s
train Ep 46, Sp 4640, loss 0.665684, t print 11.233s, t batch 0.562s
train Ep 46, Sp 4800, loss 0.680354, t print 20.674s, t batch 1.034s
train Ep 46, Sp 4960, loss 0.668023, t print 11.454s, t batch 0.573s
train Ep 46, Sp 5120, loss 0.645568, t print 11.244s, t batch 0.562s
train Ep 46, Sp 5280, loss 0.718537, t print 20.611s, t batch 1.031s
train Ep 46, Sp 5440, loss 0.682992, t print 11.66s, t batch 0.583s
train Ep 46, Sp 5600, loss 0.686879, t print 11.434s, t batch 0.572s
train Ep 46, Sp 5760, loss 0.71131, t print 19.701s, t batch 0.985s
train Ep 46, Sp 5920, loss 0.665762, t print 12.32s, t batch 0.616s
train Ep 46, Sp 6080, loss 0.682197, t print 11.282s, t batch 0.564s
train Ep 46, Sp 6240, loss 0.641082, t print 18.029s, t batch 0.901s
train Ep 46, Sp 6400, loss 0.684286, t print 14.366s, t batch 0.718s
train Ep 46, Sp 6560, loss 0.702343, t print 11.389s, t batch 0.569s
train Ep 46, Sp 6720, loss 0.66371, t print 15.861s, t batch 0.793s
train Ep 46, Sp 6880, loss 0.651733, t print 16.554s, t batch 0.828s
train Ep 46, Sp 7040, loss 0.677666, t print 11.218s, t batch 0.561s
train Ep 46, Sp 7200, loss 0.667195, t print 13.924s, t batch 0.696s
train Ep 46, Sp 7360, loss 0.658312, t print 18.263s, t batch 0.913s
train Ep 46, Sp 7520, loss 0.655061, t print 11.28s, t batch 0.564s
train Ep 46, Sp 7680, loss 0.693282, t print 11.619s, t batch 0.581s
train Ep 46, Sp 7840, loss 0.674218, t print 20.511s, t batch 1.026s
train Ep 46, Sp 8000, loss 0.667812, t print 11.246s, t batch 0.562s
train Ep 46, Sp 8160, loss 0.685851, t print 11.455s, t batch 0.573s
train Ep 46, Sp 8320, loss 0.683871, t print 20.991s, t batch 1.05s
train Ep 46, Sp 8480, loss 0.650805, t print 11.279s, t batch 0.564s
train Ep 46, Sp 8640, loss 0.647534, t print 11.271s, t batch 0.564s
train Ep 46, Sp 8800, loss 0.660452, t print 20.886s, t batch 1.044s
train Ep 46, Sp 8960, loss 0.698717, t print 11.277s, t batch 0.564s
train Ep 46, Sp 9120, loss 0.648287, t print 11.275s, t batch 0.564s
train Ep 46, Sp 9280, loss 0.668935, t print 20.976s, t batch 1.049s
train Ep 46, Sp 9440, loss 0.696552, t print 11.168s, t batch 0.558s
train Ep 46, Sp 9600, loss 0.663658, t print 11.177s, t batch 0.559s
train Ep 46, Sp 9760, loss 0.677946, t print 20.91s, t batch 1.046s
train Ep 46, Sp 9920, loss 0.685158, t print 11.064s, t batch 0.553s
train Ep 46, Sp 10080, loss 0.675636, t print 11.248s, t batch 0.562s
train Ep 46, Sp 10240, loss 0.670044, t print 20.229s, t batch 1.011s
Start looping batches...
validate Ep 46, Sp 160, loss 0.717451, t print 1.06s, t batch 0.053s
validate Ep 46, Sp 320, loss 0.675276, t print 1086.502s, t batch 54.325s
validate Ep 46, Sp 480, loss 0.684428, t print 11.787s, t batch 0.589s
validate Ep 46, Sp 640, loss 0.715685, t print 11.123s, t batch 0.556s
validate Ep 46, Sp 800, loss 0.671652, t print 18.685s, t batch 0.934s
validate Ep 46, Sp 960, loss 0.696758, t print 13.423s, t batch 0.671s
validate Ep 46, Sp 1120, loss 0.698835, t print 10.983s, t batch 0.549s
validate Ep 46, Sp 1280, loss 0.699858, t print 15.994s, t batch 0.8s
validate Ep 46, Sp 1440, loss 0.721941, t print 16.129s, t batch 0.806s
validate Ep 46, Sp 1600, loss 0.725833, t print 10.991s, t batch 0.55s
validate Ep 46, Sp 1760, loss 0.669311, t print 13.346s, t batch 0.667s
validate Ep 46, Sp 1920, loss 0.694602, t print 18.497s, t batch 0.925s
validate Ep 46, Sp 2080, loss 0.7115, t print 10.83s, t batch 0.542s
validate Ep 46, Sp 2240, loss 0.681493, t print 11.03s, t batch 0.552s
validate Ep 46, Sp 2400, loss 0.718416, t print 20.54s, t batch 1.027s
  Epoch 46, Average Epoch loss = 0.6787347103710528
  Epoch 46, nr_of_updates 60912
current learning rate: 0.001
  Epoch 46, time total 2193.652395963669s
  Epoch 46, time UNet: 123.45096564292908s
  Epoch 46, time metrics: 0.131270170211792s
  Epoch 46, time saving files: 0.0002543926239013672s
2023-12-01 06:15:32.334415
Start looping batches...
train Ep 47, Sp 160, loss 0.680032, t print 1.773s, t batch 0.089s
train Ep 47, Sp 320, loss 0.682563, t print 11.522s, t batch 0.576s
train Ep 47, Sp 480, loss 0.683025, t print 13.478s, t batch 0.674s
train Ep 47, Sp 640, loss 0.6707, t print 11.225s, t batch 0.561s
train Ep 47, Sp 800, loss 0.703507, t print 19.724s, t batch 0.986s
train Ep 47, Sp 960, loss 0.671745, t print 12.454s, t batch 0.623s
train Ep 47, Sp 1120, loss 0.686564, t print 11.267s, t batch 0.563s
train Ep 47, Sp 1280, loss 0.661612, t print 19.984s, t batch 0.999s
train Ep 47, Sp 1440, loss 0.657424, t print 12.677s, t batch 0.634s
train Ep 47, Sp 1600, loss 0.696725, t print 11.269s, t batch 0.563s
train Ep 47, Sp 1760, loss 0.708742, t print 17.912s, t batch 0.896s
train Ep 47, Sp 1920, loss 0.661391, t print 14.069s, t batch 0.703s
train Ep 47, Sp 2080, loss 0.671033, t print 11.339s, t batch 0.567s
train Ep 47, Sp 2240, loss 0.682433, t print 16.726s, t batch 0.836s
train Ep 47, Sp 2400, loss 0.64563, t print 15.041s, t batch 0.752s
train Ep 47, Sp 2560, loss 0.688136, t print 11.224s, t batch 0.561s
train Ep 47, Sp 2720, loss 0.653761, t print 15.658s, t batch 0.783s
train Ep 47, Sp 2880, loss 0.665846, t print 16.421s, t batch 0.821s
train Ep 47, Sp 3040, loss 0.673016, t print 11.027s, t batch 0.551s
train Ep 47, Sp 3200, loss 0.691596, t print 14.404s, t batch 0.72s
train Ep 47, Sp 3360, loss 0.702769, t print 17.062s, t batch 0.853s
train Ep 47, Sp 3520, loss 0.700512, t print 11.182s, t batch 0.559s
train Ep 47, Sp 3680, loss 0.707114, t print 13.484s, t batch 0.674s
train Ep 47, Sp 3840, loss 0.674898, t print 18.425s, t batch 0.921s
train Ep 47, Sp 4000, loss 0.658326, t print 11.339s, t batch 0.567s
train Ep 47, Sp 4160, loss 0.685406, t print 11.912s, t batch 0.596s
train Ep 47, Sp 4320, loss 0.647704, t print 20.756s, t batch 1.038s
train Ep 47, Sp 4480, loss 0.667434, t print 11.433s, t batch 0.572s
train Ep 47, Sp 4640, loss 0.685887, t print 11.486s, t batch 0.574s
train Ep 47, Sp 4800, loss 0.676082, t print 21.201s, t batch 1.06s
train Ep 47, Sp 4960, loss 0.712106, t print 11.396s, t batch 0.57s
train Ep 47, Sp 5120, loss 0.679758, t print 11.267s, t batch 0.563s
train Ep 47, Sp 5280, loss 0.669817, t print 21.184s, t batch 1.059s
train Ep 47, Sp 5440, loss 0.692088, t print 11.295s, t batch 0.565s
train Ep 47, Sp 5600, loss 0.672754, t print 11.307s, t batch 0.565s
train Ep 47, Sp 5760, loss 0.640736, t print 21.147s, t batch 1.057s
train Ep 47, Sp 5920, loss 0.646063, t print 11.395s, t batch 0.57s
train Ep 47, Sp 6080, loss 0.624806, t print 11.245s, t batch 0.562s
train Ep 47, Sp 6240, loss 0.696941, t print 20.999s, t batch 1.05s
train Ep 47, Sp 6400, loss 0.657577, t print 11.155s, t batch 0.558s
train Ep 47, Sp 6560, loss 0.661356, t print 11.202s, t batch 0.56s
train Ep 47, Sp 6720, loss 0.677244, t print 20.864s, t batch 1.043s
train Ep 47, Sp 6880, loss 0.706646, t print 11.177s, t batch 0.559s
train Ep 47, Sp 7040, loss 0.706094, t print 11.23s, t batch 0.562s
train Ep 47, Sp 7200, loss 0.68359, t print 21.086s, t batch 1.054s
train Ep 47, Sp 7360, loss 0.685073, t print 11.313s, t batch 0.566s
train Ep 47, Sp 7520, loss 0.71644, t print 11.262s, t batch 0.563s
train Ep 47, Sp 7680, loss 0.690386, t print 20.859s, t batch 1.043s
train Ep 47, Sp 7840, loss 0.616861, t print 11.107s, t batch 0.555s
train Ep 47, Sp 8000, loss 0.655599, t print 11.171s, t batch 0.559s
train Ep 47, Sp 8160, loss 0.655703, t print 20.634s, t batch 1.032s
train Ep 47, Sp 8320, loss 0.718756, t print 11.028s, t batch 0.551s
train Ep 47, Sp 8480, loss 0.671373, t print 11.093s, t batch 0.555s
train Ep 47, Sp 8640, loss 0.697308, t print 20.835s, t batch 1.042s
train Ep 47, Sp 8800, loss 0.679523, t print 11.159s, t batch 0.558s
train Ep 47, Sp 8960, loss 0.680605, t print 11.007s, t batch 0.55s
train Ep 47, Sp 9120, loss 0.662702, t print 20.779s, t batch 1.039s
train Ep 47, Sp 9280, loss 0.681038, t print 11.179s, t batch 0.559s
train Ep 47, Sp 9440, loss 0.680456, t print 11.263s, t batch 0.563s
train Ep 47, Sp 9600, loss 0.671929, t print 20.874s, t batch 1.044s
train Ep 47, Sp 9760, loss 0.635944, t print 11.252s, t batch 0.563s
train Ep 47, Sp 9920, loss 0.699218, t print 11.182s, t batch 0.559s
train Ep 47, Sp 10080, loss 0.696276, t print 20.949s, t batch 1.047s
train Ep 47, Sp 10240, loss 0.669342, t print 11.253s, t batch 0.563s
Start looping batches...
validate Ep 47, Sp 160, loss 0.68966, t print 1.046s, t batch 0.052s
